{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def list_files(directory):\n",
    "    files = []\n",
    "    for entry in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, entry)):\n",
    "            files.append(entry)\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"results_regression_random_fp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_fp', 'model_fp_1', 'model_fp_10', 'model_fp_11', 'model_fp_12', 'model_fp_13', 'model_fp_14', 'model_fp_15', 'model_fp_16', 'model_fp_17', 'model_fp_18', 'model_fp_19', 'model_fp_2', 'model_fp_20', 'model_fp_21', 'model_fp_22', 'model_fp_23', 'model_fp_24', 'model_fp_25', 'model_fp_26', 'model_fp_27', 'model_fp_28', 'model_fp_29', 'model_fp_3', 'model_fp_30', 'model_fp_31', 'model_fp_32', 'model_fp_33', 'model_fp_34', 'model_fp_35', 'model_fp_36', 'model_fp_37', 'model_fp_38', 'model_fp_39', 'model_fp_4', 'model_fp_40', 'model_fp_41', 'model_fp_42', 'model_fp_43', 'model_fp_44', 'model_fp_45', 'model_fp_46', 'model_fp_47', 'model_fp_48', 'model_fp_49', 'model_fp_5', 'model_fp_50', 'model_fp_51', 'model_fp_52', 'model_fp_53', 'model_fp_54', 'model_fp_55', 'model_fp_56', 'model_fp_57', 'model_fp_58', 'model_fp_59', 'model_fp_6', 'model_fp_60', 'model_fp_61', 'model_fp_62', 'model_fp_63', 'model_fp_7', 'model_fp_8', 'model_fp_9']\n"
     ]
    }
   ],
   "source": [
    "files = list_files(path1)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_load = []\n",
    "import dill as pickle\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(path1, file)\n",
    "    with open(file_path, 'rb') as filel:\n",
    "        loaded_data = pickle.load(filel)\n",
    "    file1_load.append(loaded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pred_df':     y_real    y_pred\n",
       "  0    0.260 -0.217934\n",
       "  1   -2.730 -3.277978\n",
       "  2   -1.989 -2.744406\n",
       "  3   -4.630 -4.869869\n",
       "  4   -9.160 -9.300808\n",
       "  ..     ...       ...\n",
       "  43  -0.807 -1.706972\n",
       "  44  -7.200 -6.482987\n",
       "  45  -1.520 -1.575114\n",
       "  46  -7.850 -7.854436\n",
       "  47  -3.220 -3.911534\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 6.929111003875732,\n",
       "  'mean_mse': 0.5684865117073059,\n",
       "  'mean_l1': 0.5806424021720886,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    1.100  0.383697\n",
       "  1   -1.110 -0.917745\n",
       "  2   -2.280 -2.894435\n",
       "  3   -4.799 -3.932454\n",
       "  4   -0.807 -2.730420\n",
       "  ..     ...       ...\n",
       "  43  -0.600 -0.916204\n",
       "  44  -3.100 -2.384422\n",
       "  45   0.610  0.268682\n",
       "  46  -3.450 -3.391114\n",
       "  47  -4.280 -4.056045\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 13.692472696304321,\n",
       "  'mean_mse': 1.3549762964248657,\n",
       "  'mean_l1': 0.8164159059524536,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.630 -3.918129\n",
       "  1   -4.173 -4.970779\n",
       "  2    0.430  0.119159\n",
       "  3   -0.040 -0.437762\n",
       "  4   -5.233 -5.298150\n",
       "  ..     ...       ...\n",
       "  43  -6.560 -6.055377\n",
       "  44  -1.520 -1.638013\n",
       "  45  -9.160 -9.859528\n",
       "  46  -2.420 -3.204694\n",
       "  47  -1.220 -0.884629\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 8.363253831863403,\n",
       "  'mean_mse': 0.5301823914051056,\n",
       "  'mean_l1': 0.523892343044281,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.390 -2.003737\n",
       "  1   -5.840 -2.981987\n",
       "  2   -4.920 -2.414912\n",
       "  3   -2.770 -2.672009\n",
       "  4   -0.440 -0.857579\n",
       "  ..     ...       ...\n",
       "  43  -3.010 -3.775321\n",
       "  44  -0.400  0.196680\n",
       "  45  -4.310 -4.727337\n",
       "  46  -4.799 -4.075119\n",
       "  47  -1.360 -1.435209\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 24.248043537139893,\n",
       "  'mean_mse': 1.382520854473114,\n",
       "  'mean_l1': 0.8236710727214813,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.030 -4.372954\n",
       "  1    0.620 -0.829944\n",
       "  2   -4.110 -3.861157\n",
       "  3   -5.507 -5.021128\n",
       "  4   -3.927 -2.355469\n",
       "  ..     ...       ...\n",
       "  43  -4.470 -4.783098\n",
       "  44  -3.010 -3.388128\n",
       "  45  -1.640 -1.945226\n",
       "  46  -1.947 -0.628570\n",
       "  47  -3.928 -3.790787\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 5.4149816036224365,\n",
       "  'mean_mse': 0.5311879813671112,\n",
       "  'mean_l1': 0.5351666510105133,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.450 -3.613096\n",
       "  1   -4.799 -3.774118\n",
       "  2   -4.173 -4.441538\n",
       "  3   -2.218 -1.773059\n",
       "  4    0.260 -0.367287\n",
       "  ..     ...       ...\n",
       "  43  -1.947 -1.814011\n",
       "  44  -1.300 -1.598778\n",
       "  45  -7.850 -8.804091\n",
       "  46  -3.400 -3.963107\n",
       "  47  -3.780 -3.972414\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 13.257061004638672,\n",
       "  'mean_mse': 1.4276169538497925,\n",
       "  'mean_l1': 0.847966194152832,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.928 -3.741951\n",
       "  1   -2.550 -2.079988\n",
       "  2   -1.228 -1.348674\n",
       "  3   -6.560 -5.901973\n",
       "  4   -3.083 -2.722452\n",
       "  ..     ...       ...\n",
       "  43  -3.796 -3.860889\n",
       "  44  -2.280 -1.686288\n",
       "  45  -2.000 -2.048414\n",
       "  46   0.610  0.430907\n",
       "  47  -2.370 -1.820758\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 4.819786071777344,\n",
       "  'mean_mse': 0.5575806796550751,\n",
       "  'mean_l1': 0.5650345087051392,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    -2.37 -2.064758\n",
       "  1    -1.06 -0.673330\n",
       "  2    -4.37 -3.537796\n",
       "  3    -6.25 -6.990582\n",
       "  4    -0.18 -0.679283\n",
       "  ..     ...       ...\n",
       "  43    0.62 -0.966596\n",
       "  44   -2.56 -1.069483\n",
       "  45   -0.22 -0.885021\n",
       "  46   -2.42 -3.018779\n",
       "  47   -8.40 -3.130947\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 15.219672679901123,\n",
       "  'mean_mse': 1.5047279596328735,\n",
       "  'mean_l1': 0.8422808051109314,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.300 -3.279341\n",
       "  1   -5.240 -4.536639\n",
       "  2    1.100  0.230237\n",
       "  3   -4.630 -4.457242\n",
       "  4   -5.840 -5.033255\n",
       "  ..     ...       ...\n",
       "  43   0.009 -0.168548\n",
       "  44   0.790  0.218811\n",
       "  45  -1.300 -1.294324\n",
       "  46  -3.680 -3.685260\n",
       "  47  -1.520 -2.695380\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 4.363600015640259,\n",
       "  'mean_mse': 0.6755723506212234,\n",
       "  'mean_l1': 0.6204733848571777,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -6.560 -6.333782\n",
       "  1   -6.250 -6.682584\n",
       "  2    0.009 -0.668053\n",
       "  3   -3.850 -4.672784\n",
       "  4    0.790 -0.597388\n",
       "  ..     ...       ...\n",
       "  43  -1.458 -0.770132\n",
       "  44  -0.400 -0.132061\n",
       "  45  -4.380 -1.687397\n",
       "  46  -3.900 -3.217687\n",
       "  47  -1.110 -0.868251\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 10.739335298538208,\n",
       "  'mean_mse': 1.4942464232444763,\n",
       "  'mean_l1': 0.8660785853862762,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.630 -4.917092\n",
       "  1   -4.110 -4.049964\n",
       "  2   -0.390 -0.673204\n",
       "  3   -2.730 -3.053124\n",
       "  4   -0.600 -0.988915\n",
       "  ..     ...       ...\n",
       "  43  -1.340 -1.884448\n",
       "  44  -3.928 -3.507276\n",
       "  45  -5.240 -4.394295\n",
       "  46  -7.200 -6.313456\n",
       "  47  -6.560 -5.518741\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 5.2764081954956055,\n",
       "  'mean_mse': 0.5390735864639282,\n",
       "  'mean_l1': 0.5596542060375214,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.000 -2.110910\n",
       "  1   -0.220 -0.672489\n",
       "  2   -2.770 -2.845724\n",
       "  3   -4.173 -3.136575\n",
       "  4    0.620 -1.772979\n",
       "  ..     ...       ...\n",
       "  43  -2.210 -1.775833\n",
       "  44  -2.630 -2.952218\n",
       "  45  -5.400 -4.984069\n",
       "  46  -3.928 -3.451048\n",
       "  47  -0.400 -0.515999\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 9.056148290634155,\n",
       "  'mean_mse': 1.5050499439239502,\n",
       "  'mean_l1': 0.903564989566803,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.233 -4.873865\n",
       "  1    0.580  0.229923\n",
       "  2   -0.360 -0.906853\n",
       "  3   -2.550 -1.998151\n",
       "  4   -1.110 -0.359115\n",
       "  ..     ...       ...\n",
       "  43  -0.720 -1.068185\n",
       "  44   0.510 -0.784152\n",
       "  45  -2.420 -2.907963\n",
       "  46  -4.920 -3.594499\n",
       "  47  -1.228 -1.488171\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 9.599847078323364,\n",
       "  'mean_mse': 0.4782535582780838,\n",
       "  'mean_l1': 0.5016166865825653,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    -1.52 -1.164406\n",
       "  1    -6.78 -6.734174\n",
       "  2    -0.22 -0.120508\n",
       "  3    -0.60 -1.166142\n",
       "  4    -6.25 -6.104739\n",
       "  ..     ...       ...\n",
       "  43   -1.52 -2.482758\n",
       "  44   -1.36 -1.588634\n",
       "  45   -8.40 -7.262972\n",
       "  46   -4.28 -2.712356\n",
       "  47   -3.30 -3.055870\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 10.49998164176941,\n",
       "  'mean_mse': 0.5301017314195633,\n",
       "  'mean_l1': 0.5359472185373306,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.928 -2.762423\n",
       "  1   -4.173 -3.146808\n",
       "  2   -1.990 -1.126763\n",
       "  3   -5.233 -4.069253\n",
       "  4   -1.520 -4.423492\n",
       "  ..     ...       ...\n",
       "  43  -2.780 -3.010179\n",
       "  44  -2.210 -1.502119\n",
       "  45   0.610  0.015222\n",
       "  46   0.009 -0.311669\n",
       "  47  -6.780 -5.936512\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 5.330963611602783,\n",
       "  'mean_mse': 1.7311867475509644,\n",
       "  'mean_l1': 0.9151589572429657,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.345 -4.900681\n",
       "  1   -1.989 -2.833990\n",
       "  2   -0.030  0.290458\n",
       "  3   -0.807 -1.849946\n",
       "  4   -4.380 -3.997893\n",
       "  ..     ...       ...\n",
       "  43  -4.110 -3.777539\n",
       "  44   0.540 -0.117113\n",
       "  45  -6.560 -5.582820\n",
       "  46  -7.200 -5.777318\n",
       "  47  -2.780 -2.593096\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 5.0119712352752686,\n",
       "  'mean_mse': 0.6105859875679016,\n",
       "  'mean_l1': 0.6004112064838409,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.280 -2.597973\n",
       "  1   -0.440 -0.966806\n",
       "  2   -4.799 -4.284703\n",
       "  3   -1.989 -3.072418\n",
       "  4   -0.400 -0.068923\n",
       "  ..     ...       ...\n",
       "  43  -2.676 -3.526369\n",
       "  44  -2.460 -0.573217\n",
       "  45  -5.507 -5.554794\n",
       "  46  -1.110 -1.056389\n",
       "  47  -0.220 -0.046268\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 17.238409280776978,\n",
       "  'mean_mse': 1.5247278213500977,\n",
       "  'mean_l1': 0.8785308301448822,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.228 -1.067685\n",
       "  1   -2.770 -2.578671\n",
       "  2   -2.820 -3.001813\n",
       "  3   -4.470 -2.873170\n",
       "  4    0.430 -0.460674\n",
       "  ..     ...       ...\n",
       "  43  -3.630 -3.423865\n",
       "  44   0.260 -0.328125\n",
       "  45  -2.840 -3.814067\n",
       "  46  -2.210 -3.015204\n",
       "  47  -1.870 -2.523824\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 5.026054620742798,\n",
       "  'mean_mse': 0.6500511169433594,\n",
       "  'mean_l1': 0.629200279712677,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.900 -3.041262\n",
       "  1   -1.060 -1.513315\n",
       "  2   -0.600 -1.720028\n",
       "  3   -5.400 -5.180306\n",
       "  4   -3.450 -3.881287\n",
       "  ..     ...       ...\n",
       "  43   0.260 -1.013612\n",
       "  44  -2.210 -1.874460\n",
       "  45  -3.083 -2.790754\n",
       "  46  -2.080 -2.258766\n",
       "  47  -1.390 -1.489512\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 10.617286920547485,\n",
       "  'mean_mse': 1.3447668254375458,\n",
       "  'mean_l1': 0.8194785416126251,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.370 -3.797674\n",
       "  1   -1.228 -1.242790\n",
       "  2   -8.400 -7.620490\n",
       "  3    0.009  0.290108\n",
       "  4   -6.780 -7.058819\n",
       "  ..     ...       ...\n",
       "  43  -7.420 -8.690508\n",
       "  44  -2.676 -3.222352\n",
       "  45  -3.460 -3.620855\n",
       "  46  -3.083 -2.894406\n",
       "  47  -1.390 -1.435614\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 9.253152847290039,\n",
       "  'mean_mse': 0.5737784802913666,\n",
       "  'mean_l1': 0.5634965896606445,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.218 -2.462376\n",
       "  1   -5.840 -3.915792\n",
       "  2   -1.520 -3.489736\n",
       "  3   -4.920 -1.410475\n",
       "  4    1.100 -0.546593\n",
       "  ..     ...       ...\n",
       "  43  -2.420 -3.929717\n",
       "  44  -2.560 -0.953189\n",
       "  45  -2.380 -3.210495\n",
       "  46  -8.400 -3.915792\n",
       "  47  -6.560 -6.200065\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 10.974955558776855,\n",
       "  'mean_mse': 1.4214209914207458,\n",
       "  'mean_l1': 0.8591097891330719,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    -3.40 -3.120190\n",
       "  1    -4.28 -3.322875\n",
       "  2    -4.92 -2.346251\n",
       "  3    -3.63 -3.692141\n",
       "  4    -3.46 -3.437046\n",
       "  ..     ...       ...\n",
       "  43   -5.84 -6.027562\n",
       "  44   -3.01 -3.107722\n",
       "  45   -2.38 -2.214401\n",
       "  46   -2.85 -3.386278\n",
       "  47   -2.63 -2.386295\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 13.732640981674194,\n",
       "  'mean_mse': 0.5523374676704407,\n",
       "  'mean_l1': 0.5576243698596954,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.990 -1.930916\n",
       "  1   -2.210 -2.173990\n",
       "  2   -1.520 -1.042260\n",
       "  3   -2.370 -2.079144\n",
       "  4   -2.770 -2.798078\n",
       "  ..     ...       ...\n",
       "  43  -5.840 -3.744654\n",
       "  44  -2.280 -3.237094\n",
       "  45  -0.390 -1.229159\n",
       "  46  -4.345 -5.766606\n",
       "  47  -2.780 -3.006165\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 18.33858370780945,\n",
       "  'mean_mse': 1.4732046723365784,\n",
       "  'mean_l1': 0.8961238265037537,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.470 -2.798706\n",
       "  1   -2.820 -2.247890\n",
       "  2   -3.900 -3.042326\n",
       "  3   -1.989 -4.998037\n",
       "  4   -3.100 -2.375184\n",
       "  ..     ...       ...\n",
       "  43  -2.460 -1.082865\n",
       "  44   0.510 -1.686538\n",
       "  45  -1.640 -1.951093\n",
       "  46  -0.360 -1.551063\n",
       "  47  -4.370 -4.016369\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 6.448637008666992,\n",
       "  'mean_mse': 1.4638685882091522,\n",
       "  'mean_l1': 0.8826026022434235,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.990 -2.034906\n",
       "  1   -3.460 -3.606607\n",
       "  2   -1.370 -1.472526\n",
       "  3    0.540 -0.512213\n",
       "  4   -2.370 -1.954001\n",
       "  ..     ...       ...\n",
       "  43  -1.110 -0.770797\n",
       "  44  -4.173 -4.044315\n",
       "  45  -5.233 -5.255437\n",
       "  46  -1.340 -1.725651\n",
       "  47  -1.947 -0.402936\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 5.660367727279663,\n",
       "  'mean_mse': 0.7332511246204376,\n",
       "  'mean_l1': 0.6616034805774689,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    0.430 -0.138192\n",
       "  1   -1.947 -0.521956\n",
       "  2   -0.040 -0.853579\n",
       "  3   -7.200 -4.316103\n",
       "  4   -2.280 -3.200183\n",
       "  ..     ...       ...\n",
       "  43  -2.210 -2.001259\n",
       "  44  -0.807 -5.341360\n",
       "  45  -2.218 -2.251023\n",
       "  46  -1.060 -1.593147\n",
       "  47  -5.915 -3.964717\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 18.71347403526306,\n",
       "  'mean_mse': 1.5291870832443237,\n",
       "  'mean_l1': 0.8599429130554199,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.400 -4.343569\n",
       "  1   -3.220 -2.853975\n",
       "  2    0.580 -0.128155\n",
       "  3   -2.840 -5.483406\n",
       "  4   -3.083 -2.896759\n",
       "  ..     ...       ...\n",
       "  43  -2.560 -0.609050\n",
       "  44  -0.040 -0.067921\n",
       "  45  -2.370 -2.261199\n",
       "  46   0.620  0.442446\n",
       "  47  -6.250 -6.412034\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 7.725310325622559,\n",
       "  'mean_mse': 0.7341579794883728,\n",
       "  'mean_l1': 0.6336646676063538,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.083 -2.220535\n",
       "  1    0.522 -1.327553\n",
       "  2    0.510 -0.495385\n",
       "  3   -3.140 -2.149986\n",
       "  4   -1.989 -1.921244\n",
       "  ..     ...       ...\n",
       "  43  -4.920 -1.704020\n",
       "  44  -2.218 -3.232333\n",
       "  45  -5.240 -4.216961\n",
       "  46  -2.730 -2.494741\n",
       "  47  -2.770 -2.612264\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 7.458672285079956,\n",
       "  'mean_mse': 1.6275373697280884,\n",
       "  'mean_l1': 0.9494847059249878,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -0.180 -0.845762\n",
       "  1   -3.796 -3.216601\n",
       "  2   -6.250 -5.737170\n",
       "  3   -1.220 -1.288585\n",
       "  4   -1.730 -1.908899\n",
       "  ..     ...       ...\n",
       "  43  -3.928 -2.769585\n",
       "  44  -5.030 -4.274998\n",
       "  45  -3.780 -4.932075\n",
       "  46  -2.210 -2.934277\n",
       "  47  -4.280 -2.886950\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 7.134994745254517,\n",
       "  'mean_mse': 0.6886854469776154,\n",
       "  'mean_l1': 0.6370086669921875,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    -0.04 -0.180123\n",
       "  1    -3.30 -4.182779\n",
       "  2     0.51 -1.153670\n",
       "  3    -4.63 -4.338470\n",
       "  4    -0.39 -0.931940\n",
       "  ..     ...       ...\n",
       "  43   -3.46 -2.713266\n",
       "  44   -0.18 -1.048298\n",
       "  45   -3.01 -3.037945\n",
       "  46   -2.85 -2.003934\n",
       "  47   -1.87 -2.282990\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 10.323195457458496,\n",
       "  'mean_mse': 1.3527034521102905,\n",
       "  'mean_l1': 0.8882248997688293,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -0.360 -1.536925\n",
       "  1   -3.100 -2.958472\n",
       "  2   -1.947 -0.418550\n",
       "  3   -2.560 -0.536141\n",
       "  4   -0.600 -1.334651\n",
       "  ..     ...       ...\n",
       "  43  -3.780 -5.100494\n",
       "  44  -0.220 -0.194334\n",
       "  45  -1.110 -1.155332\n",
       "  46  -2.070 -3.151245\n",
       "  47   0.260 -0.174867\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 7.640276670455933,\n",
       "  'mean_mse': 0.6581487059593201,\n",
       "  'mean_l1': 0.6154260039329529,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -7.850 -8.015408\n",
       "  1   -1.300 -1.373387\n",
       "  2   -2.080 -2.487524\n",
       "  3   -1.340 -2.211062\n",
       "  4   -1.989 -2.022881\n",
       "  ..     ...       ...\n",
       "  43  -0.180 -0.702427\n",
       "  44  -0.600 -2.467033\n",
       "  45  -2.218 -2.855879\n",
       "  46  -3.140 -2.030967\n",
       "  47  -3.010 -2.694312\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 5.513758420944214,\n",
       "  'mean_mse': 1.4356886148452759,\n",
       "  'mean_l1': 0.8965553343296051,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    -1.52 -2.780245\n",
       "  1    -2.78 -2.448841\n",
       "  2    -4.63 -4.051096\n",
       "  3    -0.60 -1.448657\n",
       "  4    -8.40 -7.638827\n",
       "  ..     ...       ...\n",
       "  43   -2.84 -5.132123\n",
       "  44   -2.08 -2.639519\n",
       "  45   -1.22 -1.220988\n",
       "  46   -6.25 -6.193004\n",
       "  47   -0.39 -0.674296\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 8.589826107025146,\n",
       "  'mean_mse': 0.7459243535995483,\n",
       "  'mean_l1': 0.6377655863761902,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -0.600 -3.042642\n",
       "  1   -0.040  0.080960\n",
       "  2   -3.100 -1.773912\n",
       "  3   -2.676 -3.092760\n",
       "  4   -1.390 -1.192555\n",
       "  ..     ...       ...\n",
       "  43  -5.115 -8.589900\n",
       "  44  -2.080 -2.264668\n",
       "  45  -3.928 -2.634177\n",
       "  46   0.430  0.037607\n",
       "  47  -5.915 -5.259315\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 13.069761037826538,\n",
       "  'mean_mse': 1.6496633291244507,\n",
       "  'mean_l1': 0.9618699252605438,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.840 -5.391744\n",
       "  1   -1.820 -1.095284\n",
       "  2   -2.850 -2.259492\n",
       "  3   -2.820 -2.037468\n",
       "  4   -7.850 -7.826528\n",
       "  ..     ...       ...\n",
       "  43   0.430  0.070520\n",
       "  44  -4.630 -5.256163\n",
       "  45   0.009 -0.251682\n",
       "  46  -2.210 -1.201904\n",
       "  47   0.540  0.253928\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 8.57856559753418,\n",
       "  'mean_mse': 0.4514086842536926,\n",
       "  'mean_l1': 0.4859088808298111,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.780 -5.896853\n",
       "  1   -1.390 -1.281998\n",
       "  2   -1.990 -1.941775\n",
       "  3   -1.110 -0.517660\n",
       "  4   -3.928 -2.901344\n",
       "  ..     ...       ...\n",
       "  43  -2.080 -2.575979\n",
       "  44   0.260 -0.331847\n",
       "  45  -3.083 -2.664111\n",
       "  46  -2.210 -1.392790\n",
       "  47  -0.360 -1.082294\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 6.447284460067749,\n",
       "  'mean_mse': 0.8138912916183472,\n",
       "  'mean_l1': 0.6859955787658691,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.310 -6.641435\n",
       "  1   -2.000 -2.184439\n",
       "  2   -0.220 -0.108554\n",
       "  3   -4.799 -4.095981\n",
       "  4   -6.291 -7.028720\n",
       "  ..     ...       ...\n",
       "  43   1.100  0.859475\n",
       "  44  -6.250 -5.856204\n",
       "  45  -3.010 -3.331807\n",
       "  46  -2.770 -3.067492\n",
       "  47  -3.796 -3.914723\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 16.76952624320984,\n",
       "  'mean_mse': 1.397617518901825,\n",
       "  'mean_l1': 0.8978160917758942,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0     0.51 -0.647028\n",
       "  1    -0.03 -0.387514\n",
       "  2    -6.25 -6.171184\n",
       "  3    -8.40 -7.203226\n",
       "  4    -4.63 -4.515692\n",
       "  ..     ...       ...\n",
       "  43   -2.42 -2.245633\n",
       "  44   -2.56 -1.032025\n",
       "  45   -4.31 -4.885792\n",
       "  46   -3.45 -3.985346\n",
       "  47   -1.11 -0.909525\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 24.893226385116577,\n",
       "  'mean_mse': 0.6640750467777252,\n",
       "  'mean_l1': 0.6011834740638733,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.420 -3.573024\n",
       "  1   -2.080 -2.189980\n",
       "  2   -2.380 -3.188338\n",
       "  3   -7.420 -9.325453\n",
       "  4   -1.458 -1.188739\n",
       "  ..     ...       ...\n",
       "  43  -6.780 -5.689321\n",
       "  44  -6.250 -6.010806\n",
       "  45  -5.915 -4.580422\n",
       "  46  -4.630 -4.556249\n",
       "  47  -2.770 -3.113107\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 16.67246413230896,\n",
       "  'mean_mse': 1.4894643425941467,\n",
       "  'mean_l1': 0.9326685667037964,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.380 -2.516917\n",
       "  1   -8.400 -7.448731\n",
       "  2    0.620  0.437152\n",
       "  3    0.510 -0.636581\n",
       "  4   -3.400 -2.471805\n",
       "  ..     ...       ...\n",
       "  43  -0.440 -1.775671\n",
       "  44  -2.000 -1.950417\n",
       "  45  -2.550 -2.088354\n",
       "  46  -1.990 -1.644164\n",
       "  47  -3.083 -2.796880\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 7.512328386306763,\n",
       "  'mean_mse': 0.6040727496147156,\n",
       "  'mean_l1': 0.5731423199176788,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -0.400 -0.528387\n",
       "  1    0.610  0.100117\n",
       "  2   -2.218 -3.276770\n",
       "  3   -0.440 -1.328222\n",
       "  4    0.540 -1.132915\n",
       "  ..     ...       ...\n",
       "  43  -4.920 -1.725795\n",
       "  44  -6.560 -5.010386\n",
       "  45  -4.173 -3.893045\n",
       "  46  -3.140 -1.999669\n",
       "  47  -6.780 -5.909285\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 7.047102928161621,\n",
       "  'mean_mse': 1.4165536165237427,\n",
       "  'mean_l1': 0.9103942513465881,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.290 -1.319713\n",
       "  1   -1.458 -1.181614\n",
       "  2   -0.030 -0.073313\n",
       "  3   -2.080 -2.644422\n",
       "  4   -7.420 -8.542537\n",
       "  ..     ...       ...\n",
       "  43   0.620  0.353544\n",
       "  44   0.260 -0.168072\n",
       "  45  -1.640 -1.468209\n",
       "  46  -0.180 -0.990765\n",
       "  47  -5.115 -7.665402\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 14.180083274841309,\n",
       "  'mean_mse': 0.6348430514335632,\n",
       "  'mean_l1': 0.5856092870235443,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.820 -1.827285\n",
       "  1   -5.915 -5.109882\n",
       "  2   -3.927 -2.660858\n",
       "  3   -0.400 -0.500851\n",
       "  4   -5.233 -4.654943\n",
       "  ..     ...       ...\n",
       "  43  -9.160 -7.348979\n",
       "  44   0.430  0.044699\n",
       "  45  -7.200 -4.527989\n",
       "  46  -4.280 -4.306958\n",
       "  47  -2.550 -1.640878\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 13.345868349075317,\n",
       "  'mean_mse': 1.4895380139350891,\n",
       "  'mean_l1': 0.9159064888954163,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.290 -1.787197\n",
       "  1   -3.630 -3.771388\n",
       "  2    0.620 -0.495275\n",
       "  3   -3.460 -3.706933\n",
       "  4   -1.360 -1.270734\n",
       "  ..     ...       ...\n",
       "  43  -2.280 -2.158246\n",
       "  44  -2.218 -4.446402\n",
       "  45  -5.115 -7.924999\n",
       "  46  -1.870 -1.829086\n",
       "  47  -0.720 -0.746887\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 6.199399471282959,\n",
       "  'mean_mse': 0.694950744509697,\n",
       "  'mean_l1': 0.6063278019428253,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -7.200 -3.857754\n",
       "  1   -5.915 -4.390695\n",
       "  2   -3.140 -1.994398\n",
       "  3   -1.228 -1.612968\n",
       "  4   -7.850 -7.841713\n",
       "  ..     ...       ...\n",
       "  43  -4.173 -3.469095\n",
       "  44  -2.840 -5.103529\n",
       "  45  -2.770 -2.722328\n",
       "  46  -3.927 -2.439160\n",
       "  47  -3.796 -4.238505\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 22.543865442276,\n",
       "  'mean_mse': 1.3016017079353333,\n",
       "  'mean_l1': 0.8571366965770721,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.460 -2.964310\n",
       "  1   -0.180 -0.931039\n",
       "  2   -2.820 -2.253083\n",
       "  3   -0.360 -1.634467\n",
       "  4   -1.520 -2.597887\n",
       "  ..     ...       ...\n",
       "  43  -5.115 -5.315798\n",
       "  44  -2.780 -2.868772\n",
       "  45  -3.300 -1.613347\n",
       "  46  -2.380 -2.760046\n",
       "  47  -1.520 -1.126348\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 15.473598957061768,\n",
       "  'mean_mse': 1.4786245822906494,\n",
       "  'mean_l1': 0.85970738530159,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.210 -3.098821\n",
       "  1   -1.520 -2.594952\n",
       "  2   -1.614 -1.376230\n",
       "  3   -2.730 -3.580375\n",
       "  4   -6.291 -5.980849\n",
       "  ..     ...       ...\n",
       "  43  -0.030 -0.485857\n",
       "  44  -1.360 -1.379822\n",
       "  45  -4.370 -4.600762\n",
       "  46  -0.040  0.226304\n",
       "  47  -1.458 -1.281738\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 8.698818683624268,\n",
       "  'mean_mse': 0.6726668179035187,\n",
       "  'mean_l1': 0.6066436767578125,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -0.220 -0.871757\n",
       "  1   -2.630 -2.973874\n",
       "  2   -0.180 -1.126456\n",
       "  3   -5.233 -3.779290\n",
       "  4   -5.240 -4.254099\n",
       "  ..     ...       ...\n",
       "  43  -3.450 -4.260020\n",
       "  44   0.620 -0.399606\n",
       "  45  -2.840 -4.397289\n",
       "  46  -4.380 -3.673467\n",
       "  47  -4.799 -3.536501\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 5.509771108627319,\n",
       "  'mean_mse': 1.4605807662010193,\n",
       "  'mean_l1': 0.9566801190376282,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.218 -4.152327\n",
       "  1   -4.920 -2.845460\n",
       "  2    0.610 -0.257703\n",
       "  3   -1.820 -1.079302\n",
       "  4   -6.291 -5.759284\n",
       "  ..     ...       ...\n",
       "  43  -3.900 -3.082974\n",
       "  44  -4.310 -3.897829\n",
       "  45  -0.180 -1.084932\n",
       "  46   0.009 -0.292535\n",
       "  47  -1.060 -1.122548\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 7.175679922103882,\n",
       "  'mean_mse': 0.6781250238418579,\n",
       "  'mean_l1': 0.6356991827487946,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    -5.40 -4.875618\n",
       "  1    -1.52 -1.626620\n",
       "  2    -0.22 -0.383120\n",
       "  3    -9.16 -6.225023\n",
       "  4    -1.22 -1.377254\n",
       "  ..     ...       ...\n",
       "  43   -0.36 -1.935526\n",
       "  44    0.62  0.352384\n",
       "  45   -1.29 -1.551468\n",
       "  46   -0.18 -1.110882\n",
       "  47   -1.87 -1.689513\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 6.31003212928772,\n",
       "  'mean_mse': 1.2762787342071533,\n",
       "  'mean_l1': 0.8583175241947174,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.115 -7.695048\n",
       "  1   -1.340 -1.818029\n",
       "  2    0.540 -0.145208\n",
       "  3   -4.110 -3.391132\n",
       "  4   -3.630 -3.623802\n",
       "  ..     ...       ...\n",
       "  43  -4.173 -4.145587\n",
       "  44  -2.218 -4.503489\n",
       "  45  -7.200 -6.429135\n",
       "  46  -3.796 -3.460693\n",
       "  47  -2.550 -1.798874\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 14.911616563796997,\n",
       "  'mean_mse': 0.6797290742397308,\n",
       "  'mean_l1': 0.6067773699760437,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -7.420 -9.159292\n",
       "  1   -3.510 -4.109252\n",
       "  2   -0.040  0.300402\n",
       "  3   -2.730 -2.354733\n",
       "  4    0.790 -0.493420\n",
       "  ..     ...       ...\n",
       "  43  -3.100 -1.499681\n",
       "  44  -0.807 -3.352306\n",
       "  45   0.580 -0.110255\n",
       "  46  -4.920 -1.805182\n",
       "  47  -7.850 -7.748081\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 9.518203735351562,\n",
       "  'mean_mse': 1.4439364075660706,\n",
       "  'mean_l1': 0.9197531938552856,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    0.610 -0.155781\n",
       "  1   -4.370 -3.965582\n",
       "  2    0.522 -0.410638\n",
       "  3   -2.676 -2.505637\n",
       "  4   -6.780 -7.771506\n",
       "  ..     ...       ...\n",
       "  43  -3.928 -3.382217\n",
       "  44  -0.400 -0.362273\n",
       "  45  -2.000 -1.895375\n",
       "  46  -8.400 -7.621054\n",
       "  47  -0.390 -0.677791\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 11.884535074234009,\n",
       "  'mean_mse': 0.6922793388366699,\n",
       "  'mean_l1': 0.6125904619693756,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.370 -2.229917\n",
       "  1   -2.850 -2.094315\n",
       "  2   -3.400 -2.117125\n",
       "  3   -2.210 -2.444512\n",
       "  4   -0.440 -1.289579\n",
       "  ..     ...       ...\n",
       "  43  -4.380 -3.432925\n",
       "  44  -1.820 -1.766640\n",
       "  45  -5.915 -5.175339\n",
       "  46  -0.040 -0.407320\n",
       "  47   0.580 -0.507423\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 17.774532079696655,\n",
       "  'mean_mse': 1.2775604724884033,\n",
       "  'mean_l1': 0.8496409058570862,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    -3.01 -2.673361\n",
       "  1    -1.22 -1.283225\n",
       "  2    -7.42 -8.461515\n",
       "  3    -3.22 -3.743826\n",
       "  4    -9.16 -9.892431\n",
       "  ..     ...       ...\n",
       "  43   -1.64 -1.807939\n",
       "  44   -2.21 -3.010315\n",
       "  45   -1.06 -1.140097\n",
       "  46   -0.40 -0.649496\n",
       "  47   -2.37 -1.927763\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 8.069670915603638,\n",
       "  'mean_mse': 0.7196527123451233,\n",
       "  'mean_l1': 0.6548291742801666,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.900 -2.948136\n",
       "  1   -2.550 -1.923324\n",
       "  2   -7.420 -9.276126\n",
       "  3   -5.115 -7.333357\n",
       "  4   -3.010 -3.034022\n",
       "  ..     ...       ...\n",
       "  43  -0.440 -1.387944\n",
       "  44  -0.030 -0.711756\n",
       "  45  -3.140 -2.224193\n",
       "  46  -5.030 -5.000781\n",
       "  47  -5.840 -6.215444\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 11.990288734436035,\n",
       "  'mean_mse': 1.3362504243850708,\n",
       "  'mean_l1': 0.8795588314533234,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.340 -1.378170\n",
       "  1   -2.560 -1.209731\n",
       "  2   -3.010 -3.181670\n",
       "  3   -4.280 -3.331141\n",
       "  4   -1.060 -1.149539\n",
       "  ..     ...       ...\n",
       "  43  -0.040 -0.491448\n",
       "  44  -0.030 -0.697158\n",
       "  45   0.522 -0.660255\n",
       "  46  -3.400 -2.775477\n",
       "  47  -6.250 -6.306321\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 4.664785861968994,\n",
       "  'mean_mse': 0.5555806905031204,\n",
       "  'mean_l1': 0.5778200030326843,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.010 -2.944349\n",
       "  1   -1.640 -1.688064\n",
       "  2   -5.507 -4.738547\n",
       "  3   -0.720 -1.826699\n",
       "  4    0.610  0.038405\n",
       "  ..     ...       ...\n",
       "  43   0.620  0.230466\n",
       "  44  -3.928 -2.797405\n",
       "  45   0.510 -0.605239\n",
       "  46  -4.280 -3.370877\n",
       "  47  -4.380 -4.859919\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 8.68287467956543,\n",
       "  'mean_mse': 0.6877357363700867,\n",
       "  'mean_l1': 0.6340806484222412,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    0.620  0.423968\n",
       "  1    0.540 -1.024496\n",
       "  2   -1.947 -0.370042\n",
       "  3   -1.060 -1.139354\n",
       "  4   -9.160 -6.548893\n",
       "  ..     ...       ...\n",
       "  43  -1.990 -1.386986\n",
       "  44  -2.780 -2.736712\n",
       "  45  -7.420 -8.544152\n",
       "  46  -4.280 -4.012712\n",
       "  47  -3.450 -3.464267\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 6.523391485214233,\n",
       "  'mean_mse': 1.1794424057006836,\n",
       "  'mean_l1': 0.8218907117843628,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -0.400 -0.230855\n",
       "  1   -0.030 -0.074999\n",
       "  2   -6.291 -5.743638\n",
       "  3    0.580 -0.343738\n",
       "  4   -2.770 -2.642245\n",
       "  ..     ...       ...\n",
       "  43  -2.218 -3.817575\n",
       "  44  -0.180 -1.195167\n",
       "  45   0.540 -0.291929\n",
       "  46  -4.630 -4.095340\n",
       "  47   0.510 -0.469028\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 7.382987976074219,\n",
       "  'mean_mse': 0.6956021785736084,\n",
       "  'mean_l1': 0.6086272299289703,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.080 -2.700986\n",
       "  1    0.430  0.281239\n",
       "  2   -0.220 -0.011597\n",
       "  3   -0.360 -1.298438\n",
       "  4    0.610 -0.013415\n",
       "  ..     ...       ...\n",
       "  43  -4.380 -3.144546\n",
       "  44  -2.210 -2.307661\n",
       "  45  -1.989 -3.023508\n",
       "  46  -6.291 -6.458953\n",
       "  47   0.510 -0.112460\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 12.357826232910156,\n",
       "  'mean_mse': 1.3391625881195068,\n",
       "  'mean_l1': 0.8623085916042328,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    0.790 -0.004218\n",
       "  1   -2.676 -2.622078\n",
       "  2   -2.420 -2.612373\n",
       "  3   -3.796 -3.733839\n",
       "  4   -2.370 -2.046178\n",
       "  ..     ...       ...\n",
       "  43  -3.927 -3.142405\n",
       "  44  -4.630 -5.347077\n",
       "  45  -5.233 -4.918328\n",
       "  46  -0.390  0.069975\n",
       "  47  -6.291 -6.174394\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 5.869471073150635,\n",
       "  'mean_mse': 1.374637246131897,\n",
       "  'mean_l1': 0.830629289150238,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.240 -4.467093\n",
       "  1    1.100 -0.197673\n",
       "  2    0.009 -0.118682\n",
       "  3   -1.110 -0.574400\n",
       "  4   -0.220 -0.792297\n",
       "  ..     ...       ...\n",
       "  43   0.790  0.419839\n",
       "  44  -1.640 -1.555670\n",
       "  45  -1.614 -1.715103\n",
       "  46   0.260 -0.100907\n",
       "  47  -1.220 -0.732389\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 5.624703884124756,\n",
       "  'mean_mse': 0.5773437321186066,\n",
       "  'mean_l1': 0.5909954607486725,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.796 -4.006439\n",
       "  1   -1.060 -0.853413\n",
       "  2   -2.370 -2.147956\n",
       "  3   -2.280 -2.616104\n",
       "  4   -5.233 -5.005042\n",
       "  ..     ...       ...\n",
       "  43  -3.010 -3.863481\n",
       "  44  -6.291 -5.932862\n",
       "  45  -6.560 -5.305884\n",
       "  46  -2.550 -2.131350\n",
       "  47  -3.400 -3.737539\n",
       "  \n",
       "  [112 rows x 2 columns],\n",
       "  'el_time': 19.75256848335266,\n",
       "  'mean_mse': 1.556464672088623,\n",
       "  'mean_l1': 0.8520574569702148,\n",
       "  'apply_scaffold_split': False,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = file1_load[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_df':     y_real    y_pred\n",
       " 0    0.260 -0.217934\n",
       " 1   -2.730 -3.277978\n",
       " 2   -1.989 -2.744406\n",
       " 3   -4.630 -4.869869\n",
       " 4   -9.160 -9.300808\n",
       " ..     ...       ...\n",
       " 43  -0.807 -1.706972\n",
       " 44  -7.200 -6.482987\n",
       " 45  -1.520 -1.575114\n",
       " 46  -7.850 -7.854436\n",
       " 47  -3.220 -3.911534\n",
       " \n",
       " [112 rows x 2 columns],\n",
       " 'el_time': 6.929111003875732,\n",
       " 'mean_mse': 0.5684865117073059,\n",
       " 'mean_l1': 0.5806424021720886,\n",
       " 'apply_scaffold_split': False,\n",
       " 'radius': 1,\n",
       " 'fpSize': 1024,\n",
       " 'linear_layers': [2048],\n",
       " 'create_count_fp': True,\n",
       " 'apply_random_aggregations': False,\n",
       " 'learning_rate': 0.001,\n",
       " 'model_type': 'GNN',\n",
       " 'model': FPN(\n",
       "   (nns): ModuleList(\n",
       "     (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "   )\n",
       "   (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "   (relu): ReLU()\n",
       " )}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_real</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.217934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.730</td>\n",
       "      <td>-3.277978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.989</td>\n",
       "      <td>-2.744406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.630</td>\n",
       "      <td>-4.869869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.160</td>\n",
       "      <td>-9.300808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.807</td>\n",
       "      <td>-1.706972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-7.200</td>\n",
       "      <td>-6.482987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1.520</td>\n",
       "      <td>-1.575114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-7.850</td>\n",
       "      <td>-7.854436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-3.220</td>\n",
       "      <td>-3.911534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_real    y_pred\n",
       "0    0.260 -0.217934\n",
       "1   -2.730 -3.277978\n",
       "2   -1.989 -2.744406\n",
       "3   -4.630 -4.869869\n",
       "4   -9.160 -9.300808\n",
       "..     ...       ...\n",
       "43  -0.807 -1.706972\n",
       "44  -7.200 -6.482987\n",
       "45  -1.520 -1.575114\n",
       "46  -7.850 -7.854436\n",
       "47  -3.220 -3.911534\n",
       "\n",
       "[112 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff[\"pred_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_df':     y_real    y_pred\n",
       " 0    0.260 -0.217934\n",
       " 1   -2.730 -3.277978\n",
       " 2   -1.989 -2.744406\n",
       " 3   -4.630 -4.869869\n",
       " 4   -9.160 -9.300808\n",
       " ..     ...       ...\n",
       " 43  -0.807 -1.706972\n",
       " 44  -7.200 -6.482987\n",
       " 45  -1.520 -1.575114\n",
       " 46  -7.850 -7.854436\n",
       " 47  -3.220 -3.911534\n",
       " \n",
       " [112 rows x 2 columns],\n",
       " 'el_time': 6.929111003875732,\n",
       " 'mean_mse': 0.5684865117073059,\n",
       " 'mean_l1': 0.5806424021720886,\n",
       " 'apply_scaffold_split': False,\n",
       " 'radius': 1,\n",
       " 'fpSize': 1024,\n",
       " 'linear_layers': [2048],\n",
       " 'create_count_fp': True,\n",
       " 'apply_random_aggregations': False,\n",
       " 'learning_rate': 0.001,\n",
       " 'model_type': 'GNN',\n",
       " 'model': FPN(\n",
       "   (nns): ModuleList(\n",
       "     (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "   )\n",
       "   (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "   (relu): ReLU()\n",
       " )}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_extract = ['create_count_fp', 'radius', 'fpSize', 'linear_layers']\n",
    "\n",
    "plot1 = []\n",
    "for run in file1_load:\n",
    "    lossvalue_mse = run[\"mean_mse\"]\n",
    "    lossvalue_l1 = run[\"mean_l1\"]\n",
    "    \n",
    "    extracted_dict = {key: run[key] for key in keys_to_extract if key in run}\n",
    "    extracted_dict[\"lossvalue_mse\"] = lossvalue_mse\n",
    "    extracted_dict[\"lossvalue_l1\"] = lossvalue_l1\n",
    "    df = pd.DataFrame([extracted_dict])\n",
    "    #plot1.append([lossvalue, df])\n",
    "    plot1.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    1024        [2048]       0.568487      0.580642,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    1024        [2048]       1.354976      0.816416,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       1    2048  [2048, 1024, 512]       0.530182   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.523892  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       1    2048  [2048, 1024, 512]       1.382521   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.823671  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    2048   [1024, 512]       0.531188      0.535167,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    2048   [1024, 512]       1.427617      0.847966,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    2048        [1024]       0.557581      0.565035,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    2048        [1024]       1.504728      0.842281,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    1024        [2048]       0.675572      0.620473,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    1024        [2048]       1.494246      0.866079,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       2    1024  [2048, 1024, 512]       0.539074   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.559654  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       2    1024  [2048, 1024, 512]        1.50505   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.903565  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       1    1024  [2048, 1024, 512]       0.478254   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.501617  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    1024   [1024, 512]       0.530102      0.535947,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    1024   [1024, 512]       1.731187      0.915159,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    1024        [1024]       0.610586      0.600411,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    1024        [1024]       1.524728      0.878531,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    2048        [2048]       0.650051        0.6292,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    2048        [2048]       1.344767      0.819479,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       2    2048  [2048, 1024, 512]       0.573778   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.563497  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       2    2048  [2048, 1024, 512]       1.421421   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0       0.85911  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    2048   [1024, 512]       0.552337      0.557624,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    2048   [1024, 512]       1.473205      0.896124,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       1    1024  [2048, 1024, 512]       1.463869   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.882603  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    2048        [1024]       0.733251      0.661603,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    2048        [1024]       1.529187      0.859943,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    1024        [2048]       0.734158      0.633665,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    1024        [2048]       1.627537      0.949485,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       3    1024  [2048, 1024, 512]       0.688685   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.637009  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       3    1024  [2048, 1024, 512]       1.352703   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.888225  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    1024   [1024, 512]       0.658149      0.615426,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    1024   [1024, 512]       1.435689      0.896555,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    1024        [1024]       0.745924      0.637766,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    1024        [1024]       1.649663       0.96187,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    1024   [1024, 512]       0.451409      0.485909,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    2048        [2048]       0.813891      0.685996,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    2048        [2048]       1.397618      0.897816,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       3    2048  [2048, 1024, 512]       0.664075   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.601183  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       3    2048  [2048, 1024, 512]       1.489464   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.932669  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    2048   [1024, 512]       0.604073      0.573142,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    2048   [1024, 512]       1.416554      0.910394,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    2048        [1024]       0.634843      0.585609,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    2048        [1024]       1.489538      0.915906,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    1024        [2048]       0.694951      0.606328,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    1024        [2048]       1.301602      0.857137,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    1024   [1024, 512]       1.478625      0.859707,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       4    1024  [2048, 1024, 512]       0.672667   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.606644  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       4    1024  [2048, 1024, 512]       1.460581   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0       0.95668  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    1024   [1024, 512]       0.678125      0.635699,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    1024   [1024, 512]       1.276279      0.858318,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    1024        [1024]       0.679729      0.606777,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    1024        [1024]       1.443936      0.919753,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    2048        [2048]       0.692279       0.61259,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    2048        [2048]        1.27756      0.849641,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       4    2048  [2048, 1024, 512]       0.719653   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.654829  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       4    2048  [2048, 1024, 512]        1.33625   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.879559  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    1024        [1024]       0.555581       0.57782,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    2048   [1024, 512]       0.687736      0.634081,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    2048   [1024, 512]       1.179442      0.821891,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    2048        [1024]       0.695602      0.608627,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    2048        [1024]       1.339163      0.862309,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    1024        [1024]       1.374637      0.830629,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    2048        [2048]       0.577344      0.590995,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    2048        [2048]       1.556465      0.852057]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_count_fp</th>\n",
       "      <th>radius</th>\n",
       "      <th>fpSize</th>\n",
       "      <th>linear_layers</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.531188</td>\n",
       "      <td>0.535167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       "0             True       1    2048   [1024, 512]       0.531188      0.535167"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot1[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullplot1 = pd.concat(plot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_count_fp</th>\n",
       "      <th>radius</th>\n",
       "      <th>fpSize</th>\n",
       "      <th>linear_layers</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.568487</td>\n",
       "      <td>0.580642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.354976</td>\n",
       "      <td>0.816416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.530182</td>\n",
       "      <td>0.523892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.382521</td>\n",
       "      <td>0.823671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.531188</td>\n",
       "      <td>0.535167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.695602</td>\n",
       "      <td>0.608627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.339163</td>\n",
       "      <td>0.862309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.374637</td>\n",
       "      <td>0.830629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.577344</td>\n",
       "      <td>0.590995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.556465</td>\n",
       "      <td>0.852057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       "0              True       1    1024             [2048]       0.568487   \n",
       "0             False       1    1024             [2048]       1.354976   \n",
       "0              True       1    2048  [2048, 1024, 512]       0.530182   \n",
       "0             False       1    2048  [2048, 1024, 512]       1.382521   \n",
       "0              True       1    2048        [1024, 512]       0.531188   \n",
       "..              ...     ...     ...                ...            ...   \n",
       "0              True       4    2048             [1024]       0.695602   \n",
       "0             False       4    2048             [1024]       1.339163   \n",
       "0             False       1    1024             [1024]       1.374637   \n",
       "0              True       1    2048             [2048]       0.577344   \n",
       "0             False       1    2048             [2048]       1.556465   \n",
       "\n",
       "    lossvalue_l1  \n",
       "0       0.580642  \n",
       "0       0.816416  \n",
       "0       0.523892  \n",
       "0       0.823671  \n",
       "0       0.535167  \n",
       "..           ...  \n",
       "0       0.608627  \n",
       "0       0.862309  \n",
       "0       0.830629  \n",
       "0       0.590995  \n",
       "0       0.852057  \n",
       "\n",
       "[64 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullplot1['linear_sizes'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullplot1['aggregations'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_count_fp</th>\n",
       "      <th>radius</th>\n",
       "      <th>fpSize</th>\n",
       "      <th>linear_layers</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.580642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.816416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.523892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.823671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.535167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.608627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.862309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.830629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.590995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.852057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_l1\n",
       "0              True       1    1024             [2048]      0.580642\n",
       "0             False       1    1024             [2048]      0.816416\n",
       "0              True       1    2048  [2048, 1024, 512]      0.523892\n",
       "0             False       1    2048  [2048, 1024, 512]      0.823671\n",
       "0              True       1    2048        [1024, 512]      0.535167\n",
       "..              ...     ...     ...                ...           ...\n",
       "0              True       4    2048             [1024]      0.608627\n",
       "0             False       4    2048             [1024]      0.862309\n",
       "0             False       1    1024             [1024]      0.830629\n",
       "0              True       1    2048             [2048]      0.590995\n",
       "0             False       1    2048             [2048]      0.852057\n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1.drop(columns=\"lossvalue_mse\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.568487\n",
       "0    1.354976\n",
       "0    0.530182\n",
       "0    1.382521\n",
       "0    0.531188\n",
       "       ...   \n",
       "0    0.695602\n",
       "0    1.339163\n",
       "0    1.374637\n",
       "0    0.577344\n",
       "0    1.556465\n",
       "Name: lossvalue_mse, Length: 64, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1[\"lossvalue_mse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullplot1['Combined Label'] = fullplot1.drop(columns=[\"lossvalue_mse\", \"lossvalue_l1\"], axis=1).astype(str).agg(' - '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_count_fp</th>\n",
       "      <th>radius</th>\n",
       "      <th>fpSize</th>\n",
       "      <th>linear_layers</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "      <th>Combined Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.451409</td>\n",
       "      <td>0.485909</td>\n",
       "      <td>True - 1 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.478254</td>\n",
       "      <td>0.501617</td>\n",
       "      <td>True - 1 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.530102</td>\n",
       "      <td>0.535947</td>\n",
       "      <td>True - 2 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.530182</td>\n",
       "      <td>0.523892</td>\n",
       "      <td>True - 1 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.531188</td>\n",
       "      <td>0.535167</td>\n",
       "      <td>True - 1 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.539074</td>\n",
       "      <td>0.559654</td>\n",
       "      <td>True - 2 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.552337</td>\n",
       "      <td>0.557624</td>\n",
       "      <td>True - 2 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.555581</td>\n",
       "      <td>0.577820</td>\n",
       "      <td>True - 1 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.557581</td>\n",
       "      <td>0.565035</td>\n",
       "      <td>True - 1 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.568487</td>\n",
       "      <td>0.580642</td>\n",
       "      <td>True - 1 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.573778</td>\n",
       "      <td>0.563497</td>\n",
       "      <td>True - 2 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.577344</td>\n",
       "      <td>0.590995</td>\n",
       "      <td>True - 1 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.604073</td>\n",
       "      <td>0.573142</td>\n",
       "      <td>True - 3 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.610586</td>\n",
       "      <td>0.600411</td>\n",
       "      <td>True - 2 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.634843</td>\n",
       "      <td>0.585609</td>\n",
       "      <td>True - 3 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.650051</td>\n",
       "      <td>0.629200</td>\n",
       "      <td>True - 2 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>0.615426</td>\n",
       "      <td>True - 3 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.664075</td>\n",
       "      <td>0.601183</td>\n",
       "      <td>True - 3 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.672667</td>\n",
       "      <td>0.606644</td>\n",
       "      <td>True - 4 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.675572</td>\n",
       "      <td>0.620473</td>\n",
       "      <td>True - 2 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.678125</td>\n",
       "      <td>0.635699</td>\n",
       "      <td>True - 4 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.679729</td>\n",
       "      <td>0.606777</td>\n",
       "      <td>True - 4 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.687736</td>\n",
       "      <td>0.634081</td>\n",
       "      <td>True - 4 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.688685</td>\n",
       "      <td>0.637009</td>\n",
       "      <td>True - 3 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.692279</td>\n",
       "      <td>0.612590</td>\n",
       "      <td>True - 4 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.694951</td>\n",
       "      <td>0.606328</td>\n",
       "      <td>True - 4 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.695602</td>\n",
       "      <td>0.608627</td>\n",
       "      <td>True - 4 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.719653</td>\n",
       "      <td>0.654829</td>\n",
       "      <td>True - 4 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.733251</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>True - 2 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.734158</td>\n",
       "      <td>0.633665</td>\n",
       "      <td>True - 3 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.745924</td>\n",
       "      <td>0.637766</td>\n",
       "      <td>True - 3 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.813891</td>\n",
       "      <td>0.685996</td>\n",
       "      <td>True - 3 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.179442</td>\n",
       "      <td>0.821891</td>\n",
       "      <td>False - 4 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.276279</td>\n",
       "      <td>0.858318</td>\n",
       "      <td>False - 4 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.277560</td>\n",
       "      <td>0.849641</td>\n",
       "      <td>False - 4 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.301602</td>\n",
       "      <td>0.857137</td>\n",
       "      <td>False - 4 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.336250</td>\n",
       "      <td>0.879559</td>\n",
       "      <td>False - 4 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.339163</td>\n",
       "      <td>0.862309</td>\n",
       "      <td>False - 4 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.344767</td>\n",
       "      <td>0.819479</td>\n",
       "      <td>False - 2 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.352703</td>\n",
       "      <td>0.888225</td>\n",
       "      <td>False - 3 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.354976</td>\n",
       "      <td>0.816416</td>\n",
       "      <td>False - 1 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.374637</td>\n",
       "      <td>0.830629</td>\n",
       "      <td>False - 1 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.382521</td>\n",
       "      <td>0.823671</td>\n",
       "      <td>False - 1 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.397618</td>\n",
       "      <td>0.897816</td>\n",
       "      <td>False - 3 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.416554</td>\n",
       "      <td>0.910394</td>\n",
       "      <td>False - 3 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.421421</td>\n",
       "      <td>0.859110</td>\n",
       "      <td>False - 2 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.427617</td>\n",
       "      <td>0.847966</td>\n",
       "      <td>False - 1 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.435689</td>\n",
       "      <td>0.896555</td>\n",
       "      <td>False - 3 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.443936</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>False - 4 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.460581</td>\n",
       "      <td>0.956680</td>\n",
       "      <td>False - 4 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.463869</td>\n",
       "      <td>0.882603</td>\n",
       "      <td>False - 1 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.473205</td>\n",
       "      <td>0.896124</td>\n",
       "      <td>False - 2 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.478625</td>\n",
       "      <td>0.859707</td>\n",
       "      <td>False - 1 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.489464</td>\n",
       "      <td>0.932669</td>\n",
       "      <td>False - 3 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.489538</td>\n",
       "      <td>0.915906</td>\n",
       "      <td>False - 3 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.494246</td>\n",
       "      <td>0.866079</td>\n",
       "      <td>False - 2 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.504728</td>\n",
       "      <td>0.842281</td>\n",
       "      <td>False - 1 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.505050</td>\n",
       "      <td>0.903565</td>\n",
       "      <td>False - 2 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.524728</td>\n",
       "      <td>0.878531</td>\n",
       "      <td>False - 2 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.529187</td>\n",
       "      <td>0.859943</td>\n",
       "      <td>False - 2 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.556465</td>\n",
       "      <td>0.852057</td>\n",
       "      <td>False - 1 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.627537</td>\n",
       "      <td>0.949485</td>\n",
       "      <td>False - 3 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.649663</td>\n",
       "      <td>0.961870</td>\n",
       "      <td>False - 3 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.731187</td>\n",
       "      <td>0.915159</td>\n",
       "      <td>False - 2 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       "0             True       1    1024        [1024, 512]       0.451409   \n",
       "0             True       1    1024  [2048, 1024, 512]       0.478254   \n",
       "0             True       2    1024        [1024, 512]       0.530102   \n",
       "0             True       1    2048  [2048, 1024, 512]       0.530182   \n",
       "0             True       1    2048        [1024, 512]       0.531188   \n",
       "0             True       2    1024  [2048, 1024, 512]       0.539074   \n",
       "0             True       2    2048        [1024, 512]       0.552337   \n",
       "0             True       1    1024             [1024]       0.555581   \n",
       "0             True       1    2048             [1024]       0.557581   \n",
       "0             True       1    1024             [2048]       0.568487   \n",
       "0             True       2    2048  [2048, 1024, 512]       0.573778   \n",
       "0             True       1    2048             [2048]       0.577344   \n",
       "0             True       3    2048        [1024, 512]       0.604073   \n",
       "0             True       2    1024             [1024]       0.610586   \n",
       "0             True       3    2048             [1024]       0.634843   \n",
       "0             True       2    2048             [2048]       0.650051   \n",
       "0             True       3    1024        [1024, 512]       0.658149   \n",
       "0             True       3    2048  [2048, 1024, 512]       0.664075   \n",
       "0             True       4    1024  [2048, 1024, 512]       0.672667   \n",
       "0             True       2    1024             [2048]       0.675572   \n",
       "0             True       4    1024        [1024, 512]       0.678125   \n",
       "0             True       4    1024             [1024]       0.679729   \n",
       "0             True       4    2048        [1024, 512]       0.687736   \n",
       "0             True       3    1024  [2048, 1024, 512]       0.688685   \n",
       "0             True       4    2048             [2048]       0.692279   \n",
       "0             True       4    1024             [2048]       0.694951   \n",
       "0             True       4    2048             [1024]       0.695602   \n",
       "0             True       4    2048  [2048, 1024, 512]       0.719653   \n",
       "0             True       2    2048             [1024]       0.733251   \n",
       "0             True       3    1024             [2048]       0.734158   \n",
       "0             True       3    1024             [1024]       0.745924   \n",
       "0             True       3    2048             [2048]       0.813891   \n",
       "0            False       4    2048        [1024, 512]       1.179442   \n",
       "0            False       4    1024        [1024, 512]       1.276279   \n",
       "0            False       4    2048             [2048]       1.277560   \n",
       "0            False       4    1024             [2048]       1.301602   \n",
       "0            False       4    2048  [2048, 1024, 512]       1.336250   \n",
       "0            False       4    2048             [1024]       1.339163   \n",
       "0            False       2    2048             [2048]       1.344767   \n",
       "0            False       3    1024  [2048, 1024, 512]       1.352703   \n",
       "0            False       1    1024             [2048]       1.354976   \n",
       "0            False       1    1024             [1024]       1.374637   \n",
       "0            False       1    2048  [2048, 1024, 512]       1.382521   \n",
       "0            False       3    2048             [2048]       1.397618   \n",
       "0            False       3    2048        [1024, 512]       1.416554   \n",
       "0            False       2    2048  [2048, 1024, 512]       1.421421   \n",
       "0            False       1    2048        [1024, 512]       1.427617   \n",
       "0            False       3    1024        [1024, 512]       1.435689   \n",
       "0            False       4    1024             [1024]       1.443936   \n",
       "0            False       4    1024  [2048, 1024, 512]       1.460581   \n",
       "0            False       1    1024  [2048, 1024, 512]       1.463869   \n",
       "0            False       2    2048        [1024, 512]       1.473205   \n",
       "0            False       1    1024        [1024, 512]       1.478625   \n",
       "0            False       3    2048  [2048, 1024, 512]       1.489464   \n",
       "0            False       3    2048             [1024]       1.489538   \n",
       "0            False       2    1024             [2048]       1.494246   \n",
       "0            False       1    2048             [1024]       1.504728   \n",
       "0            False       2    1024  [2048, 1024, 512]       1.505050   \n",
       "0            False       2    1024             [1024]       1.524728   \n",
       "0            False       2    2048             [1024]       1.529187   \n",
       "0            False       1    2048             [2048]       1.556465   \n",
       "0            False       3    1024             [2048]       1.627537   \n",
       "0            False       3    1024             [1024]       1.649663   \n",
       "0            False       2    1024        [1024, 512]       1.731187   \n",
       "\n",
       "   lossvalue_l1                        Combined Label  \n",
       "0      0.485909         True - 1 - 1024 - [1024, 512]  \n",
       "0      0.501617   True - 1 - 1024 - [2048, 1024, 512]  \n",
       "0      0.535947         True - 2 - 1024 - [1024, 512]  \n",
       "0      0.523892   True - 1 - 2048 - [2048, 1024, 512]  \n",
       "0      0.535167         True - 1 - 2048 - [1024, 512]  \n",
       "0      0.559654   True - 2 - 1024 - [2048, 1024, 512]  \n",
       "0      0.557624         True - 2 - 2048 - [1024, 512]  \n",
       "0      0.577820              True - 1 - 1024 - [1024]  \n",
       "0      0.565035              True - 1 - 2048 - [1024]  \n",
       "0      0.580642              True - 1 - 1024 - [2048]  \n",
       "0      0.563497   True - 2 - 2048 - [2048, 1024, 512]  \n",
       "0      0.590995              True - 1 - 2048 - [2048]  \n",
       "0      0.573142         True - 3 - 2048 - [1024, 512]  \n",
       "0      0.600411              True - 2 - 1024 - [1024]  \n",
       "0      0.585609              True - 3 - 2048 - [1024]  \n",
       "0      0.629200              True - 2 - 2048 - [2048]  \n",
       "0      0.615426         True - 3 - 1024 - [1024, 512]  \n",
       "0      0.601183   True - 3 - 2048 - [2048, 1024, 512]  \n",
       "0      0.606644   True - 4 - 1024 - [2048, 1024, 512]  \n",
       "0      0.620473              True - 2 - 1024 - [2048]  \n",
       "0      0.635699         True - 4 - 1024 - [1024, 512]  \n",
       "0      0.606777              True - 4 - 1024 - [1024]  \n",
       "0      0.634081         True - 4 - 2048 - [1024, 512]  \n",
       "0      0.637009   True - 3 - 1024 - [2048, 1024, 512]  \n",
       "0      0.612590              True - 4 - 2048 - [2048]  \n",
       "0      0.606328              True - 4 - 1024 - [2048]  \n",
       "0      0.608627              True - 4 - 2048 - [1024]  \n",
       "0      0.654829   True - 4 - 2048 - [2048, 1024, 512]  \n",
       "0      0.661603              True - 2 - 2048 - [1024]  \n",
       "0      0.633665              True - 3 - 1024 - [2048]  \n",
       "0      0.637766              True - 3 - 1024 - [1024]  \n",
       "0      0.685996              True - 3 - 2048 - [2048]  \n",
       "0      0.821891        False - 4 - 2048 - [1024, 512]  \n",
       "0      0.858318        False - 4 - 1024 - [1024, 512]  \n",
       "0      0.849641             False - 4 - 2048 - [2048]  \n",
       "0      0.857137             False - 4 - 1024 - [2048]  \n",
       "0      0.879559  False - 4 - 2048 - [2048, 1024, 512]  \n",
       "0      0.862309             False - 4 - 2048 - [1024]  \n",
       "0      0.819479             False - 2 - 2048 - [2048]  \n",
       "0      0.888225  False - 3 - 1024 - [2048, 1024, 512]  \n",
       "0      0.816416             False - 1 - 1024 - [2048]  \n",
       "0      0.830629             False - 1 - 1024 - [1024]  \n",
       "0      0.823671  False - 1 - 2048 - [2048, 1024, 512]  \n",
       "0      0.897816             False - 3 - 2048 - [2048]  \n",
       "0      0.910394        False - 3 - 2048 - [1024, 512]  \n",
       "0      0.859110  False - 2 - 2048 - [2048, 1024, 512]  \n",
       "0      0.847966        False - 1 - 2048 - [1024, 512]  \n",
       "0      0.896555        False - 3 - 1024 - [1024, 512]  \n",
       "0      0.919753             False - 4 - 1024 - [1024]  \n",
       "0      0.956680  False - 4 - 1024 - [2048, 1024, 512]  \n",
       "0      0.882603  False - 1 - 1024 - [2048, 1024, 512]  \n",
       "0      0.896124        False - 2 - 2048 - [1024, 512]  \n",
       "0      0.859707        False - 1 - 1024 - [1024, 512]  \n",
       "0      0.932669  False - 3 - 2048 - [2048, 1024, 512]  \n",
       "0      0.915906             False - 3 - 2048 - [1024]  \n",
       "0      0.866079             False - 2 - 1024 - [2048]  \n",
       "0      0.842281             False - 1 - 2048 - [1024]  \n",
       "0      0.903565  False - 2 - 1024 - [2048, 1024, 512]  \n",
       "0      0.878531             False - 2 - 1024 - [1024]  \n",
       "0      0.859943             False - 2 - 2048 - [1024]  \n",
       "0      0.852057             False - 1 - 2048 - [2048]  \n",
       "0      0.949485             False - 3 - 1024 - [2048]  \n",
       "0      0.961870             False - 3 - 1024 - [1024]  \n",
       "0      0.915159        False - 2 - 1024 - [1024, 512]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1.sort_values(by=['lossvalue_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_count_fp</th>\n",
       "      <th>radius</th>\n",
       "      <th>fpSize</th>\n",
       "      <th>linear_layers</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "      <th>Combined Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.451409</td>\n",
       "      <td>0.485909</td>\n",
       "      <td>True - 1 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.478254</td>\n",
       "      <td>0.501617</td>\n",
       "      <td>True - 1 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.530182</td>\n",
       "      <td>0.523892</td>\n",
       "      <td>True - 1 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.531188</td>\n",
       "      <td>0.535167</td>\n",
       "      <td>True - 1 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.530102</td>\n",
       "      <td>0.535947</td>\n",
       "      <td>True - 2 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.552337</td>\n",
       "      <td>0.557624</td>\n",
       "      <td>True - 2 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.539074</td>\n",
       "      <td>0.559654</td>\n",
       "      <td>True - 2 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.573778</td>\n",
       "      <td>0.563497</td>\n",
       "      <td>True - 2 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.557581</td>\n",
       "      <td>0.565035</td>\n",
       "      <td>True - 1 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.604073</td>\n",
       "      <td>0.573142</td>\n",
       "      <td>True - 3 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.555581</td>\n",
       "      <td>0.577820</td>\n",
       "      <td>True - 1 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.568487</td>\n",
       "      <td>0.580642</td>\n",
       "      <td>True - 1 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.634843</td>\n",
       "      <td>0.585609</td>\n",
       "      <td>True - 3 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.577344</td>\n",
       "      <td>0.590995</td>\n",
       "      <td>True - 1 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.610586</td>\n",
       "      <td>0.600411</td>\n",
       "      <td>True - 2 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.664075</td>\n",
       "      <td>0.601183</td>\n",
       "      <td>True - 3 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.694951</td>\n",
       "      <td>0.606328</td>\n",
       "      <td>True - 4 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.672667</td>\n",
       "      <td>0.606644</td>\n",
       "      <td>True - 4 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.679729</td>\n",
       "      <td>0.606777</td>\n",
       "      <td>True - 4 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.695602</td>\n",
       "      <td>0.608627</td>\n",
       "      <td>True - 4 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.692279</td>\n",
       "      <td>0.612590</td>\n",
       "      <td>True - 4 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>0.615426</td>\n",
       "      <td>True - 3 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.675572</td>\n",
       "      <td>0.620473</td>\n",
       "      <td>True - 2 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.650051</td>\n",
       "      <td>0.629200</td>\n",
       "      <td>True - 2 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.734158</td>\n",
       "      <td>0.633665</td>\n",
       "      <td>True - 3 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.687736</td>\n",
       "      <td>0.634081</td>\n",
       "      <td>True - 4 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.678125</td>\n",
       "      <td>0.635699</td>\n",
       "      <td>True - 4 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.688685</td>\n",
       "      <td>0.637009</td>\n",
       "      <td>True - 3 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.745924</td>\n",
       "      <td>0.637766</td>\n",
       "      <td>True - 3 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.719653</td>\n",
       "      <td>0.654829</td>\n",
       "      <td>True - 4 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.733251</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>True - 2 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.813891</td>\n",
       "      <td>0.685996</td>\n",
       "      <td>True - 3 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.354976</td>\n",
       "      <td>0.816416</td>\n",
       "      <td>False - 1 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.344767</td>\n",
       "      <td>0.819479</td>\n",
       "      <td>False - 2 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.179442</td>\n",
       "      <td>0.821891</td>\n",
       "      <td>False - 4 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.382521</td>\n",
       "      <td>0.823671</td>\n",
       "      <td>False - 1 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.374637</td>\n",
       "      <td>0.830629</td>\n",
       "      <td>False - 1 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.504728</td>\n",
       "      <td>0.842281</td>\n",
       "      <td>False - 1 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.427617</td>\n",
       "      <td>0.847966</td>\n",
       "      <td>False - 1 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.277560</td>\n",
       "      <td>0.849641</td>\n",
       "      <td>False - 4 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.556465</td>\n",
       "      <td>0.852057</td>\n",
       "      <td>False - 1 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.301602</td>\n",
       "      <td>0.857137</td>\n",
       "      <td>False - 4 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.276279</td>\n",
       "      <td>0.858318</td>\n",
       "      <td>False - 4 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.421421</td>\n",
       "      <td>0.859110</td>\n",
       "      <td>False - 2 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.478625</td>\n",
       "      <td>0.859707</td>\n",
       "      <td>False - 1 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.529187</td>\n",
       "      <td>0.859943</td>\n",
       "      <td>False - 2 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.339163</td>\n",
       "      <td>0.862309</td>\n",
       "      <td>False - 4 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.494246</td>\n",
       "      <td>0.866079</td>\n",
       "      <td>False - 2 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.524728</td>\n",
       "      <td>0.878531</td>\n",
       "      <td>False - 2 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.336250</td>\n",
       "      <td>0.879559</td>\n",
       "      <td>False - 4 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.463869</td>\n",
       "      <td>0.882603</td>\n",
       "      <td>False - 1 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.352703</td>\n",
       "      <td>0.888225</td>\n",
       "      <td>False - 3 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.473205</td>\n",
       "      <td>0.896124</td>\n",
       "      <td>False - 2 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.435689</td>\n",
       "      <td>0.896555</td>\n",
       "      <td>False - 3 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.397618</td>\n",
       "      <td>0.897816</td>\n",
       "      <td>False - 3 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.505050</td>\n",
       "      <td>0.903565</td>\n",
       "      <td>False - 2 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.416554</td>\n",
       "      <td>0.910394</td>\n",
       "      <td>False - 3 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.731187</td>\n",
       "      <td>0.915159</td>\n",
       "      <td>False - 2 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.489538</td>\n",
       "      <td>0.915906</td>\n",
       "      <td>False - 3 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.443936</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>False - 4 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.489464</td>\n",
       "      <td>0.932669</td>\n",
       "      <td>False - 3 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.627537</td>\n",
       "      <td>0.949485</td>\n",
       "      <td>False - 3 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.460581</td>\n",
       "      <td>0.956680</td>\n",
       "      <td>False - 4 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.649663</td>\n",
       "      <td>0.961870</td>\n",
       "      <td>False - 3 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       "0             True       1    1024        [1024, 512]       0.451409   \n",
       "0             True       1    1024  [2048, 1024, 512]       0.478254   \n",
       "0             True       1    2048  [2048, 1024, 512]       0.530182   \n",
       "0             True       1    2048        [1024, 512]       0.531188   \n",
       "0             True       2    1024        [1024, 512]       0.530102   \n",
       "0             True       2    2048        [1024, 512]       0.552337   \n",
       "0             True       2    1024  [2048, 1024, 512]       0.539074   \n",
       "0             True       2    2048  [2048, 1024, 512]       0.573778   \n",
       "0             True       1    2048             [1024]       0.557581   \n",
       "0             True       3    2048        [1024, 512]       0.604073   \n",
       "0             True       1    1024             [1024]       0.555581   \n",
       "0             True       1    1024             [2048]       0.568487   \n",
       "0             True       3    2048             [1024]       0.634843   \n",
       "0             True       1    2048             [2048]       0.577344   \n",
       "0             True       2    1024             [1024]       0.610586   \n",
       "0             True       3    2048  [2048, 1024, 512]       0.664075   \n",
       "0             True       4    1024             [2048]       0.694951   \n",
       "0             True       4    1024  [2048, 1024, 512]       0.672667   \n",
       "0             True       4    1024             [1024]       0.679729   \n",
       "0             True       4    2048             [1024]       0.695602   \n",
       "0             True       4    2048             [2048]       0.692279   \n",
       "0             True       3    1024        [1024, 512]       0.658149   \n",
       "0             True       2    1024             [2048]       0.675572   \n",
       "0             True       2    2048             [2048]       0.650051   \n",
       "0             True       3    1024             [2048]       0.734158   \n",
       "0             True       4    2048        [1024, 512]       0.687736   \n",
       "0             True       4    1024        [1024, 512]       0.678125   \n",
       "0             True       3    1024  [2048, 1024, 512]       0.688685   \n",
       "0             True       3    1024             [1024]       0.745924   \n",
       "0             True       4    2048  [2048, 1024, 512]       0.719653   \n",
       "0             True       2    2048             [1024]       0.733251   \n",
       "0             True       3    2048             [2048]       0.813891   \n",
       "0            False       1    1024             [2048]       1.354976   \n",
       "0            False       2    2048             [2048]       1.344767   \n",
       "0            False       4    2048        [1024, 512]       1.179442   \n",
       "0            False       1    2048  [2048, 1024, 512]       1.382521   \n",
       "0            False       1    1024             [1024]       1.374637   \n",
       "0            False       1    2048             [1024]       1.504728   \n",
       "0            False       1    2048        [1024, 512]       1.427617   \n",
       "0            False       4    2048             [2048]       1.277560   \n",
       "0            False       1    2048             [2048]       1.556465   \n",
       "0            False       4    1024             [2048]       1.301602   \n",
       "0            False       4    1024        [1024, 512]       1.276279   \n",
       "0            False       2    2048  [2048, 1024, 512]       1.421421   \n",
       "0            False       1    1024        [1024, 512]       1.478625   \n",
       "0            False       2    2048             [1024]       1.529187   \n",
       "0            False       4    2048             [1024]       1.339163   \n",
       "0            False       2    1024             [2048]       1.494246   \n",
       "0            False       2    1024             [1024]       1.524728   \n",
       "0            False       4    2048  [2048, 1024, 512]       1.336250   \n",
       "0            False       1    1024  [2048, 1024, 512]       1.463869   \n",
       "0            False       3    1024  [2048, 1024, 512]       1.352703   \n",
       "0            False       2    2048        [1024, 512]       1.473205   \n",
       "0            False       3    1024        [1024, 512]       1.435689   \n",
       "0            False       3    2048             [2048]       1.397618   \n",
       "0            False       2    1024  [2048, 1024, 512]       1.505050   \n",
       "0            False       3    2048        [1024, 512]       1.416554   \n",
       "0            False       2    1024        [1024, 512]       1.731187   \n",
       "0            False       3    2048             [1024]       1.489538   \n",
       "0            False       4    1024             [1024]       1.443936   \n",
       "0            False       3    2048  [2048, 1024, 512]       1.489464   \n",
       "0            False       3    1024             [2048]       1.627537   \n",
       "0            False       4    1024  [2048, 1024, 512]       1.460581   \n",
       "0            False       3    1024             [1024]       1.649663   \n",
       "\n",
       "   lossvalue_l1                        Combined Label  \n",
       "0      0.485909         True - 1 - 1024 - [1024, 512]  \n",
       "0      0.501617   True - 1 - 1024 - [2048, 1024, 512]  \n",
       "0      0.523892   True - 1 - 2048 - [2048, 1024, 512]  \n",
       "0      0.535167         True - 1 - 2048 - [1024, 512]  \n",
       "0      0.535947         True - 2 - 1024 - [1024, 512]  \n",
       "0      0.557624         True - 2 - 2048 - [1024, 512]  \n",
       "0      0.559654   True - 2 - 1024 - [2048, 1024, 512]  \n",
       "0      0.563497   True - 2 - 2048 - [2048, 1024, 512]  \n",
       "0      0.565035              True - 1 - 2048 - [1024]  \n",
       "0      0.573142         True - 3 - 2048 - [1024, 512]  \n",
       "0      0.577820              True - 1 - 1024 - [1024]  \n",
       "0      0.580642              True - 1 - 1024 - [2048]  \n",
       "0      0.585609              True - 3 - 2048 - [1024]  \n",
       "0      0.590995              True - 1 - 2048 - [2048]  \n",
       "0      0.600411              True - 2 - 1024 - [1024]  \n",
       "0      0.601183   True - 3 - 2048 - [2048, 1024, 512]  \n",
       "0      0.606328              True - 4 - 1024 - [2048]  \n",
       "0      0.606644   True - 4 - 1024 - [2048, 1024, 512]  \n",
       "0      0.606777              True - 4 - 1024 - [1024]  \n",
       "0      0.608627              True - 4 - 2048 - [1024]  \n",
       "0      0.612590              True - 4 - 2048 - [2048]  \n",
       "0      0.615426         True - 3 - 1024 - [1024, 512]  \n",
       "0      0.620473              True - 2 - 1024 - [2048]  \n",
       "0      0.629200              True - 2 - 2048 - [2048]  \n",
       "0      0.633665              True - 3 - 1024 - [2048]  \n",
       "0      0.634081         True - 4 - 2048 - [1024, 512]  \n",
       "0      0.635699         True - 4 - 1024 - [1024, 512]  \n",
       "0      0.637009   True - 3 - 1024 - [2048, 1024, 512]  \n",
       "0      0.637766              True - 3 - 1024 - [1024]  \n",
       "0      0.654829   True - 4 - 2048 - [2048, 1024, 512]  \n",
       "0      0.661603              True - 2 - 2048 - [1024]  \n",
       "0      0.685996              True - 3 - 2048 - [2048]  \n",
       "0      0.816416             False - 1 - 1024 - [2048]  \n",
       "0      0.819479             False - 2 - 2048 - [2048]  \n",
       "0      0.821891        False - 4 - 2048 - [1024, 512]  \n",
       "0      0.823671  False - 1 - 2048 - [2048, 1024, 512]  \n",
       "0      0.830629             False - 1 - 1024 - [1024]  \n",
       "0      0.842281             False - 1 - 2048 - [1024]  \n",
       "0      0.847966        False - 1 - 2048 - [1024, 512]  \n",
       "0      0.849641             False - 4 - 2048 - [2048]  \n",
       "0      0.852057             False - 1 - 2048 - [2048]  \n",
       "0      0.857137             False - 4 - 1024 - [2048]  \n",
       "0      0.858318        False - 4 - 1024 - [1024, 512]  \n",
       "0      0.859110  False - 2 - 2048 - [2048, 1024, 512]  \n",
       "0      0.859707        False - 1 - 1024 - [1024, 512]  \n",
       "0      0.859943             False - 2 - 2048 - [1024]  \n",
       "0      0.862309             False - 4 - 2048 - [1024]  \n",
       "0      0.866079             False - 2 - 1024 - [2048]  \n",
       "0      0.878531             False - 2 - 1024 - [1024]  \n",
       "0      0.879559  False - 4 - 2048 - [2048, 1024, 512]  \n",
       "0      0.882603  False - 1 - 1024 - [2048, 1024, 512]  \n",
       "0      0.888225  False - 3 - 1024 - [2048, 1024, 512]  \n",
       "0      0.896124        False - 2 - 2048 - [1024, 512]  \n",
       "0      0.896555        False - 3 - 1024 - [1024, 512]  \n",
       "0      0.897816             False - 3 - 2048 - [2048]  \n",
       "0      0.903565  False - 2 - 1024 - [2048, 1024, 512]  \n",
       "0      0.910394        False - 3 - 2048 - [1024, 512]  \n",
       "0      0.915159        False - 2 - 1024 - [1024, 512]  \n",
       "0      0.915906             False - 3 - 2048 - [1024]  \n",
       "0      0.919753             False - 4 - 1024 - [1024]  \n",
       "0      0.932669  False - 3 - 2048 - [2048, 1024, 512]  \n",
       "0      0.949485             False - 3 - 1024 - [2048]  \n",
       "0      0.956680  False - 4 - 1024 - [2048, 1024, 512]  \n",
       "0      0.961870             False - 3 - 1024 - [1024]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1.sort_values(by=['lossvalue_l1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Combined Label'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fullplot1.set_index('Combined Label', inplace=True)\n",
    "\n",
    "fullplot1['lossvalue_mse'].plot(kind='bar')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newest_dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
