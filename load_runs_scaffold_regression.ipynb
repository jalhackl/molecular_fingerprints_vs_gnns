{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def list_files(directory):\n",
    "    files = []\n",
    "    for entry in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, entry)):\n",
    "            files.append(entry)\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"results_regression_scaffold_gnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_gnn_conv', 'model_gnn_conv_1', 'model_gnn_conv_10', 'model_gnn_conv_100', 'model_gnn_conv_101', 'model_gnn_conv_102', 'model_gnn_conv_103', 'model_gnn_conv_104', 'model_gnn_conv_105', 'model_gnn_conv_106', 'model_gnn_conv_107', 'model_gnn_conv_11', 'model_gnn_conv_12', 'model_gnn_conv_13', 'model_gnn_conv_14', 'model_gnn_conv_15', 'model_gnn_conv_16', 'model_gnn_conv_17', 'model_gnn_conv_18', 'model_gnn_conv_19', 'model_gnn_conv_2', 'model_gnn_conv_20', 'model_gnn_conv_21', 'model_gnn_conv_22', 'model_gnn_conv_23', 'model_gnn_conv_24', 'model_gnn_conv_25', 'model_gnn_conv_26', 'model_gnn_conv_27', 'model_gnn_conv_28', 'model_gnn_conv_29', 'model_gnn_conv_3', 'model_gnn_conv_30', 'model_gnn_conv_31', 'model_gnn_conv_32', 'model_gnn_conv_33', 'model_gnn_conv_34', 'model_gnn_conv_35', 'model_gnn_conv_36', 'model_gnn_conv_37', 'model_gnn_conv_38', 'model_gnn_conv_39', 'model_gnn_conv_4', 'model_gnn_conv_40', 'model_gnn_conv_41', 'model_gnn_conv_42', 'model_gnn_conv_43', 'model_gnn_conv_44', 'model_gnn_conv_45', 'model_gnn_conv_46', 'model_gnn_conv_47', 'model_gnn_conv_48', 'model_gnn_conv_49', 'model_gnn_conv_5', 'model_gnn_conv_50', 'model_gnn_conv_51', 'model_gnn_conv_52', 'model_gnn_conv_53', 'model_gnn_conv_54', 'model_gnn_conv_55', 'model_gnn_conv_56', 'model_gnn_conv_57', 'model_gnn_conv_58', 'model_gnn_conv_59', 'model_gnn_conv_6', 'model_gnn_conv_60', 'model_gnn_conv_61', 'model_gnn_conv_62', 'model_gnn_conv_63', 'model_gnn_conv_64', 'model_gnn_conv_65', 'model_gnn_conv_66', 'model_gnn_conv_67', 'model_gnn_conv_68', 'model_gnn_conv_69', 'model_gnn_conv_7', 'model_gnn_conv_70', 'model_gnn_conv_71', 'model_gnn_conv_72', 'model_gnn_conv_73', 'model_gnn_conv_74', 'model_gnn_conv_75', 'model_gnn_conv_76', 'model_gnn_conv_77', 'model_gnn_conv_78', 'model_gnn_conv_79', 'model_gnn_conv_8', 'model_gnn_conv_80', 'model_gnn_conv_81', 'model_gnn_conv_82', 'model_gnn_conv_83', 'model_gnn_conv_84', 'model_gnn_conv_85', 'model_gnn_conv_86', 'model_gnn_conv_87', 'model_gnn_conv_88', 'model_gnn_conv_89', 'model_gnn_conv_9', 'model_gnn_conv_90', 'model_gnn_conv_91', 'model_gnn_conv_92', 'model_gnn_conv_93', 'model_gnn_conv_94', 'model_gnn_conv_95', 'model_gnn_conv_96', 'model_gnn_conv_97', 'model_gnn_conv_98', 'model_gnn_conv_99']\n"
     ]
    }
   ],
   "source": [
    "files = list_files(path1)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_load = []\n",
    "import dill as pickle\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(path1, file)\n",
    "    with open(file_path, 'rb') as filel:\n",
    "        loaded_data = pickle.load(filel)\n",
    "    file1_load.append(loaded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pred_df':     y_real    y_pred\n",
       "  0   -8.040 -5.336251\n",
       "  1   -3.094 -2.698454\n",
       "  2   -3.610 -2.995411\n",
       "  3   -3.060 -2.598282\n",
       "  4   -5.270 -4.742428\n",
       "  ..     ...       ...\n",
       "  44  -4.402 -4.356841\n",
       "  45  -5.190 -3.900764\n",
       "  46  -3.290 -4.809336\n",
       "  47  -2.920 -1.933442\n",
       "  48  -1.960 -3.735151\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 128.49914526939392,\n",
       "  'mean_mse': 1.8223633,\n",
       "  'mean_l1': 1.0543776,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [10.245486164093018,\n",
       "   3.849641434351603,\n",
       "   3.633398485183716,\n",
       "   3.4766549110412597,\n",
       "   3.339778693517049,\n",
       "   3.5214232842127484,\n",
       "   3.2416025002797446,\n",
       "   2.9120702385902404,\n",
       "   2.816925279299418,\n",
       "   2.808077510197957,\n",
       "   2.6306906859079997,\n",
       "   2.606770881017049,\n",
       "   2.6311336517333985,\n",
       "   2.7143933614095053,\n",
       "   2.6068966229756674,\n",
       "   2.2894060055414838,\n",
       "   2.262121494611104,\n",
       "   2.2059902350107827,\n",
       "   2.1610281626383463,\n",
       "   2.1791641394297283,\n",
       "   2.085332091649373,\n",
       "   2.0199548403422036,\n",
       "   1.9446157018343608,\n",
       "   1.8561254223187764,\n",
       "   2.0748777548472086,\n",
       "   1.8563391129175821,\n",
       "   1.8418890317281087,\n",
       "   1.8521492242813111,\n",
       "   1.7990753253300984,\n",
       "   1.7074095010757446,\n",
       "   1.9949644843737284,\n",
       "   1.7774877945582073,\n",
       "   1.6270771503448487,\n",
       "   1.6270374139149983,\n",
       "   1.5656809409459431,\n",
       "   1.57162051598231,\n",
       "   1.6783667008082073,\n",
       "   1.617337457338969,\n",
       "   1.4464350779851278,\n",
       "   1.4525826692581176,\n",
       "   1.5193050980567933,\n",
       "   1.522053631146749,\n",
       "   1.4185364683469137,\n",
       "   1.4243167042732239,\n",
       "   1.39568084081014,\n",
       "   1.363304030895233,\n",
       "   1.3865405082702638,\n",
       "   1.4009225726127625,\n",
       "   1.4180922945340475,\n",
       "   1.3560147205988566,\n",
       "   1.2944121440251668,\n",
       "   1.3145299514134725,\n",
       "   1.3101358532905578,\n",
       "   1.248644999663035,\n",
       "   1.2321911056836445,\n",
       "   1.271419676144918,\n",
       "   1.1820587933063507,\n",
       "   1.415858018398285,\n",
       "   1.2401572704315185,\n",
       "   1.2433702985445658,\n",
       "   1.1960076014200847,\n",
       "   1.4211961348851523,\n",
       "   1.1815643032391867,\n",
       "   1.2196959614753724,\n",
       "   1.1699199000994365,\n",
       "   1.2902218461036683,\n",
       "   1.0983460863431296,\n",
       "   1.1357225974400837,\n",
       "   1.1272162556648255,\n",
       "   1.1050981998443603,\n",
       "   1.2107107957204184,\n",
       "   1.1125417470932006,\n",
       "   1.1203450481096904],\n",
       "  'val_losses': [9.414766788482666,\n",
       "   4.771497964859009,\n",
       "   4.543305158615112,\n",
       "   4.523425817489624,\n",
       "   4.411806106567383,\n",
       "   4.129918694496155,\n",
       "   4.248782396316528,\n",
       "   4.1452189683914185,\n",
       "   4.371139287948608,\n",
       "   4.2445409297943115,\n",
       "   4.247758150100708,\n",
       "   4.2427321672439575,\n",
       "   3.9053685665130615,\n",
       "   3.9647570848464966,\n",
       "   4.206765413284302,\n",
       "   4.0055296421051025,\n",
       "   3.738456964492798,\n",
       "   3.864161491394043,\n",
       "   3.8042213916778564,\n",
       "   3.7483909130096436,\n",
       "   3.570444703102112,\n",
       "   3.624173641204834,\n",
       "   3.356778144836426,\n",
       "   3.368768334388733,\n",
       "   3.3618701696395874,\n",
       "   3.208799719810486,\n",
       "   3.183034300804138,\n",
       "   3.065619111061096,\n",
       "   3.0749263763427734,\n",
       "   3.2763105630874634,\n",
       "   2.8235484957695007,\n",
       "   3.0142343044281006,\n",
       "   2.863064169883728,\n",
       "   2.9550375938415527,\n",
       "   2.9008709192276,\n",
       "   3.053530693054199,\n",
       "   2.6746084690093994,\n",
       "   2.72660493850708,\n",
       "   3.1129775047302246,\n",
       "   2.633130192756653,\n",
       "   2.8202348947525024,\n",
       "   2.963721513748169,\n",
       "   2.851326107978821,\n",
       "   2.7047502994537354,\n",
       "   2.524585485458374,\n",
       "   2.7012192010879517,\n",
       "   2.458508014678955,\n",
       "   2.5134702920913696,\n",
       "   2.4972957372665405,\n",
       "   2.791144847869873,\n",
       "   2.6746705770492554,\n",
       "   2.313979923725128,\n",
       "   2.31086802482605,\n",
       "   2.604888677597046,\n",
       "   2.4409942030906677,\n",
       "   2.5828351974487305,\n",
       "   2.2431362867355347,\n",
       "   2.3486424684524536,\n",
       "   2.2528598308563232,\n",
       "   2.5660794973373413,\n",
       "   2.2910666465759277,\n",
       "   2.3367894887924194,\n",
       "   2.486027240753174,\n",
       "   2.162380337715149,\n",
       "   2.294910192489624,\n",
       "   2.1547319293022156,\n",
       "   2.3537654876708984,\n",
       "   2.053794801235199,\n",
       "   2.2453209161758423,\n",
       "   2.093329071998596,\n",
       "   2.145702600479126,\n",
       "   2.3778370022773743,\n",
       "   2.1022821068763733]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.445 -4.499601\n",
       "  1   -3.168 -3.199362\n",
       "  2    0.790 -0.340273\n",
       "  3   -3.050 -4.973593\n",
       "  4   -4.173 -5.035722\n",
       "  ..     ...       ...\n",
       "  44  -2.461 -2.377716\n",
       "  45  -3.043 -3.732729\n",
       "  46  -3.880 -3.719980\n",
       "  47  -4.376 -4.343405\n",
       "  48  -2.943 -2.622013\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 156.16203999519348,\n",
       "  'mean_mse': 1.7740463,\n",
       "  'mean_l1': 1.0000901,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [11.289174588521321,\n",
       "   4.094536399841308,\n",
       "   3.952411715189616,\n",
       "   3.845433266957601,\n",
       "   3.5962141036987303,\n",
       "   3.6803650697072348,\n",
       "   3.3646756331125895,\n",
       "   3.3659361521402995,\n",
       "   3.351941204071045,\n",
       "   3.144792373975118,\n",
       "   2.942635456720988,\n",
       "   2.8438491145769755,\n",
       "   2.992737404505412,\n",
       "   2.900094668070475,\n",
       "   2.780128335952759,\n",
       "   2.9426810264587404,\n",
       "   2.584234635035197,\n",
       "   2.573454181353251,\n",
       "   2.5431200504302978,\n",
       "   2.433758858839671,\n",
       "   2.396890405813853,\n",
       "   2.4470863739649453,\n",
       "   2.369876750310262,\n",
       "   2.479389746983846,\n",
       "   2.615027602513631,\n",
       "   2.329159371058146,\n",
       "   2.5468549887339273,\n",
       "   2.2281037171681723,\n",
       "   2.5833232482274373,\n",
       "   2.2280240217844645,\n",
       "   2.169060158729553,\n",
       "   2.2248855670293173,\n",
       "   2.2334040721257526,\n",
       "   2.2257261991500856,\n",
       "   2.064102617899577,\n",
       "   2.1479368766148883,\n",
       "   2.1222439050674438,\n",
       "   2.0502485116322835,\n",
       "   2.0349074840545653,\n",
       "   1.9970311085383097,\n",
       "   1.9866236607233683,\n",
       "   2.0395476818084717,\n",
       "   1.934773580233256,\n",
       "   1.915269390741984,\n",
       "   1.9183812061945598,\n",
       "   1.9708282232284546,\n",
       "   1.8884822845458984,\n",
       "   1.9687522808710733,\n",
       "   1.9479057312011718,\n",
       "   1.8249427994092307,\n",
       "   1.8649760882059734,\n",
       "   2.028521196047465,\n",
       "   1.76090616385142,\n",
       "   1.8097222646077473,\n",
       "   1.9253233353296915,\n",
       "   1.848137664794922,\n",
       "   1.749996503194173,\n",
       "   1.7893712600072225,\n",
       "   1.8418790419896445,\n",
       "   1.834997288386027,\n",
       "   1.7168492476145427,\n",
       "   1.7131964206695556,\n",
       "   1.8743729909261069,\n",
       "   1.8351686398188274,\n",
       "   1.8973296324412028,\n",
       "   1.6240205943584443,\n",
       "   1.652552342414856,\n",
       "   1.579014507929484,\n",
       "   1.6351325352986654,\n",
       "   1.5838173349698386,\n",
       "   1.6010393857955934,\n",
       "   1.5919595877329509,\n",
       "   1.6465683221817016,\n",
       "   1.7204949617385865,\n",
       "   1.6375902891159058,\n",
       "   1.5029080669085184,\n",
       "   1.618701958656311,\n",
       "   1.504262351989746,\n",
       "   1.7792406638463338,\n",
       "   1.5726308345794677,\n",
       "   1.4597439726193746,\n",
       "   1.5697232643763224,\n",
       "   1.5785126129786173,\n",
       "   1.5063644568125407,\n",
       "   1.5202374537785848,\n",
       "   1.4453385651111603,\n",
       "   1.5010012050469717,\n",
       "   1.5608882427215576,\n",
       "   1.5039016803105671,\n",
       "   1.4930801550547281,\n",
       "   1.4284740328788756,\n",
       "   1.5611178994178772],\n",
       "  'val_losses': [12.230501651763916,\n",
       "   5.039335608482361,\n",
       "   4.7384021282196045,\n",
       "   4.418507218360901,\n",
       "   4.57303524017334,\n",
       "   4.301961064338684,\n",
       "   4.298018455505371,\n",
       "   4.296051502227783,\n",
       "   4.285735845565796,\n",
       "   4.322989463806152,\n",
       "   4.266013026237488,\n",
       "   4.260072469711304,\n",
       "   4.231152653694153,\n",
       "   4.099986791610718,\n",
       "   3.9646456241607666,\n",
       "   3.6541054248809814,\n",
       "   3.9969568252563477,\n",
       "   3.642282009124756,\n",
       "   3.795770525932312,\n",
       "   3.7933796644210815,\n",
       "   3.695717453956604,\n",
       "   3.6533145904541016,\n",
       "   3.5504144430160522,\n",
       "   3.7207562923431396,\n",
       "   3.432278633117676,\n",
       "   3.539914608001709,\n",
       "   3.2405266761779785,\n",
       "   3.4065566062927246,\n",
       "   3.1551417112350464,\n",
       "   3.341596245765686,\n",
       "   3.1344279050827026,\n",
       "   3.1515719890594482,\n",
       "   3.3770928382873535,\n",
       "   3.1607930660247803,\n",
       "   3.3056349754333496,\n",
       "   3.071093440055847,\n",
       "   2.89911150932312,\n",
       "   2.9569883346557617,\n",
       "   2.8875824213027954,\n",
       "   3.03820538520813,\n",
       "   2.799353241920471,\n",
       "   2.9529908895492554,\n",
       "   2.8191574811935425,\n",
       "   2.87346088886261,\n",
       "   2.753196358680725,\n",
       "   2.778993844985962,\n",
       "   2.708046317100525,\n",
       "   2.851135015487671,\n",
       "   2.803879141807556,\n",
       "   2.715175151824951,\n",
       "   2.6342896223068237,\n",
       "   2.556923270225525,\n",
       "   2.4980748295783997,\n",
       "   2.6013309955596924,\n",
       "   2.620369791984558,\n",
       "   2.4232847690582275,\n",
       "   2.4693485498428345,\n",
       "   2.641579747200012,\n",
       "   2.425309896469116,\n",
       "   2.481200695037842,\n",
       "   2.39922171831131,\n",
       "   2.5369967818260193,\n",
       "   2.4078482389450073,\n",
       "   2.460232734680176,\n",
       "   2.3300898671150208,\n",
       "   2.448926568031311,\n",
       "   2.3654619455337524,\n",
       "   2.3404404520988464,\n",
       "   2.2999852299690247,\n",
       "   2.332212805747986,\n",
       "   2.2507693767547607,\n",
       "   2.2981865406036377,\n",
       "   2.368529975414276,\n",
       "   2.254509925842285,\n",
       "   2.3003371357917786,\n",
       "   2.2255179286003113,\n",
       "   2.4136003255844116,\n",
       "   2.20347660779953,\n",
       "   2.323521375656128,\n",
       "   2.407036781311035,\n",
       "   2.2914493083953857,\n",
       "   2.1253373622894287,\n",
       "   2.194817304611206,\n",
       "   2.1811593174934387,\n",
       "   2.092909812927246,\n",
       "   2.3391852378845215,\n",
       "   1.974918782711029,\n",
       "   2.0561386346817017,\n",
       "   2.1435893774032593,\n",
       "   2.1560176610946655,\n",
       "   2.0082253217697144,\n",
       "   2.153209686279297]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.320 -5.894148\n",
       "  1   -3.880 -3.737573\n",
       "  2   -2.266 -1.802552\n",
       "  3   -4.799 -4.271437\n",
       "  4   -1.800 -1.832675\n",
       "  ..     ...       ...\n",
       "  44   0.300 -0.372801\n",
       "  45   0.522  0.137814\n",
       "  46  -7.800 -7.190526\n",
       "  47  -3.094 -3.560366\n",
       "  48  -4.173 -5.158621\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 34.33989214897156,\n",
       "  'mean_mse': 2.4277835,\n",
       "  'mean_l1': 1.1682303,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-3): 3 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.290584421157837,\n",
       "   3.965909465154012,\n",
       "   3.647536770502726,\n",
       "   2.9269301573435467,\n",
       "   2.6170370101928713,\n",
       "   2.091901977856954,\n",
       "   2.126119303703308,\n",
       "   1.880405863126119,\n",
       "   1.5804246584574382,\n",
       "   2.2510775963465375,\n",
       "   1.461655561129252,\n",
       "   1.3518333594004313,\n",
       "   1.2972294767697652,\n",
       "   1.2900361180305482,\n",
       "   1.239503554503123,\n",
       "   1.3335354288419088,\n",
       "   1.324958117802938],\n",
       "  'val_losses': [5.226559162139893,\n",
       "   5.0882885456085205,\n",
       "   4.864617824554443,\n",
       "   4.38711416721344,\n",
       "   4.0303672552108765,\n",
       "   3.58904492855072,\n",
       "   3.5741915702819824,\n",
       "   4.148447751998901,\n",
       "   2.3848456144332886,\n",
       "   2.2185349464416504,\n",
       "   2.1887952089309692,\n",
       "   3.130659580230713,\n",
       "   2.1959877014160156,\n",
       "   2.2708088159561157,\n",
       "   2.113350570201874,\n",
       "   2.663071632385254,\n",
       "   2.220093250274658]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.982 -2.792983\n",
       "  1   -0.400  0.084707\n",
       "  2   -3.220 -2.446277\n",
       "  3   -6.020 -3.059699\n",
       "  4   -3.658 -4.198142\n",
       "  ..     ...       ...\n",
       "  44  -6.680 -6.829843\n",
       "  45  -3.690 -5.498803\n",
       "  46  -2.266 -1.816899\n",
       "  47  -5.000 -6.006015\n",
       "  48  -2.780 -5.301799\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 37.49506878852844,\n",
       "  'mean_mse': 1.8535128,\n",
       "  'mean_l1': 0.9979146,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1): GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.531990003585816,\n",
       "   3.519010639190674,\n",
       "   2.890055799484253,\n",
       "   2.254103167851766,\n",
       "   2.0258532603581747,\n",
       "   1.5975584030151366,\n",
       "   1.694416077931722,\n",
       "   1.4022323846817017,\n",
       "   1.3583762526512146,\n",
       "   1.4225667595863343,\n",
       "   1.2257449865341186,\n",
       "   1.357360593477885,\n",
       "   1.5272137562433878,\n",
       "   1.088635790348053,\n",
       "   1.1379610200723012],\n",
       "  'val_losses': [7.265436887741089,\n",
       "   4.829875946044922,\n",
       "   3.8256064653396606,\n",
       "   3.160058856010437,\n",
       "   2.693939208984375,\n",
       "   2.4195141792297363,\n",
       "   1.9892221689224243,\n",
       "   1.9387022256851196,\n",
       "   2.1945229172706604,\n",
       "   1.9919636845588684,\n",
       "   2.062167763710022,\n",
       "   1.7515215873718262,\n",
       "   2.11917906999588,\n",
       "   1.864113688468933,\n",
       "   1.832251787185669]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.120 -2.965829\n",
       "  1   -3.931 -6.020732\n",
       "  2   -1.740 -4.419778\n",
       "  3   -3.638 -4.131661\n",
       "  4   -3.590 -5.137600\n",
       "  ..     ...       ...\n",
       "  44  -5.270 -5.123044\n",
       "  45  -4.376 -4.579854\n",
       "  46  -3.290 -4.654814\n",
       "  47  -4.632 -2.977364\n",
       "  48  -4.883 -4.950721\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 80.63839054107666,\n",
       "  'mean_mse': 1.6771173,\n",
       "  'mean_l1': 1.0261866,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1): GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.45991248289744,\n",
       "   3.262957239151001,\n",
       "   2.495846172173818,\n",
       "   2.1914851029713946,\n",
       "   1.856033726533254,\n",
       "   1.6132921775182087,\n",
       "   1.3777043958504995,\n",
       "   1.3183808008829752,\n",
       "   1.3036721289157867,\n",
       "   1.1589329918225606,\n",
       "   1.110817281405131,\n",
       "   0.9446105321248373,\n",
       "   1.0135783831278482,\n",
       "   1.1060021216670672,\n",
       "   0.9451316833496094,\n",
       "   1.0230485320091247,\n",
       "   0.8348710616429647,\n",
       "   0.8473465065161387,\n",
       "   0.8206799368063609,\n",
       "   0.7296030938625335,\n",
       "   0.7649674773216247,\n",
       "   0.7394455413023631,\n",
       "   0.7190990020831426,\n",
       "   0.6674265325069427,\n",
       "   0.7233432630697886,\n",
       "   0.6908328413963318,\n",
       "   0.6538083791732788,\n",
       "   0.778047130505244,\n",
       "   0.7641410231590271,\n",
       "   0.5855654021104176,\n",
       "   0.6846823116143544,\n",
       "   0.5998661935329437,\n",
       "   0.5673687716325124,\n",
       "   0.6673413515090942,\n",
       "   0.5303015823165576],\n",
       "  'val_losses': [7.978283643722534,\n",
       "   4.283355951309204,\n",
       "   5.013293743133545,\n",
       "   3.7416911125183105,\n",
       "   3.346437692642212,\n",
       "   2.9069292545318604,\n",
       "   2.5976853370666504,\n",
       "   2.2748184204101562,\n",
       "   2.1349955797195435,\n",
       "   2.126424729824066,\n",
       "   2.075383424758911,\n",
       "   1.9817993640899658,\n",
       "   1.9011446833610535,\n",
       "   2.8509790897369385,\n",
       "   2.1679270267486572,\n",
       "   1.9804877638816833,\n",
       "   1.843005120754242,\n",
       "   1.8792826533317566,\n",
       "   1.7951577305793762,\n",
       "   2.357249140739441,\n",
       "   2.104617714881897,\n",
       "   1.7740111947059631,\n",
       "   2.094580829143524,\n",
       "   1.8664108514785767,\n",
       "   1.762256145477295,\n",
       "   1.9579954743385315,\n",
       "   1.8780122995376587,\n",
       "   1.7327574491500854,\n",
       "   1.7853078842163086,\n",
       "   1.8729209899902344,\n",
       "   1.8223012685775757,\n",
       "   1.7301657795906067,\n",
       "   2.0753613710403442,\n",
       "   1.8406668901443481,\n",
       "   1.8746910691261292]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.800 -3.831715\n",
       "  1   -4.445 -4.978214\n",
       "  2   -0.600 -0.596747\n",
       "  3   -2.780 -3.708529\n",
       "  4   -4.160 -4.618169\n",
       "  ..     ...       ...\n",
       "  44  -9.332 -9.776299\n",
       "  45  -4.799 -3.385504\n",
       "  46  -4.120 -4.207095\n",
       "  47  -4.743 -4.501012\n",
       "  48  -4.380 -3.957703\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 58.11202383041382,\n",
       "  'mean_mse': 1.3044899,\n",
       "  'mean_l1': 0.89120054,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-2): 2 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.554416449864705,\n",
       "   2.890693211555481,\n",
       "   1.9222558657328288,\n",
       "   1.5843912045160928,\n",
       "   1.3886338273684184,\n",
       "   1.203202740351359,\n",
       "   1.1778778990109762,\n",
       "   1.5292384505271912,\n",
       "   0.7490868687629699,\n",
       "   0.7802765965461731,\n",
       "   1.0917556951443355,\n",
       "   0.6298066775004069,\n",
       "   0.5181450764338176,\n",
       "   0.4513465960820516,\n",
       "   0.43205991586049397,\n",
       "   0.5796452701091767,\n",
       "   0.49437753756841024,\n",
       "   0.43430336117744445,\n",
       "   0.37439528902371727,\n",
       "   0.42333335280418394,\n",
       "   0.4889611820379893,\n",
       "   0.3078101336956024,\n",
       "   0.35123644371827445],\n",
       "  'val_losses': [5.344034910202026,\n",
       "   3.9995068311691284,\n",
       "   3.128193736076355,\n",
       "   2.5703080892562866,\n",
       "   2.7843241691589355,\n",
       "   2.189608097076416,\n",
       "   2.0476917028427124,\n",
       "   2.2752097249031067,\n",
       "   1.7038747072219849,\n",
       "   1.8143550157546997,\n",
       "   1.6304421424865723,\n",
       "   2.1310824155807495,\n",
       "   1.7147697806358337,\n",
       "   1.5589569807052612,\n",
       "   1.6946950554847717,\n",
       "   1.6669297814369202,\n",
       "   1.435705304145813,\n",
       "   1.6921067237854004,\n",
       "   1.9491360187530518,\n",
       "   1.7232650518417358,\n",
       "   2.103541374206543,\n",
       "   1.5088635087013245,\n",
       "   1.582549810409546]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.410 -5.226018\n",
       "  1   -5.696 -5.115135\n",
       "  2   -1.850 -5.559714\n",
       "  3   -4.925 -4.196924\n",
       "  4   -3.290 -4.589594\n",
       "  ..     ...       ...\n",
       "  44  -2.982 -2.238691\n",
       "  45  -3.401 -1.152473\n",
       "  46  -3.610 -4.068750\n",
       "  47  -2.160 -2.200430\n",
       "  48  -3.094 -2.833154\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 43.55951929092407,\n",
       "  'mean_mse': 1.7365249,\n",
       "  'mean_l1': 1.0271642,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-2): 2 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.583628416061401,\n",
       "   3.218082038561503,\n",
       "   2.04933762550354,\n",
       "   2.279750386873881,\n",
       "   2.0151682058970133,\n",
       "   1.7386407136917115,\n",
       "   1.4029529174168904,\n",
       "   1.3395522157351176,\n",
       "   1.3169200817743938,\n",
       "   1.263690960407257,\n",
       "   1.0028262575467428,\n",
       "   0.9075107018152873,\n",
       "   0.9485897342363994,\n",
       "   0.7950972080230713,\n",
       "   0.7778697530428569,\n",
       "   0.8497052987416586,\n",
       "   0.6789577007293701,\n",
       "   0.7044421335061392],\n",
       "  'val_losses': [6.0596604347229,\n",
       "   4.042687177658081,\n",
       "   2.9708532094955444,\n",
       "   3.0849339962005615,\n",
       "   2.1075428128242493,\n",
       "   3.3814382553100586,\n",
       "   2.7099488973617554,\n",
       "   2.33376944065094,\n",
       "   1.9099847078323364,\n",
       "   3.2852638959884644,\n",
       "   1.8112521767616272,\n",
       "   2.00589656829834,\n",
       "   1.737474262714386,\n",
       "   2.9926021099090576,\n",
       "   2.5992499589920044,\n",
       "   2.005452871322632,\n",
       "   1.9226921796798706,\n",
       "   2.23488050699234]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -9.332 -9.835913\n",
       "  1   -4.047 -4.534871\n",
       "  2   -1.800 -2.836169\n",
       "  3   -3.451 -4.726476\n",
       "  4   -4.402 -4.679652\n",
       "  ..     ...       ...\n",
       "  44  -8.000 -8.812478\n",
       "  45  -5.220 -6.156251\n",
       "  46  -4.310 -4.098916\n",
       "  47  -2.676 -2.688220\n",
       "  48  -1.990 -2.183286\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 74.22773504257202,\n",
       "  'mean_mse': 1.3206216,\n",
       "  'mean_l1': 0.9238008,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-2): 2 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.421030553181966,\n",
       "   3.0602563619613647,\n",
       "   2.3325878143310548,\n",
       "   2.0876633882522584,\n",
       "   1.5964135567347209,\n",
       "   1.280539858341217,\n",
       "   1.1623116890589396,\n",
       "   0.9472734530766805,\n",
       "   0.8876108209292094,\n",
       "   0.8803676764170328,\n",
       "   0.7099922180175782,\n",
       "   0.6546075244744619,\n",
       "   0.6234814683596294,\n",
       "   0.5728733092546463,\n",
       "   0.6101139148076375,\n",
       "   0.5740618447462718,\n",
       "   0.5167005896568299,\n",
       "   0.5844316641489665,\n",
       "   0.5074552873770396,\n",
       "   0.4349741925795873,\n",
       "   0.5199853976567587,\n",
       "   0.47174840370814003,\n",
       "   0.42534439464410145,\n",
       "   0.4029520889123281,\n",
       "   0.4415855417648951,\n",
       "   0.45141678154468534,\n",
       "   0.3630113164583842,\n",
       "   0.41375454713900883,\n",
       "   0.34488067229588826],\n",
       "  'val_losses': [4.980792760848999,\n",
       "   5.247233152389526,\n",
       "   3.6485795974731445,\n",
       "   3.2617474794387817,\n",
       "   4.458087682723999,\n",
       "   2.430075764656067,\n",
       "   2.0680999755859375,\n",
       "   1.928359866142273,\n",
       "   1.8868622779846191,\n",
       "   1.8037627935409546,\n",
       "   1.8111523389816284,\n",
       "   2.104733407497406,\n",
       "   1.6979779601097107,\n",
       "   1.7614652514457703,\n",
       "   1.6161288619041443,\n",
       "   1.6777212619781494,\n",
       "   2.929569125175476,\n",
       "   1.7081406116485596,\n",
       "   1.6069454550743103,\n",
       "   1.4042783677577972,\n",
       "   1.5321683883666992,\n",
       "   1.8299334049224854,\n",
       "   1.3712555170059204,\n",
       "   1.4022148251533508,\n",
       "   1.7315409779548645,\n",
       "   1.3404636979103088,\n",
       "   1.461946427822113,\n",
       "   1.595004916191101,\n",
       "   1.3545945882797241]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -0.600 -0.661976\n",
       "  1   -3.451 -4.334042\n",
       "  2   -3.168 -2.377018\n",
       "  3   -3.930 -2.264237\n",
       "  4   -4.634 -3.666454\n",
       "  ..     ...       ...\n",
       "  44  -4.800 -5.060522\n",
       "  45  -3.043 -3.674400\n",
       "  46  -1.640 -3.734159\n",
       "  47  -2.266 -1.481877\n",
       "  48  -2.982 -2.703736\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 88.35202956199646,\n",
       "  'mean_mse': 1.317651,\n",
       "  'mean_l1': 0.891474,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-3): 3 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.408862829208374,\n",
       "   2.7720427672068277,\n",
       "   2.219077738126119,\n",
       "   1.7004103342692056,\n",
       "   1.2345266660054526,\n",
       "   1.0972707311312357,\n",
       "   1.4273903727531434,\n",
       "   1.0868275552988051,\n",
       "   0.7381093978881836,\n",
       "   0.7427487134933471,\n",
       "   0.5767943600813548,\n",
       "   0.5352640410264333,\n",
       "   0.5271596173445384,\n",
       "   0.424646324912707,\n",
       "   0.6133727351824443,\n",
       "   0.3594862073659897,\n",
       "   0.48011277318000795,\n",
       "   0.38533484439055127,\n",
       "   0.2889318277438482,\n",
       "   0.31607768932978314,\n",
       "   0.2927503993113836,\n",
       "   0.24839283923308056,\n",
       "   0.2392044315735499,\n",
       "   0.28654007812341054,\n",
       "   0.33766440600156783,\n",
       "   0.19447964429855347,\n",
       "   0.19760229637225468,\n",
       "   0.17793667316436768,\n",
       "   0.21978157609701157,\n",
       "   0.17453438540299734,\n",
       "   0.14210069576899212],\n",
       "  'val_losses': [4.472600936889648,\n",
       "   4.459078073501587,\n",
       "   4.017756938934326,\n",
       "   3.019769310951233,\n",
       "   1.9697726964950562,\n",
       "   1.852449119091034,\n",
       "   1.7410590648651123,\n",
       "   3.9147753715515137,\n",
       "   1.6369823813438416,\n",
       "   1.612991988658905,\n",
       "   2.142865300178528,\n",
       "   1.6345064640045166,\n",
       "   1.7150375843048096,\n",
       "   1.6964475512504578,\n",
       "   1.5536122918128967,\n",
       "   1.6684057712554932,\n",
       "   1.67033052444458,\n",
       "   1.6415382623672485,\n",
       "   1.4964900612831116,\n",
       "   1.4913840889930725,\n",
       "   1.3914920687675476,\n",
       "   1.6325746774673462,\n",
       "   1.4196065068244934,\n",
       "   1.4306672811508179,\n",
       "   1.597940742969513,\n",
       "   1.4650846123695374,\n",
       "   1.5704230666160583,\n",
       "   1.6186419129371643,\n",
       "   1.3931151032447815,\n",
       "   1.3333431482315063,\n",
       "   1.449872374534607]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.173 -4.305480\n",
       "  1   -6.860 -6.181535\n",
       "  2   -3.290 -3.768840\n",
       "  3   -1.899 -0.933690\n",
       "  4   -3.401 -1.047067\n",
       "  ..     ...       ...\n",
       "  44  -2.982 -2.573457\n",
       "  45  -4.370 -4.037220\n",
       "  46  -3.246 -4.370774\n",
       "  47  -2.281 -2.086575\n",
       "  48  -5.220 -6.099770\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 55.71765351295471,\n",
       "  'mean_mse': 1.8262135,\n",
       "  'mean_l1': 1.0048227,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-3): 3 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.4663875261942545,\n",
       "   2.9376121679941813,\n",
       "   2.9321783622105917,\n",
       "   2.1330948193868,\n",
       "   1.6660350640614827,\n",
       "   1.3772466739018758,\n",
       "   0.9969750722249349,\n",
       "   1.050253732999166,\n",
       "   0.9262996097405751,\n",
       "   1.0005698323249816,\n",
       "   1.0427436113357544,\n",
       "   1.0571329553922018,\n",
       "   0.6142124970753987,\n",
       "   0.6609399855136872,\n",
       "   0.6304683923721314,\n",
       "   0.49736799200375875,\n",
       "   0.5843554516633351,\n",
       "   0.47909511923789977,\n",
       "   0.4229021886984507,\n",
       "   0.586842542886734],\n",
       "  'val_losses': [4.55672550201416,\n",
       "   4.80694317817688,\n",
       "   3.865453004837036,\n",
       "   4.327919840812683,\n",
       "   2.2081708908081055,\n",
       "   3.2199103832244873,\n",
       "   2.0211533904075623,\n",
       "   2.362581253051758,\n",
       "   1.8401841521263123,\n",
       "   2.8560363054275513,\n",
       "   3.077054262161255,\n",
       "   2.575263261795044,\n",
       "   1.7346453666687012,\n",
       "   2.090027332305908,\n",
       "   2.095321774482727,\n",
       "   1.6871771812438965,\n",
       "   5.702335357666016,\n",
       "   1.6588538885116577,\n",
       "   2.226491689682007,\n",
       "   1.7808000445365906]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.880 -4.208005\n",
       "  1   -4.402 -5.174550\n",
       "  2   -2.982 -3.047313\n",
       "  3   -2.780 -4.578907\n",
       "  4   -8.000 -8.582699\n",
       "  ..     ...       ...\n",
       "  44  -1.716 -2.836828\n",
       "  45  -2.349 -2.322003\n",
       "  46  -4.800 -6.285405\n",
       "  47  -1.800 -2.785399\n",
       "  48   1.100  0.681071\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 95.1283450126648,\n",
       "  'mean_mse': 1.5450864,\n",
       "  'mean_l1': 0.9424009,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-3): 3 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.340437221527099,\n",
       "   3.0383296330769856,\n",
       "   2.299736913045247,\n",
       "   1.9233312527338664,\n",
       "   1.479011599222819,\n",
       "   1.3384421149889627,\n",
       "   1.0863545219103494,\n",
       "   0.958579542239507,\n",
       "   0.8725474357604981,\n",
       "   0.7736611942450206,\n",
       "   0.7291077593962352,\n",
       "   0.6596957623958588,\n",
       "   0.6627462267875671,\n",
       "   0.5925245503584544,\n",
       "   0.6708131591478984,\n",
       "   0.46313959956169126,\n",
       "   0.5015539427598318,\n",
       "   0.5068087925513586,\n",
       "   0.3709014808138212,\n",
       "   0.3771309753259023,\n",
       "   0.50498392979304,\n",
       "   0.581636244058609,\n",
       "   0.39809219241142274,\n",
       "   0.35011461973190305,\n",
       "   0.3786131838957469,\n",
       "   0.4312326967716217,\n",
       "   0.31751484274864195,\n",
       "   0.2972961684068044,\n",
       "   0.2759291887283325,\n",
       "   0.4036409874757131,\n",
       "   0.24700272778669993,\n",
       "   0.253918453057607,\n",
       "   0.2685748696327209,\n",
       "   0.24747277001539866,\n",
       "   0.26886977851390836],\n",
       "  'val_losses': [4.568132638931274,\n",
       "   4.355946063995361,\n",
       "   3.6122684478759766,\n",
       "   3.2200114727020264,\n",
       "   2.5180100202560425,\n",
       "   2.7254514694213867,\n",
       "   2.4705694913864136,\n",
       "   2.867590546607971,\n",
       "   1.9955087304115295,\n",
       "   2.030933380126953,\n",
       "   2.2046828269958496,\n",
       "   1.9056081771850586,\n",
       "   1.8796782493591309,\n",
       "   1.6291074752807617,\n",
       "   1.8300389051437378,\n",
       "   1.8165984153747559,\n",
       "   1.5618940591812134,\n",
       "   1.5288922786712646,\n",
       "   1.7465224266052246,\n",
       "   1.4806952476501465,\n",
       "   1.6826893091201782,\n",
       "   1.4984130859375,\n",
       "   1.5063727498054504,\n",
       "   1.6315310299396515,\n",
       "   1.727648913860321,\n",
       "   1.4082920551300049,\n",
       "   1.532107651233673,\n",
       "   1.463322937488556,\n",
       "   1.4224645495414734,\n",
       "   1.3930557370185852,\n",
       "   1.652492105960846,\n",
       "   1.5113130807876587,\n",
       "   1.5031521320343018,\n",
       "   1.3749337792396545,\n",
       "   1.5924299359321594]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.350 -4.638422\n",
       "  1   -2.780 -4.794113\n",
       "  2   -0.600 -1.447423\n",
       "  3   -1.716 -3.702607\n",
       "  4   -4.120 -4.085909\n",
       "  ..     ...       ...\n",
       "  44  -2.338 -2.919304\n",
       "  45  -4.799 -3.757067\n",
       "  46  -9.332 -9.639874\n",
       "  47  -0.400  0.454677\n",
       "  48  -3.171 -5.090995\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 54.50554823875427,\n",
       "  'mean_mse': 1.903641,\n",
       "  'mean_l1': 1.0801415,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-3): 3 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [8.127731688817342,\n",
       "   3.5541234811147056,\n",
       "   3.655987517038981,\n",
       "   3.057891082763672,\n",
       "   2.552776543299357,\n",
       "   1.978678790728251,\n",
       "   2.189159401257833,\n",
       "   1.6883602062861125,\n",
       "   1.5290675560633342,\n",
       "   1.5632382849852244,\n",
       "   1.379669431845347,\n",
       "   1.3791696190834046,\n",
       "   1.2946308453877766,\n",
       "   1.536406441529592,\n",
       "   1.078378140926361,\n",
       "   0.9813467423121135,\n",
       "   0.9349905153115591,\n",
       "   0.8804794510205587,\n",
       "   1.0107921520868937,\n",
       "   0.8772431929906209,\n",
       "   0.8583675742149353,\n",
       "   1.018428522348404,\n",
       "   0.7884223540623982,\n",
       "   0.8129194339116415,\n",
       "   0.8085854649543762],\n",
       "  'val_losses': [7.699792861938477,\n",
       "   4.588324785232544,\n",
       "   4.274340867996216,\n",
       "   4.022332668304443,\n",
       "   4.726775169372559,\n",
       "   4.193328380584717,\n",
       "   3.059415817260742,\n",
       "   4.33666455745697,\n",
       "   2.7022074460983276,\n",
       "   2.4961503744125366,\n",
       "   2.2695045471191406,\n",
       "   2.6867352724075317,\n",
       "   2.085326135158539,\n",
       "   2.0465357303619385,\n",
       "   1.961462378501892,\n",
       "   1.9545966386795044,\n",
       "   2.007817327976227,\n",
       "   1.910317599773407,\n",
       "   2.084603488445282,\n",
       "   2.0937612056732178,\n",
       "   2.067321300506592,\n",
       "   2.3409066796302795,\n",
       "   1.9118744730949402,\n",
       "   1.941361665725708,\n",
       "   2.0010260343551636]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.538 -3.801933\n",
       "  1   -3.290 -4.516503\n",
       "  2   -5.270 -4.843226\n",
       "  3   -3.094 -2.332519\n",
       "  4   -2.943 -2.780928\n",
       "  ..     ...       ...\n",
       "  44  -6.680 -5.507557\n",
       "  45  -2.932 -2.276168\n",
       "  46  -3.610 -2.826012\n",
       "  47  -5.190 -5.516786\n",
       "  48  -3.931 -4.327082\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 142.33368277549744,\n",
       "  'mean_mse': 1.9824286,\n",
       "  'mean_l1': 1.135471,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [11.262166976928711,\n",
       "   3.9964651584625246,\n",
       "   3.844138765335083,\n",
       "   3.549137798945109,\n",
       "   3.295359754562378,\n",
       "   3.2446205774943033,\n",
       "   3.0894501487414043,\n",
       "   3.0198440392812094,\n",
       "   3.1047065099080404,\n",
       "   3.0570355892181396,\n",
       "   2.7083837588628135,\n",
       "   2.7114588658014935,\n",
       "   2.7589351495107013,\n",
       "   2.8634154081344603,\n",
       "   2.385979413986206,\n",
       "   2.3761915445327757,\n",
       "   2.2795345783233643,\n",
       "   2.236640004316966,\n",
       "   2.318046196301778,\n",
       "   2.129039430618286,\n",
       "   2.1328290859858194,\n",
       "   2.002084191640218,\n",
       "   2.050826732317607,\n",
       "   1.9467740376790366,\n",
       "   2.1032663027445477,\n",
       "   2.001981282234192,\n",
       "   1.8699819087982177,\n",
       "   1.8008676807085673,\n",
       "   1.910721739133199,\n",
       "   1.7398780783017476,\n",
       "   1.696662755807241,\n",
       "   1.8849330306053163,\n",
       "   1.5913284569978714,\n",
       "   1.7042004982630412,\n",
       "   1.7318117380142213,\n",
       "   1.6369437456130982,\n",
       "   1.5349395036697389,\n",
       "   1.5378066460291544,\n",
       "   1.527885361512502,\n",
       "   1.6105581760406493,\n",
       "   1.42963760693868,\n",
       "   1.5178385774294536,\n",
       "   1.4019832213719685,\n",
       "   1.4715371290842691,\n",
       "   1.3823926091194152,\n",
       "   1.3342317382494608,\n",
       "   1.4057894070943198,\n",
       "   1.318174910545349,\n",
       "   1.400943104426066,\n",
       "   1.2973599394162496,\n",
       "   1.2783018151919048,\n",
       "   1.3335454026858011,\n",
       "   1.3074540893236797,\n",
       "   1.2690616806348165,\n",
       "   1.3660566767056783,\n",
       "   1.3389009873072306,\n",
       "   1.2308047413825989,\n",
       "   1.1980407218138376,\n",
       "   1.2061166405677795,\n",
       "   1.205905520915985,\n",
       "   1.198700527350108,\n",
       "   1.1299189547697703,\n",
       "   1.2851423184076944,\n",
       "   1.1484102010726929,\n",
       "   1.1612730582555135,\n",
       "   1.1343171079953511,\n",
       "   1.2282665610313415,\n",
       "   1.2075915614763895,\n",
       "   1.1050359686215718,\n",
       "   1.1329093138376871,\n",
       "   1.143248160680135,\n",
       "   1.1125027497609457,\n",
       "   1.2098137974739074,\n",
       "   1.0480738401412963,\n",
       "   1.0808850119511286,\n",
       "   1.0240523139635722,\n",
       "   1.117221482594808,\n",
       "   1.1461424827575684,\n",
       "   1.113856558005015,\n",
       "   1.006984535853068,\n",
       "   1.037077796459198,\n",
       "   1.0653291463851928,\n",
       "   0.9817870378494262,\n",
       "   1.023412048816681,\n",
       "   1.0098960717519125,\n",
       "   0.9862352093060811,\n",
       "   1.0029555598894755,\n",
       "   0.9547851676742236,\n",
       "   0.9664732376734416,\n",
       "   0.9346246937910716,\n",
       "   0.9452055553595226,\n",
       "   0.9641581495602926,\n",
       "   0.9379277308781941,\n",
       "   0.9108204344908396,\n",
       "   0.9787530958652496],\n",
       "  'val_losses': [12.052473068237305,\n",
       "   5.144157648086548,\n",
       "   4.660155773162842,\n",
       "   4.585339546203613,\n",
       "   4.308596849441528,\n",
       "   4.295367002487183,\n",
       "   4.35063910484314,\n",
       "   4.321800947189331,\n",
       "   4.311952590942383,\n",
       "   4.232468843460083,\n",
       "   4.320201992988586,\n",
       "   4.249383449554443,\n",
       "   4.33000373840332,\n",
       "   4.05245304107666,\n",
       "   4.223891019821167,\n",
       "   4.0642290115356445,\n",
       "   4.399624586105347,\n",
       "   4.29715895652771,\n",
       "   3.892762064933777,\n",
       "   4.015958189964294,\n",
       "   3.968323230743408,\n",
       "   3.8226298093795776,\n",
       "   3.8476598262786865,\n",
       "   3.6845864057540894,\n",
       "   3.4888756275177,\n",
       "   3.4551374912261963,\n",
       "   3.562472939491272,\n",
       "   3.706007719039917,\n",
       "   3.3804529905319214,\n",
       "   3.3021299839019775,\n",
       "   3.039850652217865,\n",
       "   3.3890804052352905,\n",
       "   3.182639479637146,\n",
       "   3.3309996128082275,\n",
       "   3.0660111904144287,\n",
       "   3.13482928276062,\n",
       "   3.3864355087280273,\n",
       "   3.1285558938980103,\n",
       "   3.2236385345458984,\n",
       "   2.9615375995635986,\n",
       "   2.865229606628418,\n",
       "   2.811803936958313,\n",
       "   2.813010096549988,\n",
       "   2.7182939052581787,\n",
       "   2.7658987045288086,\n",
       "   2.7583447694778442,\n",
       "   2.575528621673584,\n",
       "   2.625808596611023,\n",
       "   2.7820624113082886,\n",
       "   2.5140450596809387,\n",
       "   2.4957319498062134,\n",
       "   2.64729642868042,\n",
       "   2.6447004079818726,\n",
       "   2.493034601211548,\n",
       "   2.5579155683517456,\n",
       "   2.5625073313713074,\n",
       "   2.7030436992645264,\n",
       "   2.3451313972473145,\n",
       "   2.346771478652954,\n",
       "   2.5278491973876953,\n",
       "   2.4345897436141968,\n",
       "   2.628828525543213,\n",
       "   2.381468176841736,\n",
       "   2.3693385124206543,\n",
       "   2.440009593963623,\n",
       "   2.5072181224823,\n",
       "   2.3755316138267517,\n",
       "   2.294019341468811,\n",
       "   2.2604439854621887,\n",
       "   2.1943209171295166,\n",
       "   2.22880882024765,\n",
       "   2.5064094066619873,\n",
       "   2.214778482913971,\n",
       "   2.1498674154281616,\n",
       "   2.2009183168411255,\n",
       "   2.2797893285751343,\n",
       "   2.162059783935547,\n",
       "   2.248456358909607,\n",
       "   2.2758729457855225,\n",
       "   2.18452787399292,\n",
       "   2.607881546020508,\n",
       "   2.2294929027557373,\n",
       "   2.1520329117774963,\n",
       "   2.1742337942123413,\n",
       "   2.654289484024048,\n",
       "   2.267870306968689,\n",
       "   2.0501332879066467,\n",
       "   2.4936625957489014,\n",
       "   2.5328195095062256,\n",
       "   2.171667456626892,\n",
       "   2.10298353433609,\n",
       "   2.196827530860901,\n",
       "   2.0866439938545227,\n",
       "   2.221766412258148,\n",
       "   2.0593615770339966]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.270 -4.918567\n",
       "  1   -2.281 -2.950265\n",
       "  2   -1.800 -2.826174\n",
       "  3   -8.000 -5.930760\n",
       "  4   -2.943 -2.706303\n",
       "  ..     ...       ...\n",
       "  44   1.100 -0.215897\n",
       "  45  -2.160 -3.400159\n",
       "  46  -6.800 -8.517517\n",
       "  47  -5.915 -3.871899\n",
       "  48  -3.620 -3.097354\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 123.71207189559937,\n",
       "  'mean_mse': 1.9811338,\n",
       "  'mean_l1': 1.0721475,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.0790145556132,\n",
       "   3.894130309422811,\n",
       "   3.619435175259908,\n",
       "   3.617029841740926,\n",
       "   3.558494512240092,\n",
       "   3.920826244354248,\n",
       "   3.7898998896280927,\n",
       "   3.2253038267294567,\n",
       "   3.6214821656545,\n",
       "   3.162582023938497,\n",
       "   3.049921735127767,\n",
       "   3.016124971707662,\n",
       "   3.012409480412801,\n",
       "   3.0059459686279295,\n",
       "   2.8638931274414063,\n",
       "   2.749357477823893,\n",
       "   2.727585522333781,\n",
       "   3.0159795840581256,\n",
       "   2.5985150138537088,\n",
       "   2.730113704999288,\n",
       "   2.555706810951233,\n",
       "   2.5849862178166707,\n",
       "   2.6717496951421102,\n",
       "   2.8982356707255046,\n",
       "   2.4251563707987467,\n",
       "   2.4310345967610676,\n",
       "   2.383117373784383,\n",
       "   2.4168901761372883,\n",
       "   2.432571808497111,\n",
       "   2.309855898221334,\n",
       "   2.223156201839447,\n",
       "   2.3083072106043496,\n",
       "   2.2000921726226808,\n",
       "   2.2481026887893676,\n",
       "   2.235864289601644,\n",
       "   2.1828472296396892,\n",
       "   2.1283745050430296,\n",
       "   2.061938234170278,\n",
       "   2.1964616934458414,\n",
       "   2.024104611078898,\n",
       "   2.206839593251546,\n",
       "   2.0754115263621014,\n",
       "   1.937955872217814,\n",
       "   2.059059492746989,\n",
       "   1.974527621269226,\n",
       "   2.0514846642812095,\n",
       "   1.8794337590535481,\n",
       "   1.9482813517252604,\n",
       "   1.9045983294645945,\n",
       "   1.9911667505900066,\n",
       "   1.9021708567937214,\n",
       "   2.026924808820089,\n",
       "   1.8804608980814617,\n",
       "   1.8395596583684286,\n",
       "   1.861655338605245,\n",
       "   1.8655309915542602,\n",
       "   1.7696377754211425,\n",
       "   1.9828090826670328,\n",
       "   1.8222831726074218,\n",
       "   1.7046204447746276,\n",
       "   1.713671330610911,\n",
       "   1.7830678224563599,\n",
       "   1.758484705289205,\n",
       "   1.6599154273668926,\n",
       "   1.7077062924702961,\n",
       "   1.7071759343147277,\n",
       "   1.717246691385905,\n",
       "   1.8878796021143596,\n",
       "   1.6980841000874838,\n",
       "   1.7569417715072633,\n",
       "   1.7100886424382529,\n",
       "   1.643796451886495,\n",
       "   1.7199788649876913,\n",
       "   1.6659660498301188,\n",
       "   1.5712705612182618,\n",
       "   1.5547182202339171,\n",
       "   1.5807742754618326,\n",
       "   1.5896592140197754,\n",
       "   1.5918820222218832,\n",
       "   1.6329890012741088,\n",
       "   1.5903743028640747,\n",
       "   1.498750106493632,\n",
       "   1.5987911939620971,\n",
       "   1.5172977368036906,\n",
       "   1.7057011524836223,\n",
       "   1.4726639191309612,\n",
       "   1.6808395544687906],\n",
       "  'val_losses': [8.506663799285889,\n",
       "   5.4193830490112305,\n",
       "   4.770029067993164,\n",
       "   4.492410898208618,\n",
       "   4.318184733390808,\n",
       "   4.563369035720825,\n",
       "   4.432820081710815,\n",
       "   4.277888536453247,\n",
       "   4.12905490398407,\n",
       "   4.32077431678772,\n",
       "   4.217115879058838,\n",
       "   4.352018713951111,\n",
       "   4.353133201599121,\n",
       "   4.366026401519775,\n",
       "   4.206403017044067,\n",
       "   4.203871011734009,\n",
       "   4.1641881465911865,\n",
       "   4.331749439239502,\n",
       "   3.8704782724380493,\n",
       "   4.153767108917236,\n",
       "   3.9904106855392456,\n",
       "   3.9029111862182617,\n",
       "   3.81021249294281,\n",
       "   3.7998034954071045,\n",
       "   4.0661842823028564,\n",
       "   3.784074544906616,\n",
       "   3.673317790031433,\n",
       "   3.8053923845291138,\n",
       "   3.6266517639160156,\n",
       "   3.9635164737701416,\n",
       "   3.5598560571670532,\n",
       "   3.2749346494674683,\n",
       "   3.4811103343963623,\n",
       "   3.4200698137283325,\n",
       "   3.2597471475601196,\n",
       "   3.2113277912139893,\n",
       "   3.035058617591858,\n",
       "   3.1639400720596313,\n",
       "   3.285465121269226,\n",
       "   3.2075092792510986,\n",
       "   3.376409411430359,\n",
       "   2.941675305366516,\n",
       "   2.868014097213745,\n",
       "   2.8890206813812256,\n",
       "   3.0360742807388306,\n",
       "   2.77692449092865,\n",
       "   3.104920268058777,\n",
       "   2.690088629722595,\n",
       "   3.4374884366989136,\n",
       "   2.801348328590393,\n",
       "   2.754700541496277,\n",
       "   2.789534091949463,\n",
       "   2.7938220500946045,\n",
       "   2.8466509580612183,\n",
       "   2.52047598361969,\n",
       "   2.7936865091323853,\n",
       "   2.6866241693496704,\n",
       "   2.6320784091949463,\n",
       "   2.532062292098999,\n",
       "   3.125050187110901,\n",
       "   2.592513680458069,\n",
       "   2.4898273944854736,\n",
       "   2.4717408418655396,\n",
       "   2.447221875190735,\n",
       "   2.5079864263534546,\n",
       "   2.403952121734619,\n",
       "   2.6329180002212524,\n",
       "   2.3864805698394775,\n",
       "   2.5898865461349487,\n",
       "   2.5612882375717163,\n",
       "   2.491009831428528,\n",
       "   2.357497453689575,\n",
       "   2.3414578437805176,\n",
       "   2.3854252099990845,\n",
       "   2.456726610660553,\n",
       "   2.2625433206558228,\n",
       "   2.2521296739578247,\n",
       "   2.3949846029281616,\n",
       "   2.163794159889221,\n",
       "   2.1985541582107544,\n",
       "   2.3549208641052246,\n",
       "   2.1309980750083923,\n",
       "   2.217921257019043,\n",
       "   2.199455499649048,\n",
       "   2.3448436856269836,\n",
       "   2.2270249128341675,\n",
       "   2.188770055770874]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.050 -3.815982\n",
       "  1   -3.246 -6.190946\n",
       "  2   -2.266 -2.347986\n",
       "  3   -1.899 -2.732260\n",
       "  4   -5.696 -5.449053\n",
       "  ..     ...       ...\n",
       "  44  -2.700 -4.508019\n",
       "  45  -6.800 -3.564295\n",
       "  46  -4.160 -3.565041\n",
       "  47  -3.360 -4.077495\n",
       "  48  -4.805 -2.798979\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 71.82686042785645,\n",
       "  'mean_mse': 2.734133,\n",
       "  'mean_l1': 1.2823756,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.242615040143331,\n",
       "   3.792132043838501,\n",
       "   3.700554196039836,\n",
       "   3.4761131604512534,\n",
       "   3.5469393571217855,\n",
       "   3.2891968568166097,\n",
       "   3.7070219993591307,\n",
       "   3.133171860376994,\n",
       "   3.0033036947250364,\n",
       "   3.06226331392924,\n",
       "   2.7979972759882608,\n",
       "   2.991204198201497,\n",
       "   2.6732755502065024,\n",
       "   2.5817006111145018,\n",
       "   2.5319331407547,\n",
       "   2.4887929201126098,\n",
       "   2.373183560371399,\n",
       "   2.4959573189417523,\n",
       "   2.2132835030555724,\n",
       "   2.181552354494731,\n",
       "   2.1448439598083495,\n",
       "   2.0768758416175843,\n",
       "   2.2127177079518634,\n",
       "   2.0648967266082763,\n",
       "   1.9520232995351157,\n",
       "   1.9725085179011026,\n",
       "   2.1792399644851685,\n",
       "   2.035219097137451,\n",
       "   1.8209351897239685,\n",
       "   1.9435442765553792,\n",
       "   1.891319211324056,\n",
       "   2.124518084526062,\n",
       "   1.766540571053823,\n",
       "   1.9378814220428466,\n",
       "   1.8101259231567384,\n",
       "   1.7931743542353311,\n",
       "   1.7519641319910686,\n",
       "   1.8172382911046345,\n",
       "   1.803254199028015,\n",
       "   1.7107820669809977,\n",
       "   1.6764451265335083,\n",
       "   1.6959060827891033,\n",
       "   1.668830386797587,\n",
       "   1.705123774210612,\n",
       "   1.6170286417007447,\n",
       "   1.6739906072616577,\n",
       "   1.6309354146321615,\n",
       "   1.6015730420748393],\n",
       "  'val_losses': [8.081978797912598,\n",
       "   5.149878025054932,\n",
       "   4.67221736907959,\n",
       "   4.422495365142822,\n",
       "   4.3299455642700195,\n",
       "   4.441745638847351,\n",
       "   4.4410282373428345,\n",
       "   4.295623302459717,\n",
       "   4.136041641235352,\n",
       "   4.085534334182739,\n",
       "   4.30926513671875,\n",
       "   3.868369936943054,\n",
       "   4.067623496055603,\n",
       "   4.018750905990601,\n",
       "   3.9548609256744385,\n",
       "   4.044752597808838,\n",
       "   3.931808114051819,\n",
       "   3.8011209964752197,\n",
       "   3.6202961206436157,\n",
       "   3.652109384536743,\n",
       "   3.6880571842193604,\n",
       "   3.603713035583496,\n",
       "   3.630598783493042,\n",
       "   3.658130168914795,\n",
       "   3.5121177434921265,\n",
       "   3.403963804244995,\n",
       "   3.365906238555908,\n",
       "   3.2281402349472046,\n",
       "   3.250080943107605,\n",
       "   3.2306997776031494,\n",
       "   3.191683053970337,\n",
       "   3.288338780403137,\n",
       "   3.127866268157959,\n",
       "   3.0575642585754395,\n",
       "   3.0936232805252075,\n",
       "   3.106358528137207,\n",
       "   2.937273383140564,\n",
       "   2.9400177001953125,\n",
       "   2.787051796913147,\n",
       "   2.8147119283676147,\n",
       "   3.1181628704071045,\n",
       "   2.9457035064697266,\n",
       "   2.643287181854248,\n",
       "   2.7215553522109985,\n",
       "   2.8195855617523193,\n",
       "   2.7159053087234497,\n",
       "   2.836074948310852,\n",
       "   2.7649013996124268]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.160 -5.021044\n",
       "  1   -3.246 -4.828755\n",
       "  2   -1.899 -2.159404\n",
       "  3   -4.445 -5.715401\n",
       "  4   -4.047 -4.640721\n",
       "  ..     ...       ...\n",
       "  44  -4.450 -1.795877\n",
       "  45  -3.180 -2.949317\n",
       "  46  -7.280 -3.282305\n",
       "  47  -6.860 -7.429920\n",
       "  48  -3.451 -4.708873\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 81.78207683563232,\n",
       "  'mean_mse': 1.847012,\n",
       "  'mean_l1': 1.0539073,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1): GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [9.734828408559164,\n",
       "   3.693936840693156,\n",
       "   3.280676007270813,\n",
       "   3.125010347366333,\n",
       "   2.9181405862172443,\n",
       "   2.4275949239730834,\n",
       "   2.276490346590678,\n",
       "   2.1851538817087808,\n",
       "   2.046151065826416,\n",
       "   1.994120971361796,\n",
       "   1.9484456062316895,\n",
       "   1.8408532381057738,\n",
       "   1.5852807680765788,\n",
       "   1.6431903521219888,\n",
       "   1.4823071678479514,\n",
       "   1.381738539536794,\n",
       "   1.3110090454419454,\n",
       "   1.2272606412569682,\n",
       "   1.2042508562405905,\n",
       "   1.130457846323649,\n",
       "   1.1884526888529459,\n",
       "   1.0991405129432679,\n",
       "   1.093926187356313,\n",
       "   1.0277543624242147,\n",
       "   0.9567871610323588,\n",
       "   0.9644739468892415,\n",
       "   0.9375605861345927,\n",
       "   1.0585479299227396,\n",
       "   0.9089452028274536,\n",
       "   0.8560126543045044,\n",
       "   0.8791208863258362,\n",
       "   0.8302320798238119,\n",
       "   0.7954714218775432,\n",
       "   0.7672540744145712,\n",
       "   0.7466462691624959,\n",
       "   0.9410417675971985,\n",
       "   1.0177035808563233,\n",
       "   0.7216288685798645,\n",
       "   0.7013032734394073,\n",
       "   0.674214905500412,\n",
       "   0.8999185897409916,\n",
       "   0.6671839356422424],\n",
       "  'val_losses': [7.8063859939575195,\n",
       "   4.89239501953125,\n",
       "   4.7471923828125,\n",
       "   4.1953853368759155,\n",
       "   4.253803610801697,\n",
       "   3.8026152849197388,\n",
       "   3.670071244239807,\n",
       "   3.7287867069244385,\n",
       "   3.757263660430908,\n",
       "   3.286543607711792,\n",
       "   3.2592474222183228,\n",
       "   2.955655336380005,\n",
       "   2.730165123939514,\n",
       "   2.755580186843872,\n",
       "   2.586585521697998,\n",
       "   2.365249991416931,\n",
       "   2.3543083667755127,\n",
       "   2.5390623807907104,\n",
       "   2.3056188225746155,\n",
       "   2.0943446159362793,\n",
       "   2.0446996688842773,\n",
       "   2.1045323610305786,\n",
       "   1.9841439127922058,\n",
       "   1.9275193214416504,\n",
       "   1.9797936081886292,\n",
       "   1.975904941558838,\n",
       "   2.435043692588806,\n",
       "   1.9420691132545471,\n",
       "   1.870375394821167,\n",
       "   2.0012503266334534,\n",
       "   1.79082590341568,\n",
       "   1.8383386135101318,\n",
       "   1.9172576665878296,\n",
       "   1.8291433453559875,\n",
       "   1.865313470363617,\n",
       "   2.003881096839905,\n",
       "   1.8328863382339478,\n",
       "   1.8415669798851013,\n",
       "   1.780937373638153,\n",
       "   1.8770207166671753,\n",
       "   1.9269516468048096,\n",
       "   1.8057004809379578]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.672 -3.610212\n",
       "  1   -3.290 -4.623510\n",
       "  2   -4.120 -5.200264\n",
       "  3   -3.460 -3.601141\n",
       "  4   -1.990 -1.179294\n",
       "  ..     ...       ...\n",
       "  44  -3.120 -3.285465\n",
       "  45  -3.168 -2.627663\n",
       "  46  -3.460 -2.343143\n",
       "  47  -3.021 -3.815982\n",
       "  48  -3.094 -3.827029\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 77.54761624336243,\n",
       "  'mean_mse': 2.1943269,\n",
       "  'mean_l1': 1.0981159,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1): GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [9.282157802581787,\n",
       "   4.142723433176676,\n",
       "   3.943493366241455,\n",
       "   3.5685895442962647,\n",
       "   3.2907413721084593,\n",
       "   3.2704654852549235,\n",
       "   3.131107298533122,\n",
       "   2.762870677312215,\n",
       "   2.7400193373362223,\n",
       "   2.705467669169108,\n",
       "   2.663233423233032,\n",
       "   2.4917524337768553,\n",
       "   2.420353102684021,\n",
       "   2.1819503625233967,\n",
       "   2.1796809434890747,\n",
       "   1.9970949014027914,\n",
       "   1.933935292561849,\n",
       "   2.0009706258773803,\n",
       "   2.293321879704793,\n",
       "   1.6844857613245645,\n",
       "   1.5674361308415732,\n",
       "   1.6684784094492595,\n",
       "   1.4911139647165934,\n",
       "   1.4993076999982198,\n",
       "   1.4271718740463257,\n",
       "   1.3559841861327488,\n",
       "   1.4985844135284423,\n",
       "   1.2669947624206543,\n",
       "   1.4950058182080588,\n",
       "   1.2235397179921468,\n",
       "   1.2454518755276998,\n",
       "   1.2077011903127035,\n",
       "   1.3001765092213948,\n",
       "   1.1485450863838196,\n",
       "   1.1142019669214884,\n",
       "   1.1152228792508443,\n",
       "   1.185814913113912,\n",
       "   1.0995457172393799,\n",
       "   1.1321159680684407,\n",
       "   1.1126607338587442,\n",
       "   1.0365357875823975,\n",
       "   1.2169498880704244,\n",
       "   1.226196297009786,\n",
       "   1.0409034172693887],\n",
       "  'val_losses': [9.372557878494263,\n",
       "   5.02699875831604,\n",
       "   4.763882637023926,\n",
       "   4.699126958847046,\n",
       "   4.648951530456543,\n",
       "   4.99590790271759,\n",
       "   4.57734489440918,\n",
       "   4.622087717056274,\n",
       "   4.315746426582336,\n",
       "   4.233401536941528,\n",
       "   4.284796953201294,\n",
       "   4.193287134170532,\n",
       "   3.7729477882385254,\n",
       "   3.4991114139556885,\n",
       "   3.7395665645599365,\n",
       "   3.568637490272522,\n",
       "   2.960040330886841,\n",
       "   2.790033459663391,\n",
       "   2.6387391090393066,\n",
       "   2.6636940240859985,\n",
       "   2.5656425952911377,\n",
       "   2.4801924228668213,\n",
       "   2.6825098991394043,\n",
       "   2.2620969414711,\n",
       "   2.2522337436676025,\n",
       "   2.1302073001861572,\n",
       "   2.455224871635437,\n",
       "   2.108971953392029,\n",
       "   2.225998818874359,\n",
       "   2.2260460257530212,\n",
       "   2.191961884498596,\n",
       "   2.178048253059387,\n",
       "   2.230653166770935,\n",
       "   2.5404679775238037,\n",
       "   2.4011003971099854,\n",
       "   2.1675650477409363,\n",
       "   2.298305869102478,\n",
       "   2.188718318939209,\n",
       "   2.1353124380111694,\n",
       "   2.2720056772232056,\n",
       "   2.1543997526168823,\n",
       "   2.0303242206573486,\n",
       "   2.008767306804657,\n",
       "   2.144901752471924]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.930 -3.264761\n",
       "  1   -4.380 -4.353372\n",
       "  2   -3.050 -3.525409\n",
       "  3   -4.950 -3.451988\n",
       "  4   -2.281 -2.567681\n",
       "  ..     ...       ...\n",
       "  44  -7.280 -3.964998\n",
       "  45  -4.743 -4.876507\n",
       "  46  -5.190 -5.395742\n",
       "  47  -4.883 -5.314796\n",
       "  48  -3.451 -4.822879\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 79.6144950389862,\n",
       "  'mean_mse': 1.6390457,\n",
       "  'mean_l1': 0.97821015,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1): GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [9.80547742843628,\n",
       "   3.8722640832265216,\n",
       "   3.5974220911661785,\n",
       "   3.2476895809173585,\n",
       "   3.154091787338257,\n",
       "   2.7041526953379313,\n",
       "   2.518838119506836,\n",
       "   2.4319682121276855,\n",
       "   2.324748953183492,\n",
       "   2.10696698029836,\n",
       "   1.956831192970276,\n",
       "   1.8490314245224,\n",
       "   1.7961172024408976,\n",
       "   1.8417971054712932,\n",
       "   1.7061237255732218,\n",
       "   1.57629501024882,\n",
       "   1.4980165878931682,\n",
       "   1.5824451367060344,\n",
       "   1.5073766350746154,\n",
       "   1.4604766766230266,\n",
       "   1.5440319458643594,\n",
       "   1.3307738780975342,\n",
       "   1.3225265661875407,\n",
       "   1.2677839279174805,\n",
       "   1.2192341287930806,\n",
       "   1.1487850288550059,\n",
       "   1.153215722242991,\n",
       "   1.1701952616373699,\n",
       "   1.0784937461217246,\n",
       "   1.092261012395223,\n",
       "   1.0445380528767905,\n",
       "   1.1558960596720378,\n",
       "   1.0547455986340841,\n",
       "   1.0130713661511739,\n",
       "   1.0050820092360178,\n",
       "   0.988229509194692,\n",
       "   1.0263018329938254,\n",
       "   1.0770235578219096,\n",
       "   1.059486242135366,\n",
       "   0.9973411719004314,\n",
       "   0.9399269938468933,\n",
       "   0.9495696187019348,\n",
       "   1.0183755040168763,\n",
       "   0.8650227089722952,\n",
       "   0.8776848455270131,\n",
       "   0.8822416126728058,\n",
       "   0.8716598927974701],\n",
       "  'val_losses': [7.745280504226685,\n",
       "   4.830937147140503,\n",
       "   5.001428127288818,\n",
       "   4.110766887664795,\n",
       "   4.046369433403015,\n",
       "   4.132982492446899,\n",
       "   4.045113205909729,\n",
       "   3.7633962631225586,\n",
       "   3.65689754486084,\n",
       "   3.4361815452575684,\n",
       "   3.5000357627868652,\n",
       "   3.1594513654708862,\n",
       "   3.079300284385681,\n",
       "   2.9639878273010254,\n",
       "   3.0644805431365967,\n",
       "   2.7668681144714355,\n",
       "   2.8760353326797485,\n",
       "   2.893378257751465,\n",
       "   2.5841108560562134,\n",
       "   2.556329607963562,\n",
       "   2.523048162460327,\n",
       "   2.4989224672317505,\n",
       "   2.5963584184646606,\n",
       "   2.316396951675415,\n",
       "   2.3897252082824707,\n",
       "   2.360458254814148,\n",
       "   2.2040328979492188,\n",
       "   2.2258743047714233,\n",
       "   2.467994749546051,\n",
       "   2.511088490486145,\n",
       "   2.2353888750076294,\n",
       "   2.2265824675559998,\n",
       "   2.0954408645629883,\n",
       "   2.0793174505233765,\n",
       "   2.0099252462387085,\n",
       "   2.120272934436798,\n",
       "   2.0595253705978394,\n",
       "   2.0354697704315186,\n",
       "   2.028733491897583,\n",
       "   2.025329828262329,\n",
       "   1.9924106001853943,\n",
       "   1.9042934775352478,\n",
       "   2.0066111087799072,\n",
       "   1.9559029936790466,\n",
       "   1.9845890402793884,\n",
       "   1.944744050502777,\n",
       "   2.086394429206848]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.716 -3.427165\n",
       "  1   -1.990 -0.630720\n",
       "  2   -2.070 -4.069614\n",
       "  3   -4.370 -3.942702\n",
       "  4   -6.800 -6.010814\n",
       "  ..     ...       ...\n",
       "  44  -3.880 -3.632973\n",
       "  45  -2.266 -1.260151\n",
       "  46  -3.060 -2.480747\n",
       "  47  -8.000 -7.652788\n",
       "  48  -6.780 -5.210084\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 49.21515607833862,\n",
       "  'mean_mse': 1.8692635,\n",
       "  'mean_l1': 1.0711238,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-2): 2 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.5066698551177975,\n",
       "   3.546428136030833,\n",
       "   2.7476664145787555,\n",
       "   2.2232441266377765,\n",
       "   2.0969760258992514,\n",
       "   1.9724989096323648,\n",
       "   1.5795297026634216,\n",
       "   1.3891275266806284,\n",
       "   1.2803666194279988,\n",
       "   1.2663506110509237,\n",
       "   1.1196518143018086,\n",
       "   1.3182663679122926,\n",
       "   1.2089266459147134,\n",
       "   1.0292098641395568,\n",
       "   1.024025297164917,\n",
       "   0.9690387765566508,\n",
       "   1.1563671668370565,\n",
       "   0.9338278452555339,\n",
       "   0.9505799651145935,\n",
       "   0.804114451011022,\n",
       "   0.7460436503092448,\n",
       "   0.7344541827837626,\n",
       "   0.9121038496494294,\n",
       "   0.8528670867284139],\n",
       "  'val_losses': [5.017389535903931,\n",
       "   4.327238440513611,\n",
       "   4.0201274156570435,\n",
       "   4.157100796699524,\n",
       "   3.3858143091201782,\n",
       "   3.673766016960144,\n",
       "   2.6467500925064087,\n",
       "   2.4682257175445557,\n",
       "   2.399751901626587,\n",
       "   2.7987254858016968,\n",
       "   2.0048945546150208,\n",
       "   1.9715012311935425,\n",
       "   2.1607086658477783,\n",
       "   2.2031136751174927,\n",
       "   2.3163204193115234,\n",
       "   2.076283276081085,\n",
       "   1.9642618298530579,\n",
       "   2.14471971988678,\n",
       "   2.5496233701705933,\n",
       "   2.3403807282447815,\n",
       "   1.9963973760604858,\n",
       "   2.270716071128845,\n",
       "   2.207690954208374,\n",
       "   1.8448379635810852]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.349 -2.252894\n",
       "  1   -2.100 -1.423950\n",
       "  2   -3.120 -3.164342\n",
       "  3   -6.680 -7.121240\n",
       "  4   -4.450 -2.390303\n",
       "  ..     ...       ...\n",
       "  44  -5.190 -4.567689\n",
       "  45  -7.280 -3.734195\n",
       "  46  -6.800 -9.888711\n",
       "  47  -8.000 -8.091286\n",
       "  48  -4.883 -4.427948\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 85.17537879943848,\n",
       "  'mean_mse': 1.7181768,\n",
       "  'mean_l1': 1.0258343,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-2): 2 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [9.61024351119995,\n",
       "   3.7533711512883503,\n",
       "   3.4744701027870177,\n",
       "   3.1990370114644366,\n",
       "   3.1268639087677004,\n",
       "   2.735313892364502,\n",
       "   2.297065838177999,\n",
       "   2.342133148511251,\n",
       "   2.1147772391637165,\n",
       "   1.837603012720744,\n",
       "   1.7617662270863852,\n",
       "   1.5475448449452718,\n",
       "   1.5115792473157248,\n",
       "   1.339514038960139,\n",
       "   1.2229320446650187,\n",
       "   1.3858360767364502,\n",
       "   1.2535903255144756,\n",
       "   1.3658849000930786,\n",
       "   1.2630980829397838,\n",
       "   1.115764864285787,\n",
       "   1.0864136258761088,\n",
       "   1.0822203675905864,\n",
       "   1.106525957584381,\n",
       "   1.0082379579544067,\n",
       "   1.3586247205734252,\n",
       "   1.0496683557828268,\n",
       "   0.9516413827737172,\n",
       "   0.9831455469131469,\n",
       "   1.022315243879954,\n",
       "   0.9834922830263774,\n",
       "   0.9491659879684449,\n",
       "   0.9636836767196655,\n",
       "   0.9905035098393759,\n",
       "   0.83580628434817,\n",
       "   0.8717531323432922,\n",
       "   0.8897095620632172,\n",
       "   0.8480050245920817,\n",
       "   0.843215270837148,\n",
       "   0.8380286554495494,\n",
       "   0.8812470306952794,\n",
       "   0.7913411935170491,\n",
       "   0.7563948184251785,\n",
       "   0.7241215308507284],\n",
       "  'val_losses': [9.847511291503906,\n",
       "   4.794103384017944,\n",
       "   4.748643159866333,\n",
       "   4.229404807090759,\n",
       "   5.186021566390991,\n",
       "   3.7529972791671753,\n",
       "   3.4513444900512695,\n",
       "   3.434012770652771,\n",
       "   3.4681252241134644,\n",
       "   2.5579460859298706,\n",
       "   2.3747657537460327,\n",
       "   2.117878556251526,\n",
       "   2.633521318435669,\n",
       "   2.0836313366889954,\n",
       "   2.1035921573638916,\n",
       "   2.58670437335968,\n",
       "   2.534730315208435,\n",
       "   1.9176077842712402,\n",
       "   2.540380358695984,\n",
       "   2.207696557044983,\n",
       "   2.220263183116913,\n",
       "   1.9908656477928162,\n",
       "   2.6266400814056396,\n",
       "   1.8352099657058716,\n",
       "   2.174891769886017,\n",
       "   1.860581874847412,\n",
       "   1.8428283333778381,\n",
       "   1.8562921285629272,\n",
       "   1.9104768633842468,\n",
       "   1.8073193430900574,\n",
       "   2.612885594367981,\n",
       "   1.838472604751587,\n",
       "   1.9735131859779358,\n",
       "   1.8390802145004272,\n",
       "   1.7760018706321716,\n",
       "   1.7279973030090332,\n",
       "   1.7901975512504578,\n",
       "   1.74183189868927,\n",
       "   2.4471429586410522,\n",
       "   1.7789645791053772,\n",
       "   2.175271153450012,\n",
       "   1.7403690814971924,\n",
       "   1.7866754531860352]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.270 -3.939650\n",
       "  1   -4.805 -1.909385\n",
       "  2   -3.880 -2.016235\n",
       "  3    0.522 -0.590635\n",
       "  4   -3.460 -5.015414\n",
       "  ..     ...       ...\n",
       "  44  -9.018 -4.230117\n",
       "  45  -3.060 -3.900720\n",
       "  46  -1.990 -3.945398\n",
       "  47  -2.120 -1.957337\n",
       "  48  -5.915 -4.318786\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 94.45434260368347,\n",
       "  'mean_mse': 3.061537,\n",
       "  'mean_l1': 1.3504741,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [14.800938987731934,\n",
       "   4.104070123036703,\n",
       "   3.8781524181365965,\n",
       "   3.598211574554443,\n",
       "   3.3880948861440023,\n",
       "   3.5798471927642823,\n",
       "   3.2596595764160154,\n",
       "   3.2721052805582684,\n",
       "   3.1556920846303305,\n",
       "   3.105971686045329,\n",
       "   3.076427936553955,\n",
       "   3.3886216481526694,\n",
       "   2.786616766452789,\n",
       "   2.7577714999516805,\n",
       "   2.8272213141123452,\n",
       "   2.694468037287394,\n",
       "   2.990862584114075,\n",
       "   2.649566157658895,\n",
       "   2.7145228147506715,\n",
       "   2.4557844003041587,\n",
       "   2.4124134302139284,\n",
       "   2.365484054883321,\n",
       "   2.3433053572972615,\n",
       "   2.2745145400365194,\n",
       "   2.285343130429586,\n",
       "   2.2711910009384155,\n",
       "   2.1820401350657144,\n",
       "   2.297042949994405,\n",
       "   2.1965688784917194,\n",
       "   2.077297902107239,\n",
       "   2.380360213915507,\n",
       "   2.131902813911438,\n",
       "   2.0413470109303793,\n",
       "   2.1295958121617633,\n",
       "   1.9403165300687155,\n",
       "   2.2400081316630045,\n",
       "   2.0311385949452716,\n",
       "   1.8721544439593951,\n",
       "   2.0273658831914267,\n",
       "   1.881081267197927,\n",
       "   1.9720437367757162,\n",
       "   1.9221930424372355,\n",
       "   1.9302008549372356,\n",
       "   1.827874441941579,\n",
       "   1.9826817194620767,\n",
       "   1.8889097452163697,\n",
       "   1.864135193824768,\n",
       "   1.734518470366796,\n",
       "   1.8855814456939697,\n",
       "   1.8705893198649088,\n",
       "   1.9277990659077961,\n",
       "   1.730412276585897,\n",
       "   1.74388427734375,\n",
       "   2.033658337593079,\n",
       "   1.6734803756078085,\n",
       "   1.7310420831044515,\n",
       "   1.8829634269078572],\n",
       "  'val_losses': [16.396684646606445,\n",
       "   5.205287456512451,\n",
       "   5.124354124069214,\n",
       "   4.900841236114502,\n",
       "   4.585355758666992,\n",
       "   4.23891282081604,\n",
       "   4.31355094909668,\n",
       "   4.22596800327301,\n",
       "   4.290089130401611,\n",
       "   4.21259617805481,\n",
       "   4.392581582069397,\n",
       "   4.21940815448761,\n",
       "   4.342534184455872,\n",
       "   4.3463054895401,\n",
       "   4.274850368499756,\n",
       "   4.089327454566956,\n",
       "   4.245384931564331,\n",
       "   4.155082821846008,\n",
       "   4.191918849945068,\n",
       "   4.054623126983643,\n",
       "   4.186818838119507,\n",
       "   4.124459981918335,\n",
       "   4.066916227340698,\n",
       "   3.8741087913513184,\n",
       "   4.175514340400696,\n",
       "   4.101724743843079,\n",
       "   3.8962050676345825,\n",
       "   3.9933043718338013,\n",
       "   3.9390711784362793,\n",
       "   3.9298821687698364,\n",
       "   3.850759267807007,\n",
       "   3.6233673095703125,\n",
       "   3.7884294986724854,\n",
       "   3.760326385498047,\n",
       "   3.6005759239196777,\n",
       "   3.6366024017333984,\n",
       "   3.5266005992889404,\n",
       "   3.745832920074463,\n",
       "   3.718348979949951,\n",
       "   3.3397845029830933,\n",
       "   3.440050959587097,\n",
       "   3.3937666416168213,\n",
       "   3.437772512435913,\n",
       "   3.35578191280365,\n",
       "   3.4603922367095947,\n",
       "   3.289151906967163,\n",
       "   3.3260602951049805,\n",
       "   3.310234308242798,\n",
       "   3.3209495544433594,\n",
       "   3.4174548387527466,\n",
       "   3.2256109714508057,\n",
       "   3.1843940019607544,\n",
       "   3.183331847190857,\n",
       "   3.1545515060424805,\n",
       "   3.3303844928741455,\n",
       "   3.211885690689087,\n",
       "   3.1291171312332153]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.070 -4.500014\n",
       "  1   -6.726 -6.165729\n",
       "  2   -3.583 -1.572376\n",
       "  3   -3.246 -4.966200\n",
       "  4   -1.040 -3.102355\n",
       "  ..     ...       ...\n",
       "  44  -4.310 -5.235042\n",
       "  45  -2.100 -1.434300\n",
       "  46  -1.800 -2.608706\n",
       "  47  -0.742 -1.242482\n",
       "  48   1.100  0.169582\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 34.06398892402649,\n",
       "  'mean_mse': 1.952973,\n",
       "  'mean_l1': 1.1073835,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-2): 2 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.5718507448832195,\n",
       "   3.457096878687541,\n",
       "   2.8505283037821454,\n",
       "   2.2408504486083984,\n",
       "   2.070394444465637,\n",
       "   1.8735097885131835,\n",
       "   1.605659023920695,\n",
       "   1.3843265970547993,\n",
       "   1.3576553106307983,\n",
       "   1.1814881881078085,\n",
       "   1.1149547100067139,\n",
       "   1.036255939801534,\n",
       "   0.9604409694671631,\n",
       "   0.9215649445851644,\n",
       "   0.8089923024177551,\n",
       "   0.8297303199768067,\n",
       "   1.0122371157010397],\n",
       "  'val_losses': [5.2389020919799805,\n",
       "   4.212519645690918,\n",
       "   4.259310960769653,\n",
       "   4.079998731613159,\n",
       "   3.8945882320404053,\n",
       "   3.0199387073516846,\n",
       "   2.479832887649536,\n",
       "   3.6600006818771362,\n",
       "   2.2188892364501953,\n",
       "   1.751861810684204,\n",
       "   1.791079819202423,\n",
       "   1.9997262954711914,\n",
       "   2.890608549118042,\n",
       "   1.8150549530982971,\n",
       "   1.8152304887771606,\n",
       "   1.825801134109497,\n",
       "   1.8388848900794983]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -8.600 -6.570939\n",
       "  1   -4.925 -4.449844\n",
       "  2   -3.360 -4.684294\n",
       "  3   -2.349 -2.285472\n",
       "  4   -4.310 -4.046120\n",
       "  ..     ...       ...\n",
       "  44  -0.742 -1.063442\n",
       "  45  -3.290 -5.600157\n",
       "  46  -3.590 -4.962970\n",
       "  47  -5.000 -5.592255\n",
       "  48   1.100  0.042190\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 44.86062955856323,\n",
       "  'mean_mse': 1.7826945,\n",
       "  'mean_l1': 1.063235,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-3): 3 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.393460321426391,\n",
       "   3.6040006637573243,\n",
       "   3.25512220064799,\n",
       "   2.361793279647827,\n",
       "   1.9968079408009847,\n",
       "   1.5067663272221883,\n",
       "   1.7212740858395894,\n",
       "   1.2112250477075577,\n",
       "   1.1494699637095134,\n",
       "   1.1682562371095022,\n",
       "   1.0784425894419352,\n",
       "   1.0345529794692994,\n",
       "   1.0288758238156637,\n",
       "   0.8966435750325521,\n",
       "   0.9374272187550863,\n",
       "   0.8510320742925008,\n",
       "   0.8293954869111378,\n",
       "   0.9631464719772339,\n",
       "   0.7554000496864319],\n",
       "  'val_losses': [4.745564699172974,\n",
       "   5.1591198444366455,\n",
       "   3.9068708419799805,\n",
       "   3.8953211307525635,\n",
       "   3.25232195854187,\n",
       "   3.149146318435669,\n",
       "   2.442656636238098,\n",
       "   2.414449095726013,\n",
       "   2.20233690738678,\n",
       "   1.9751482009887695,\n",
       "   1.9640995264053345,\n",
       "   2.1357680559158325,\n",
       "   1.9934877157211304,\n",
       "   2.5378326177597046,\n",
       "   2.661181330680847,\n",
       "   2.060366153717041,\n",
       "   1.7623722553253174,\n",
       "   2.1109626293182373,\n",
       "   1.915672481060028]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.281 -2.143073\n",
       "  1   -5.696 -5.497747\n",
       "  2   -3.538 -4.520967\n",
       "  3   -4.310 -4.233186\n",
       "  4   -3.638 -2.265496\n",
       "  ..     ...       ...\n",
       "  44  -3.050 -4.350123\n",
       "  45  -1.990 -3.247259\n",
       "  46  -4.799 -4.340686\n",
       "  47  -2.100 -1.887747\n",
       "  48  -8.040 -7.109634\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 48.51041054725647,\n",
       "  'mean_mse': 1.6638286,\n",
       "  'mean_l1': 0.9831178,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-3): 3 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.6259897470474245,\n",
       "   4.008297602335612,\n",
       "   3.5827865759531656,\n",
       "   2.7236453533172607,\n",
       "   2.346843163172404,\n",
       "   2.057767868041992,\n",
       "   1.9442428668340048,\n",
       "   1.7824682076772054,\n",
       "   1.3537224054336547,\n",
       "   1.5287479599316915,\n",
       "   1.4640857060750325,\n",
       "   1.2164838234583537,\n",
       "   1.1754002690315246,\n",
       "   0.9637303342421849,\n",
       "   0.9824894944826762,\n",
       "   0.8986788014570872,\n",
       "   1.0470922231674193,\n",
       "   1.2538742542266845,\n",
       "   1.126577619711558,\n",
       "   0.8939584175745646,\n",
       "   0.8185271819432577,\n",
       "   0.8471485416094462],\n",
       "  'val_losses': [6.544674396514893,\n",
       "   4.826731204986572,\n",
       "   4.349809408187866,\n",
       "   4.071244835853577,\n",
       "   3.3143259286880493,\n",
       "   3.889085292816162,\n",
       "   3.9383667707443237,\n",
       "   2.3191500902175903,\n",
       "   2.3256713151931763,\n",
       "   3.2596988677978516,\n",
       "   2.90435791015625,\n",
       "   2.079015612602234,\n",
       "   2.5368542671203613,\n",
       "   1.980999231338501,\n",
       "   1.9072819948196411,\n",
       "   2.3675343990325928,\n",
       "   1.8321989178657532,\n",
       "   2.1909533739089966,\n",
       "   2.259635627269745,\n",
       "   2.1064902544021606,\n",
       "   1.9278180599212646,\n",
       "   1.943876028060913]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    0.790  0.236172\n",
       "  1   -2.160 -1.720015\n",
       "  2   -4.445 -5.101621\n",
       "  3   -2.349 -2.089272\n",
       "  4   -5.190 -2.781692\n",
       "  ..     ...       ...\n",
       "  44  -3.800 -4.334553\n",
       "  45  -4.632 -2.900621\n",
       "  46  -3.583 -1.513687\n",
       "  47  -3.043 -2.711027\n",
       "  48  -2.932 -0.862944\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 73.03480792045593,\n",
       "  'mean_mse': 1.6670423,\n",
       "  'mean_l1': 1.0039947,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-3): 3 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [9.015510336558025,\n",
       "   3.6406769355138144,\n",
       "   3.3162397543589273,\n",
       "   2.6604662418365477,\n",
       "   2.4221816937128704,\n",
       "   1.9520197629928588,\n",
       "   2.2728926658630373,\n",
       "   1.6235349655151368,\n",
       "   1.389796006679535,\n",
       "   1.3782169421513875,\n",
       "   1.1572546680768332,\n",
       "   1.1604811469713847,\n",
       "   1.173087728023529,\n",
       "   1.2722968459129333,\n",
       "   1.0083049098650614,\n",
       "   0.9410125295321147,\n",
       "   0.9136905491352081,\n",
       "   0.8762603481610616,\n",
       "   0.770291656255722,\n",
       "   0.7312788208325703,\n",
       "   0.8113893548647563,\n",
       "   0.6971104164918264,\n",
       "   0.6842987477779389,\n",
       "   0.8373891015847524,\n",
       "   0.6368724018335342,\n",
       "   0.6653965254624684,\n",
       "   0.6597132762273152,\n",
       "   0.7354372421900431,\n",
       "   0.5889041264851888,\n",
       "   0.5133541539311409,\n",
       "   0.6104672690232594,\n",
       "   0.48074648479620613,\n",
       "   0.47313175797462464],\n",
       "  'val_losses': [6.759976625442505,\n",
       "   5.01034951210022,\n",
       "   4.17921257019043,\n",
       "   3.8734846115112305,\n",
       "   4.411785840988159,\n",
       "   3.3920512199401855,\n",
       "   3.212283968925476,\n",
       "   3.1727232933044434,\n",
       "   2.416372299194336,\n",
       "   2.4000052213668823,\n",
       "   2.1253944635391235,\n",
       "   2.103459358215332,\n",
       "   1.9132187366485596,\n",
       "   2.215579330921173,\n",
       "   1.9805906414985657,\n",
       "   1.7082934379577637,\n",
       "   1.9941141605377197,\n",
       "   1.9737910628318787,\n",
       "   1.6990763545036316,\n",
       "   1.9031888842582703,\n",
       "   1.7824251055717468,\n",
       "   1.554656207561493,\n",
       "   1.6033408045768738,\n",
       "   1.4705308079719543,\n",
       "   1.7994256615638733,\n",
       "   1.6697916984558105,\n",
       "   1.5942930579185486,\n",
       "   1.6298211216926575,\n",
       "   1.4747332334518433,\n",
       "   1.441035807132721,\n",
       "   1.4060267806053162,\n",
       "   1.4497195482254028,\n",
       "   1.4324654340744019]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.658 -5.340091\n",
       "  1   -2.700 -3.182073\n",
       "  2   -4.402 -4.404143\n",
       "  3   -3.460 -4.848202\n",
       "  4   -2.266 -2.747826\n",
       "  ..     ...       ...\n",
       "  44  -3.538 -3.815911\n",
       "  45  -6.780 -3.963766\n",
       "  46  -2.920 -2.008306\n",
       "  47  -3.610 -3.373849\n",
       "  48  -2.281 -2.894523\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 98.01135420799255,\n",
       "  'mean_mse': 1.8790804,\n",
       "  'mean_l1': 1.0708022,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [8.005008427302043,\n",
       "   3.7043697516123455,\n",
       "   3.400561459859212,\n",
       "   3.5080035448074343,\n",
       "   3.132176939646403,\n",
       "   3.1072385629018147,\n",
       "   2.8102567354838053,\n",
       "   2.740845052401225,\n",
       "   2.694480276107788,\n",
       "   2.8746748129526773,\n",
       "   2.7125724156697593,\n",
       "   2.413022748629252,\n",
       "   2.312717898686727,\n",
       "   2.230485510826111,\n",
       "   2.213096841176351,\n",
       "   2.193187959988912,\n",
       "   2.0450398365656537,\n",
       "   2.29442032178243,\n",
       "   1.966363298892975,\n",
       "   1.9896233956019083,\n",
       "   1.9856706619262696,\n",
       "   1.9526127815246581,\n",
       "   1.853361709912618,\n",
       "   1.8567048549652099,\n",
       "   1.7643605868021648,\n",
       "   1.737134091059367,\n",
       "   1.784982148806254,\n",
       "   1.7299688577651977,\n",
       "   1.8990297714869182,\n",
       "   1.6139611800511677,\n",
       "   1.6960831562678018,\n",
       "   1.7405807018280028,\n",
       "   1.5340440630912782,\n",
       "   1.5650888005892436,\n",
       "   1.7425079902013143,\n",
       "   1.6101847569147745,\n",
       "   1.5949456055959066,\n",
       "   1.448251191775004,\n",
       "   1.4442603508631389,\n",
       "   1.5040560086568198,\n",
       "   1.5706427574157715,\n",
       "   1.4202365438143412,\n",
       "   1.5014729579289754,\n",
       "   1.394819168249766,\n",
       "   1.3574620445569356,\n",
       "   1.3725440502166748,\n",
       "   1.33343665599823,\n",
       "   1.2805762191613514,\n",
       "   1.3689102133115132,\n",
       "   1.394190994898478,\n",
       "   1.3973800579706828,\n",
       "   1.3041613618532817,\n",
       "   1.3329120715459188,\n",
       "   1.3179945747057598,\n",
       "   1.236325470606486,\n",
       "   1.3070127407709757,\n",
       "   1.1812628865242005,\n",
       "   1.1826565742492676,\n",
       "   1.1465627551078796,\n",
       "   1.1631638367970785,\n",
       "   1.214338982105255],\n",
       "  'val_losses': [7.370361804962158,\n",
       "   4.994804859161377,\n",
       "   4.579511880874634,\n",
       "   4.264878749847412,\n",
       "   4.2730712890625,\n",
       "   4.1879723072052,\n",
       "   4.072366237640381,\n",
       "   4.224378824234009,\n",
       "   4.039556860923767,\n",
       "   4.322049260139465,\n",
       "   3.9111123085021973,\n",
       "   4.181743621826172,\n",
       "   3.9138059616088867,\n",
       "   3.7469863891601562,\n",
       "   3.8965413570404053,\n",
       "   3.611841320991516,\n",
       "   3.6781927347183228,\n",
       "   3.4498761892318726,\n",
       "   3.527446150779724,\n",
       "   3.446788191795349,\n",
       "   3.2673548460006714,\n",
       "   3.215690016746521,\n",
       "   3.249778389930725,\n",
       "   3.1503912210464478,\n",
       "   3.1794514656066895,\n",
       "   3.069585919380188,\n",
       "   3.0215665102005005,\n",
       "   3.028593897819519,\n",
       "   2.9180327653884888,\n",
       "   2.6998414993286133,\n",
       "   2.8865416049957275,\n",
       "   2.716904401779175,\n",
       "   2.6378356218338013,\n",
       "   2.6259961128234863,\n",
       "   2.727408289909363,\n",
       "   2.723872661590576,\n",
       "   2.4274353981018066,\n",
       "   2.4909467697143555,\n",
       "   2.4215588569641113,\n",
       "   2.5912434458732605,\n",
       "   2.348417282104492,\n",
       "   2.550478458404541,\n",
       "   2.3421682119369507,\n",
       "   2.602903723716736,\n",
       "   2.3697359561920166,\n",
       "   2.233253598213196,\n",
       "   2.39399254322052,\n",
       "   2.27532559633255,\n",
       "   2.208246111869812,\n",
       "   2.1053227186203003,\n",
       "   2.317738652229309,\n",
       "   2.161881685256958,\n",
       "   2.328042507171631,\n",
       "   2.281609535217285,\n",
       "   2.4818684458732605,\n",
       "   2.14687716960907,\n",
       "   2.2766306400299072,\n",
       "   2.142051577568054,\n",
       "   2.1794466972351074,\n",
       "   2.1133227348327637,\n",
       "   2.058039426803589]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.120 -3.019654\n",
       "  1   -5.410 -5.356654\n",
       "  2   -1.800 -2.762305\n",
       "  3    0.522 -0.288683\n",
       "  4   -5.220 -4.751989\n",
       "  ..     ...       ...\n",
       "  44  -4.799 -3.488463\n",
       "  45  -0.600 -1.966362\n",
       "  46  -2.266 -2.752186\n",
       "  47  -4.950 -3.329020\n",
       "  48  -6.726 -5.030584\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 128.63520216941833,\n",
       "  'mean_mse': 2.007505,\n",
       "  'mean_l1': 1.0795025,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [9.069120375315348,\n",
       "   3.9685909430185955,\n",
       "   4.021666256586711,\n",
       "   3.7487219174702964,\n",
       "   3.649420801798503,\n",
       "   3.5582991441090903,\n",
       "   3.446390962600708,\n",
       "   3.3308422565460205,\n",
       "   3.3718214988708497,\n",
       "   3.097625728448232,\n",
       "   3.147508668899536,\n",
       "   2.892907377084096,\n",
       "   3.021760272979736,\n",
       "   2.9313878218332925,\n",
       "   2.7964614550272624,\n",
       "   2.806127325693766,\n",
       "   2.7370222409566245,\n",
       "   2.6956633726755777,\n",
       "   2.6856173276901245,\n",
       "   2.6982743660608928,\n",
       "   2.4965674738089243,\n",
       "   2.5549702644348145,\n",
       "   2.4686586300532025,\n",
       "   2.5579100211461383,\n",
       "   2.4784836530685426,\n",
       "   2.39395694732666,\n",
       "   2.534083374341329,\n",
       "   2.970281489690145,\n",
       "   2.3610849380493164,\n",
       "   2.264938314755758,\n",
       "   2.2261216203371683,\n",
       "   2.2536187489827473,\n",
       "   2.4031882286071777,\n",
       "   2.2675191879272463,\n",
       "   2.2688071966171264,\n",
       "   2.136809992790222,\n",
       "   2.1951411247253416,\n",
       "   2.2355030218760175,\n",
       "   2.2541914701461794,\n",
       "   2.234189200401306,\n",
       "   2.061324691772461,\n",
       "   1.9712928692499796,\n",
       "   2.193633755048116,\n",
       "   2.1670631170272827,\n",
       "   1.9445686340332031,\n",
       "   2.04484494527181,\n",
       "   1.8289856734375158,\n",
       "   1.919346022605896,\n",
       "   1.952253770828247,\n",
       "   1.9218374729156493,\n",
       "   1.8932792266209921,\n",
       "   1.8330560207366944,\n",
       "   1.8577657063802084,\n",
       "   1.872175931930542,\n",
       "   1.7505918741226196,\n",
       "   1.8805653174718222,\n",
       "   1.769370436668396,\n",
       "   1.8012231190999348,\n",
       "   1.8104747931162517,\n",
       "   1.7708952665328979,\n",
       "   1.7460039933522542,\n",
       "   1.7996216773986817,\n",
       "   1.6767078439394634,\n",
       "   1.6903038660685221,\n",
       "   1.6786121129989624,\n",
       "   1.8440446376800537,\n",
       "   1.8596286376317341,\n",
       "   1.6313795407613119,\n",
       "   1.8237276117006938,\n",
       "   1.6144354343414307,\n",
       "   1.5946104367574057,\n",
       "   1.7153157631556193,\n",
       "   1.5434974312782288,\n",
       "   1.6008575280507407,\n",
       "   1.6701734383900961,\n",
       "   1.673240554332733,\n",
       "   1.5622660398483277,\n",
       "   1.6050308465957641,\n",
       "   1.5037780205408733,\n",
       "   1.5945799668629965,\n",
       "   1.6325308879216511,\n",
       "   1.55266432762146,\n",
       "   1.5568909804026285,\n",
       "   1.6012717247009278,\n",
       "   1.5699731508890789],\n",
       "  'val_losses': [10.65657091140747,\n",
       "   5.003796100616455,\n",
       "   4.634777545928955,\n",
       "   4.585130214691162,\n",
       "   4.5632195472717285,\n",
       "   4.511117458343506,\n",
       "   4.4422571659088135,\n",
       "   4.330594897270203,\n",
       "   4.656251907348633,\n",
       "   4.590690732002258,\n",
       "   4.542505502700806,\n",
       "   4.560989141464233,\n",
       "   4.410562992095947,\n",
       "   4.5809314250946045,\n",
       "   4.592979192733765,\n",
       "   4.361348390579224,\n",
       "   4.2401299476623535,\n",
       "   4.264413356781006,\n",
       "   4.445099115371704,\n",
       "   4.139307498931885,\n",
       "   4.051329970359802,\n",
       "   4.243571877479553,\n",
       "   4.251044511795044,\n",
       "   3.9443057775497437,\n",
       "   3.8713051080703735,\n",
       "   3.7267268896102905,\n",
       "   3.5953317880630493,\n",
       "   3.626601815223694,\n",
       "   3.835432291030884,\n",
       "   3.576116681098938,\n",
       "   3.6667394638061523,\n",
       "   3.4009023904800415,\n",
       "   3.4294464588165283,\n",
       "   3.2973415851593018,\n",
       "   3.2844003438949585,\n",
       "   3.3609163761138916,\n",
       "   3.471124768257141,\n",
       "   3.323927402496338,\n",
       "   3.0957731008529663,\n",
       "   3.1253061294555664,\n",
       "   3.045177698135376,\n",
       "   3.084133744239807,\n",
       "   2.7752373814582825,\n",
       "   3.022429347038269,\n",
       "   2.933171033859253,\n",
       "   2.8661911487579346,\n",
       "   2.9507893323898315,\n",
       "   3.133320450782776,\n",
       "   2.657897114753723,\n",
       "   2.7137179374694824,\n",
       "   2.7682849168777466,\n",
       "   2.881859064102173,\n",
       "   2.801414370536804,\n",
       "   2.7973185777664185,\n",
       "   2.703822374343872,\n",
       "   2.885359048843384,\n",
       "   2.6930603981018066,\n",
       "   2.6207518577575684,\n",
       "   2.517943859100342,\n",
       "   2.4941983222961426,\n",
       "   2.6809366941452026,\n",
       "   2.5439515113830566,\n",
       "   2.4110207557678223,\n",
       "   2.54325795173645,\n",
       "   2.4085726737976074,\n",
       "   2.331620216369629,\n",
       "   2.3616284132003784,\n",
       "   2.4709380865097046,\n",
       "   2.2938852310180664,\n",
       "   2.28639554977417,\n",
       "   2.2946304082870483,\n",
       "   2.307018518447876,\n",
       "   2.264900803565979,\n",
       "   2.463956356048584,\n",
       "   2.2646541595458984,\n",
       "   2.285764455795288,\n",
       "   2.4038140773773193,\n",
       "   2.2218433618545532,\n",
       "   2.2268608808517456,\n",
       "   2.089878022670746,\n",
       "   2.1894354224205017,\n",
       "   2.239397883415222,\n",
       "   2.1183127760887146,\n",
       "   2.411113739013672,\n",
       "   2.2834166288375854]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -0.600 -3.204388\n",
       "  1   -3.638 -3.774805\n",
       "  2   -3.043 -3.459767\n",
       "  3   -4.380 -4.063742\n",
       "  4   -3.538 -3.503768\n",
       "  ..     ...       ...\n",
       "  44  -5.270 -3.136544\n",
       "  45  -1.990 -3.484374\n",
       "  46  -6.680 -3.266088\n",
       "  47  -2.320 -3.442193\n",
       "  48  -4.160 -3.693582\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 22.886104583740234,\n",
       "  'mean_mse': 3.7048802,\n",
       "  'mean_l1': 1.422107,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [15.636564381917317,\n",
       "   3.9697043180465696,\n",
       "   3.715642714500427,\n",
       "   3.895857493082682,\n",
       "   3.471182918548584,\n",
       "   3.4855005105336505,\n",
       "   3.433531093597412,\n",
       "   3.2839736302693683,\n",
       "   3.1992857774098713,\n",
       "   3.2037399848302206,\n",
       "   3.1524381001790363,\n",
       "   2.958206860224406,\n",
       "   2.891003195444743,\n",
       "   2.9242892106374105,\n",
       "   2.739063016573588],\n",
       "  'val_losses': [15.249886989593506,\n",
       "   5.805335760116577,\n",
       "   5.157270669937134,\n",
       "   4.705927848815918,\n",
       "   4.504047274589539,\n",
       "   4.446075677871704,\n",
       "   4.360592842102051,\n",
       "   4.433483600616455,\n",
       "   4.363359689712524,\n",
       "   4.542288780212402,\n",
       "   4.342222809791565,\n",
       "   4.419077157974243,\n",
       "   4.6084794998168945,\n",
       "   4.367020845413208,\n",
       "   4.357917666435242]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -6.860 -8.217908\n",
       "  1   -4.805 -2.713264\n",
       "  2   -8.040 -6.524817\n",
       "  3   -4.173 -5.288417\n",
       "  4   -3.583 -2.001173\n",
       "  ..     ...       ...\n",
       "  44  -1.250  0.118955\n",
       "  45  -3.094 -2.108622\n",
       "  46  -2.349 -1.955031\n",
       "  47   1.100 -0.359120\n",
       "  48  -3.620 -3.398389\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 146.07844972610474,\n",
       "  'mean_mse': 1.8513316,\n",
       "  'mean_l1': 1.0745431,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1): GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.06999618212382,\n",
       "   3.848517576853434,\n",
       "   3.216973654429118,\n",
       "   2.9372883160909016,\n",
       "   2.63748615582784,\n",
       "   2.430845399697622,\n",
       "   2.578214732805888,\n",
       "   2.236145353317261,\n",
       "   2.1905686378479006,\n",
       "   2.096024187405904,\n",
       "   2.154543391863505,\n",
       "   1.93749893506368,\n",
       "   1.8198326349258422,\n",
       "   1.7582539319992065,\n",
       "   1.683334438006083,\n",
       "   1.6823446909586588,\n",
       "   1.7314994215965271,\n",
       "   1.5926310698191324,\n",
       "   1.5958080848058065,\n",
       "   1.5764403025309244,\n",
       "   1.7335670471191407,\n",
       "   1.433717425664266,\n",
       "   1.3242196718851724,\n",
       "   1.282187529404958,\n",
       "   1.3868582924207051,\n",
       "   1.316079560915629,\n",
       "   1.1752821922302246,\n",
       "   1.192509796222051,\n",
       "   1.2093579451243082,\n",
       "   1.0733341058095296,\n",
       "   1.176035229365031,\n",
       "   1.006345029671987,\n",
       "   1.0060633301734925,\n",
       "   1.0295889178911846,\n",
       "   1.0028026342391967,\n",
       "   1.0503069599469503,\n",
       "   0.8798690636952718,\n",
       "   0.8681719779968262,\n",
       "   1.0576242168744405,\n",
       "   0.919522245724996,\n",
       "   0.9657868713140487,\n",
       "   0.8811831672986349,\n",
       "   0.8071787873903911,\n",
       "   0.8569010575612386,\n",
       "   0.7772517720858256,\n",
       "   0.840180532137553,\n",
       "   0.7700052857398987,\n",
       "   0.724775234858195,\n",
       "   0.7299211223920187,\n",
       "   0.7438857595125834,\n",
       "   0.7394078016281128,\n",
       "   0.828766930103302,\n",
       "   0.7051411151885987,\n",
       "   0.6894349018732707,\n",
       "   0.7652084112167359,\n",
       "   0.6999682267506917,\n",
       "   0.8242351015408834,\n",
       "   0.6648816943168641,\n",
       "   0.7141276439030965,\n",
       "   0.6973552902539571,\n",
       "   0.6370032588640849,\n",
       "   0.7103365659713745,\n",
       "   0.6555328249931336,\n",
       "   0.6292645514011384,\n",
       "   0.6452566524346669,\n",
       "   0.6629599750041961],\n",
       "  'val_losses': [6.096109867095947,\n",
       "   4.353740692138672,\n",
       "   4.206069231033325,\n",
       "   4.290111184120178,\n",
       "   4.363570213317871,\n",
       "   4.328056573867798,\n",
       "   3.9996225833892822,\n",
       "   4.000415682792664,\n",
       "   3.8160074949264526,\n",
       "   3.6718043088912964,\n",
       "   3.972043514251709,\n",
       "   3.3300880193710327,\n",
       "   3.69244122505188,\n",
       "   3.1674838066101074,\n",
       "   3.1422812938690186,\n",
       "   3.3607248067855835,\n",
       "   2.926478862762451,\n",
       "   2.816933035850525,\n",
       "   2.779094696044922,\n",
       "   2.8991405963897705,\n",
       "   2.621033191680908,\n",
       "   2.7804770469665527,\n",
       "   2.5449639558792114,\n",
       "   2.6481785774230957,\n",
       "   2.5709619522094727,\n",
       "   2.3189111948013306,\n",
       "   2.257502317428589,\n",
       "   2.5982446670532227,\n",
       "   2.296910583972931,\n",
       "   2.313751697540283,\n",
       "   2.094491422176361,\n",
       "   2.1609214544296265,\n",
       "   2.205885887145996,\n",
       "   2.3007463216781616,\n",
       "   2.075225591659546,\n",
       "   2.556894540786743,\n",
       "   2.1600362062454224,\n",
       "   2.2670035362243652,\n",
       "   1.8946726322174072,\n",
       "   1.9276573061943054,\n",
       "   1.9607461094856262,\n",
       "   2.075756847858429,\n",
       "   1.9169355034828186,\n",
       "   1.9690189957618713,\n",
       "   1.9351493120193481,\n",
       "   2.1053585410118103,\n",
       "   1.9773637056350708,\n",
       "   1.9331873655319214,\n",
       "   1.9045705199241638,\n",
       "   1.871472716331482,\n",
       "   1.9526890516281128,\n",
       "   1.8274834752082825,\n",
       "   2.027417242527008,\n",
       "   1.9513092041015625,\n",
       "   1.9377421140670776,\n",
       "   1.861174464225769,\n",
       "   2.000755548477173,\n",
       "   1.8677811026573181,\n",
       "   1.7921412587165833,\n",
       "   1.9366861581802368,\n",
       "   1.8479803204536438,\n",
       "   1.7725000381469727,\n",
       "   1.8133499026298523,\n",
       "   1.8522832989692688,\n",
       "   1.7394347786903381,\n",
       "   1.8343707919120789]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.931 -4.521851\n",
       "  1   -5.696 -5.061683\n",
       "  2   -6.680 -6.463814\n",
       "  3   -9.332 -8.907627\n",
       "  4   -1.740 -4.505754\n",
       "  ..     ...       ...\n",
       "  44  -3.800 -4.514913\n",
       "  45  -4.160 -5.624646\n",
       "  46  -2.060  0.400301\n",
       "  47  -5.400 -5.182481\n",
       "  48  -2.100 -0.747688\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 93.47493195533752,\n",
       "  'mean_mse': 1.9669389,\n",
       "  'mean_l1': 1.0525553,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1): GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.2074552853902185,\n",
       "   3.8090785185496014,\n",
       "   3.7099645932515464,\n",
       "   3.432641879717509,\n",
       "   3.4594112237294516,\n",
       "   3.174726470311483,\n",
       "   2.883475430806478,\n",
       "   2.92094517548879,\n",
       "   2.62634441057841,\n",
       "   2.5712092876434327,\n",
       "   2.4664252758026124,\n",
       "   2.4043362538019815,\n",
       "   2.291780718167623,\n",
       "   2.39501264890035,\n",
       "   2.546861465771993,\n",
       "   2.4169906695683796,\n",
       "   1.9630205551783244,\n",
       "   1.9218703905741374,\n",
       "   1.9085965275764465,\n",
       "   1.7439664443333944,\n",
       "   1.6475645502408345,\n",
       "   1.7264776229858398,\n",
       "   1.6186586459477743,\n",
       "   1.5632805983225504,\n",
       "   1.46419651110967,\n",
       "   1.665408976872762,\n",
       "   1.4374153772989908,\n",
       "   1.396797744433085,\n",
       "   1.3813048005104065,\n",
       "   1.3568111062049866,\n",
       "   1.3179535508155822,\n",
       "   1.2581923921902975,\n",
       "   1.248641268412272,\n",
       "   1.3383586724599204,\n",
       "   1.3119987924893697,\n",
       "   1.1958207170168558,\n",
       "   1.403928311665853,\n",
       "   1.1230976422627768,\n",
       "   1.3940919597943624,\n",
       "   1.2560617407162984],\n",
       "  'val_losses': [6.949522256851196,\n",
       "   4.997170686721802,\n",
       "   4.682382583618164,\n",
       "   4.73311448097229,\n",
       "   4.213534593582153,\n",
       "   4.515915393829346,\n",
       "   4.2017515897750854,\n",
       "   4.135164260864258,\n",
       "   3.9215636253356934,\n",
       "   3.853670835494995,\n",
       "   3.605499029159546,\n",
       "   3.8349955081939697,\n",
       "   3.4766218662261963,\n",
       "   3.195305585861206,\n",
       "   3.142572522163391,\n",
       "   2.9797686338424683,\n",
       "   2.9691929817199707,\n",
       "   2.8259776830673218,\n",
       "   2.8752323389053345,\n",
       "   2.5844324827194214,\n",
       "   2.55985951423645,\n",
       "   2.4568910002708435,\n",
       "   2.2905760407447815,\n",
       "   2.3639330863952637,\n",
       "   2.2973228693008423,\n",
       "   2.209637701511383,\n",
       "   2.0636672377586365,\n",
       "   2.0492846965789795,\n",
       "   2.0547040700912476,\n",
       "   2.235402762889862,\n",
       "   1.901749074459076,\n",
       "   1.9447896480560303,\n",
       "   1.8610427379608154,\n",
       "   2.7286959886550903,\n",
       "   2.190800428390503,\n",
       "   1.9941728115081787,\n",
       "   1.8416171669960022,\n",
       "   1.8859708309173584,\n",
       "   2.20828914642334,\n",
       "   1.9262420535087585]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.349 -2.787684\n",
       "  1   -3.290 -4.939330\n",
       "  2    0.790 -0.667674\n",
       "  3   -2.338 -2.666525\n",
       "  4   -1.040 -3.368245\n",
       "  ..     ...       ...\n",
       "  44  -6.860 -9.365116\n",
       "  45  -3.638 -4.307678\n",
       "  46  -2.780 -3.608018\n",
       "  47  -5.696 -4.775649\n",
       "  48  -4.950 -2.977193\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 101.4038233757019,\n",
       "  'mean_mse': 1.7298901,\n",
       "  'mean_l1': 1.0143454,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1): GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.107202434539795,\n",
       "   3.6142900307973225,\n",
       "   3.2043662627538043,\n",
       "   2.9052796522776285,\n",
       "   2.669760815302531,\n",
       "   2.3464197635650637,\n",
       "   2.188919417063395,\n",
       "   2.08799041112264,\n",
       "   2.0925737222035727,\n",
       "   1.9369422674179078,\n",
       "   1.8837704181671142,\n",
       "   1.8426324407259622,\n",
       "   1.7451681216557822,\n",
       "   1.5796200195948282,\n",
       "   1.5467314720153809,\n",
       "   1.4984987099965414,\n",
       "   1.4137712836265564,\n",
       "   1.3512224197387694,\n",
       "   1.1960489551226299,\n",
       "   1.2650034228960674,\n",
       "   1.2779522339502971,\n",
       "   1.052556679646174,\n",
       "   1.142872961362203,\n",
       "   1.061468517780304,\n",
       "   1.2321020285288493,\n",
       "   1.0899184703826905,\n",
       "   1.05725443760554,\n",
       "   0.9998280723889669,\n",
       "   0.943029514948527,\n",
       "   1.0749617298444112,\n",
       "   0.9839525977770488,\n",
       "   0.9959753553072611,\n",
       "   0.9365481615066529,\n",
       "   1.0456392089525859,\n",
       "   0.8834503690401713,\n",
       "   0.854494700829188,\n",
       "   1.1344250082969665,\n",
       "   0.9029879927635193,\n",
       "   0.9201408465703328,\n",
       "   0.8496205290158589,\n",
       "   0.9632226665814717,\n",
       "   0.7913065135478974,\n",
       "   0.7975631455580393,\n",
       "   0.7614529192447662],\n",
       "  'val_losses': [4.955658912658691,\n",
       "   4.928942680358887,\n",
       "   4.217199325561523,\n",
       "   4.021136403083801,\n",
       "   3.9673354625701904,\n",
       "   4.2317235469818115,\n",
       "   4.218604922294617,\n",
       "   3.919915199279785,\n",
       "   3.6768559217453003,\n",
       "   3.460905432701111,\n",
       "   3.370970845222473,\n",
       "   3.2092443704605103,\n",
       "   3.01676344871521,\n",
       "   3.3763346672058105,\n",
       "   2.898791790008545,\n",
       "   2.668990135192871,\n",
       "   2.7596518993377686,\n",
       "   2.4701465368270874,\n",
       "   2.196040630340576,\n",
       "   2.1841753721237183,\n",
       "   2.358039975166321,\n",
       "   2.2222588062286377,\n",
       "   2.0884894728660583,\n",
       "   1.9484462141990662,\n",
       "   2.09196537733078,\n",
       "   2.0719545483589172,\n",
       "   1.9883587956428528,\n",
       "   2.451552987098694,\n",
       "   1.9285422563552856,\n",
       "   2.4373421669006348,\n",
       "   2.5491212606430054,\n",
       "   2.228588819503784,\n",
       "   1.8982442021369934,\n",
       "   1.9073113203048706,\n",
       "   1.9301729202270508,\n",
       "   2.005880296230316,\n",
       "   1.8462389707565308,\n",
       "   1.8404242396354675,\n",
       "   1.7556464076042175,\n",
       "   1.9197455644607544,\n",
       "   1.8797447085380554,\n",
       "   2.0929102897644043,\n",
       "   1.9179446697235107,\n",
       "   2.077578067779541]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.070 -4.131938\n",
       "  1   -5.220 -6.293449\n",
       "  2   -2.676 -3.222664\n",
       "  3   -2.160 -2.492549\n",
       "  4   -4.800 -6.668983\n",
       "  ..     ...       ...\n",
       "  44  -4.799 -3.667021\n",
       "  45   1.100 -0.229949\n",
       "  46  -4.883 -4.342649\n",
       "  47  -7.800 -8.213313\n",
       "  48  -2.120 -1.510671\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 90.37868976593018,\n",
       "  'mean_mse': 1.8593729,\n",
       "  'mean_l1': 1.0692629,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1): GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [13.508611488342286,\n",
       "   3.7376850128173826,\n",
       "   3.256449055671692,\n",
       "   3.1891316095987956,\n",
       "   3.0186379750569663,\n",
       "   2.529063097635905,\n",
       "   2.3568124373753867,\n",
       "   2.380744942029317,\n",
       "   1.9658466617266337,\n",
       "   1.904204281171163,\n",
       "   1.8396073897679648,\n",
       "   2.040344993273417,\n",
       "   1.6905151685078939,\n",
       "   1.5550385157267252,\n",
       "   1.5932267645994822,\n",
       "   1.4662999590237935,\n",
       "   1.612202525138855,\n",
       "   1.3666826089223225,\n",
       "   1.354292126496633,\n",
       "   1.300543987751007,\n",
       "   1.1574929296970367,\n",
       "   1.1873811841011048,\n",
       "   1.2978102087974548,\n",
       "   1.1988704164822896,\n",
       "   1.108840537071228,\n",
       "   1.0046255826950072,\n",
       "   1.0624196211496988,\n",
       "   0.9515938997268677,\n",
       "   0.9090903878211976,\n",
       "   1.0033385515213014,\n",
       "   0.882023020585378,\n",
       "   0.8666701157887776,\n",
       "   0.8563409407933553,\n",
       "   0.9412814259529114,\n",
       "   0.7772606054941813,\n",
       "   0.8994756698608398,\n",
       "   0.7901661992073059,\n",
       "   0.758386782805125,\n",
       "   0.7041205565134684,\n",
       "   0.8102479457855225,\n",
       "   0.7075701614220937,\n",
       "   0.7622849146525065],\n",
       "  'val_losses': [10.779491901397705,\n",
       "   4.994014501571655,\n",
       "   4.528707265853882,\n",
       "   4.206230640411377,\n",
       "   4.05278754234314,\n",
       "   4.089494228363037,\n",
       "   4.410592317581177,\n",
       "   3.661787509918213,\n",
       "   3.738785743713379,\n",
       "   3.2950711250305176,\n",
       "   2.9966481924057007,\n",
       "   3.0021493434906006,\n",
       "   3.2024253606796265,\n",
       "   2.8303511142730713,\n",
       "   2.4753624200820923,\n",
       "   2.8735461235046387,\n",
       "   2.4873647689819336,\n",
       "   2.328550696372986,\n",
       "   2.2376756072044373,\n",
       "   2.435028553009033,\n",
       "   2.1803576946258545,\n",
       "   2.28508597612381,\n",
       "   2.0984479784965515,\n",
       "   2.128789246082306,\n",
       "   2.2194682359695435,\n",
       "   2.1885794401168823,\n",
       "   1.993533968925476,\n",
       "   2.122101128101349,\n",
       "   2.0154457092285156,\n",
       "   1.9102333784103394,\n",
       "   2.0321479439735413,\n",
       "   1.9776498079299927,\n",
       "   2.0244612097740173,\n",
       "   2.0565510988235474,\n",
       "   2.0447336435317993,\n",
       "   1.9708925485610962,\n",
       "   1.8690537214279175,\n",
       "   1.9392111897468567,\n",
       "   1.963979959487915,\n",
       "   1.9854061007499695,\n",
       "   1.8970609903335571,\n",
       "   1.945259690284729]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.094 -2.863290\n",
       "  1    1.100  0.323554\n",
       "  2   -0.742 -1.367392\n",
       "  3   -3.120 -2.355792\n",
       "  4   -5.270 -5.322253\n",
       "  ..     ...       ...\n",
       "  44  -1.800 -2.040818\n",
       "  45  -3.672 -2.694501\n",
       "  46  -4.160 -5.195856\n",
       "  47  -4.800 -5.670531\n",
       "  48  -5.190 -3.536050\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 66.51390075683594,\n",
       "  'mean_mse': 1.7944767,\n",
       "  'mean_l1': 1.0297416,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-2): 2 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.832946399847667,\n",
       "   3.1594223976135254,\n",
       "   2.465654500325521,\n",
       "   1.9741554419199625,\n",
       "   1.6606862465540568,\n",
       "   1.5504563570022583,\n",
       "   1.2918271144231162,\n",
       "   1.3220118681589763,\n",
       "   1.1354215701421102,\n",
       "   1.13174862464269,\n",
       "   1.3110013961791993,\n",
       "   1.0234391530354818,\n",
       "   0.8987413704395294,\n",
       "   0.9928269187609354,\n",
       "   1.1333766460418702,\n",
       "   0.9477798938751221,\n",
       "   0.8636587778727214,\n",
       "   0.7641835560401281,\n",
       "   0.8922554274400075,\n",
       "   0.826865267753601,\n",
       "   0.7288641055425008,\n",
       "   0.6968494852383932,\n",
       "   0.7335468749205272,\n",
       "   0.6059174418449402],\n",
       "  'val_losses': [4.8896262645721436,\n",
       "   4.3285828828811646,\n",
       "   3.7862610816955566,\n",
       "   3.156820297241211,\n",
       "   3.0942952632904053,\n",
       "   2.617258906364441,\n",
       "   2.5129319429397583,\n",
       "   2.6645745038986206,\n",
       "   1.9548363089561462,\n",
       "   1.8532439470291138,\n",
       "   2.160778284072876,\n",
       "   1.8220410346984863,\n",
       "   1.8001402616500854,\n",
       "   1.835209608078003,\n",
       "   1.6693012118339539,\n",
       "   1.7019447088241577,\n",
       "   1.6786125898361206,\n",
       "   1.9021787643432617,\n",
       "   1.575914978981018,\n",
       "   1.752701997756958,\n",
       "   2.63949316740036,\n",
       "   1.6792219877243042,\n",
       "   1.8540953993797302,\n",
       "   1.6891788840293884]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.451 -5.078820\n",
       "  1   -2.920 -2.357913\n",
       "  2   -4.370 -4.522486\n",
       "  3   -3.050 -4.409502\n",
       "  4   -1.640 -4.909017\n",
       "  ..     ...       ...\n",
       "  44  -3.246 -3.899294\n",
       "  45  -3.290 -4.316787\n",
       "  46  -4.376 -3.856957\n",
       "  47  -2.700 -3.537956\n",
       "  48  -2.943 -1.578539\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 65.61969304084778,\n",
       "  'mean_mse': 1.9980787,\n",
       "  'mean_l1': 1.0438598,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-2): 2 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.883854794502258,\n",
       "   4.1552644570668535,\n",
       "   3.345610507329305,\n",
       "   2.989754486083984,\n",
       "   2.9539836088816327,\n",
       "   2.709370764096578,\n",
       "   2.4313472429911296,\n",
       "   2.1951998154322307,\n",
       "   2.3980195840199787,\n",
       "   1.917448623975118,\n",
       "   1.7636740605036418,\n",
       "   1.7099536736806233,\n",
       "   1.5290990034739176,\n",
       "   1.4983635902404786,\n",
       "   1.4093830267588296,\n",
       "   1.2284376780192057,\n",
       "   1.2060033321380614,\n",
       "   1.3100478092829386,\n",
       "   1.175396994749705,\n",
       "   1.1926146825154622,\n",
       "   1.2543448448181151,\n",
       "   1.4500998536745706,\n",
       "   1.1390159527460735,\n",
       "   1.033459977308909,\n",
       "   1.0455413301785788],\n",
       "  'val_losses': [5.952745199203491,\n",
       "   4.971449375152588,\n",
       "   4.5735859870910645,\n",
       "   5.586628198623657,\n",
       "   4.178641080856323,\n",
       "   3.4923057556152344,\n",
       "   4.733031749725342,\n",
       "   3.4368444681167603,\n",
       "   3.832359790802002,\n",
       "   2.75866162776947,\n",
       "   2.531928777694702,\n",
       "   3.020462393760681,\n",
       "   2.2765085697174072,\n",
       "   2.144963264465332,\n",
       "   1.9827114939689636,\n",
       "   1.935780644416809,\n",
       "   2.563902258872986,\n",
       "   2.030906558036804,\n",
       "   1.9243656396865845,\n",
       "   2.6804466247558594,\n",
       "   2.0692253708839417,\n",
       "   2.391801595687866,\n",
       "   1.9438979625701904,\n",
       "   1.905291497707367,\n",
       "   1.9551785588264465]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.376 -3.543879\n",
       "  1    0.790  0.002059\n",
       "  2   -4.800 -6.316354\n",
       "  3   -4.450 -1.301030\n",
       "  4   -3.610 -3.080249\n",
       "  ..     ...       ...\n",
       "  44  -2.780 -4.452994\n",
       "  45  -6.800 -6.805265\n",
       "  46  -4.370 -4.037704\n",
       "  47  -2.266 -1.212142\n",
       "  48  -3.460 -4.808611\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 75.01949620246887,\n",
       "  'mean_mse': 1.9919221,\n",
       "  'mean_l1': 1.0932571,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-2): 2 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.035958973566691,\n",
       "   3.569453509648641,\n",
       "   3.417007557551066,\n",
       "   3.0095693429311114,\n",
       "   2.2969496647516885,\n",
       "   2.0681490023930866,\n",
       "   1.9700619538625082,\n",
       "   1.6682730436325073,\n",
       "   1.5217981616655984,\n",
       "   1.4969726920127868,\n",
       "   1.347974427541097,\n",
       "   1.2268250862757364,\n",
       "   1.2851405461629233,\n",
       "   1.1522253155708313,\n",
       "   1.0646867195765177,\n",
       "   1.120487880706787,\n",
       "   1.0330787658691407,\n",
       "   0.9703317443529765,\n",
       "   0.9841117898623148,\n",
       "   1.0410740375518799,\n",
       "   1.2393220901489257,\n",
       "   0.9441515624523162,\n",
       "   0.8273714423179627,\n",
       "   0.8091427405675252,\n",
       "   0.8525934159755707,\n",
       "   0.8237515250841777,\n",
       "   0.783509087562561,\n",
       "   0.7678564786911011,\n",
       "   0.7632118741671244,\n",
       "   0.7026542544364929],\n",
       "  'val_losses': [5.070414304733276,\n",
       "   4.593681216239929,\n",
       "   4.569137215614319,\n",
       "   4.057433128356934,\n",
       "   3.850399971008301,\n",
       "   3.5670305490493774,\n",
       "   3.4246476888656616,\n",
       "   3.1774545907974243,\n",
       "   3.0409886837005615,\n",
       "   2.7898457050323486,\n",
       "   2.48185932636261,\n",
       "   2.2775923013687134,\n",
       "   2.2182790637016296,\n",
       "   2.1174396872520447,\n",
       "   2.004705548286438,\n",
       "   2.1046589612960815,\n",
       "   2.267507314682007,\n",
       "   2.017058551311493,\n",
       "   1.931027889251709,\n",
       "   2.3178089261054993,\n",
       "   1.9877782464027405,\n",
       "   1.8497992753982544,\n",
       "   1.9663091897964478,\n",
       "   1.9639416933059692,\n",
       "   2.208957552909851,\n",
       "   2.131431221961975,\n",
       "   1.8763675093650818,\n",
       "   1.8224599361419678,\n",
       "   1.811359167098999,\n",
       "   1.8959110975265503]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -6.020 -1.798042\n",
       "  1   -3.168 -3.259488\n",
       "  2   -1.740 -4.208312\n",
       "  3   -3.658 -4.065496\n",
       "  4   -4.120 -4.710379\n",
       "  ..     ...       ...\n",
       "  44  -4.402 -4.927770\n",
       "  45  -4.445 -5.312930\n",
       "  46  -5.350 -4.776301\n",
       "  47  -5.270 -5.326683\n",
       "  48   0.522  0.290189\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 100.17083048820496,\n",
       "  'mean_mse': 1.810129,\n",
       "  'mean_l1': 1.0217474,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-3): 3 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.484526554743449,\n",
       "   4.023978646596273,\n",
       "   3.05259903271993,\n",
       "   2.414851665496826,\n",
       "   2.316217581431071,\n",
       "   2.019514067967733,\n",
       "   2.11117848555247,\n",
       "   1.7173446814219158,\n",
       "   1.724849518140157,\n",
       "   1.4187890529632567,\n",
       "   1.3559152563412984,\n",
       "   1.5532017946243286,\n",
       "   1.3793001890182495,\n",
       "   1.1494561036427815,\n",
       "   1.0717298905054728,\n",
       "   1.0225839177767435,\n",
       "   1.001787547270457,\n",
       "   0.895477565129598,\n",
       "   0.9395228187243144,\n",
       "   0.8372363686561585,\n",
       "   0.9096111396948496,\n",
       "   0.7892679214477539,\n",
       "   0.7964558939139048,\n",
       "   0.6435209726293881,\n",
       "   0.6860142111778259,\n",
       "   0.7546291391054789,\n",
       "   0.6795214573542278,\n",
       "   0.6191345925132433,\n",
       "   0.7677994887034099,\n",
       "   0.67420927186807,\n",
       "   0.7740083694458008,\n",
       "   0.6144767105579376,\n",
       "   0.5317441463470459,\n",
       "   0.6438645184040069],\n",
       "  'val_losses': [4.784792184829712,\n",
       "   4.877283573150635,\n",
       "   4.331951975822449,\n",
       "   4.269419431686401,\n",
       "   3.69256329536438,\n",
       "   3.4161107540130615,\n",
       "   2.9879733324050903,\n",
       "   2.9760130643844604,\n",
       "   2.6143558025360107,\n",
       "   2.498082160949707,\n",
       "   2.2009910345077515,\n",
       "   2.2191059589385986,\n",
       "   2.176083505153656,\n",
       "   1.954307198524475,\n",
       "   2.0687555074691772,\n",
       "   2.559064030647278,\n",
       "   2.2622069120407104,\n",
       "   2.0344331860542297,\n",
       "   2.376651644706726,\n",
       "   1.8392519354820251,\n",
       "   1.878406286239624,\n",
       "   1.9634524583816528,\n",
       "   2.240553081035614,\n",
       "   1.7073224186897278,\n",
       "   1.9362954497337341,\n",
       "   1.7697744965553284,\n",
       "   1.681639850139618,\n",
       "   1.708233654499054,\n",
       "   3.0148061513900757,\n",
       "   1.8352720737457275,\n",
       "   1.7358080744743347,\n",
       "   2.3459174633026123,\n",
       "   1.6900750398635864,\n",
       "   1.9806413054466248]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.740 -4.681064\n",
       "  1   -4.450 -2.352278\n",
       "  2   -3.360 -4.263783\n",
       "  3   -4.370 -4.113267\n",
       "  4   -2.461 -1.730312\n",
       "  ..     ...       ...\n",
       "  44  -4.160 -5.535678\n",
       "  45  -0.400 -0.489481\n",
       "  46  -2.060 -1.146676\n",
       "  47  -5.270 -5.959046\n",
       "  48  -2.160 -2.794791\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 58.25477457046509,\n",
       "  'mean_mse': 1.8646637,\n",
       "  'mean_l1': 0.972548,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-3): 3 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [8.5108460744222,\n",
       "   3.8910579363505047,\n",
       "   3.414212115605672,\n",
       "   2.5101701577504474,\n",
       "   1.9811036427815756,\n",
       "   2.0309522708257037,\n",
       "   1.776090137163798,\n",
       "   1.4748538494110108,\n",
       "   1.3089680552482605,\n",
       "   1.3615659753481546,\n",
       "   1.2553886850674947,\n",
       "   1.3137691497802735,\n",
       "   1.1577960213025411,\n",
       "   1.0425380329291025,\n",
       "   1.2855895201365153,\n",
       "   1.0318801482518514,\n",
       "   1.203528610865275,\n",
       "   1.0445459564526876,\n",
       "   1.1186253309249878,\n",
       "   1.0784530480702719],\n",
       "  'val_losses': [6.5442054271698,\n",
       "   4.8028788566589355,\n",
       "   4.511675596237183,\n",
       "   4.357974529266357,\n",
       "   2.960262179374695,\n",
       "   2.5090399980545044,\n",
       "   4.467595815658569,\n",
       "   1.9566276669502258,\n",
       "   2.2633175253868103,\n",
       "   2.3373943567276,\n",
       "   2.211471736431122,\n",
       "   1.873502254486084,\n",
       "   2.5335018634796143,\n",
       "   2.0395163893699646,\n",
       "   2.17682421207428,\n",
       "   2.009950637817383,\n",
       "   2.1730316281318665,\n",
       "   1.8821061253547668,\n",
       "   1.8755019307136536,\n",
       "   1.8326701521873474]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -6.680 -6.509290\n",
       "  1   -3.672 -2.147323\n",
       "  2   -4.047 -4.185581\n",
       "  3   -3.180 -3.078327\n",
       "  4   -6.860 -5.720604\n",
       "  ..     ...       ...\n",
       "  44  -6.726 -6.162022\n",
       "  45  -4.120 -4.342454\n",
       "  46   1.100 -0.491268\n",
       "  47  -2.060 -1.090363\n",
       "  48  -4.632 -2.712313\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 52.786231994628906,\n",
       "  'mean_mse': 1.7423959,\n",
       "  'mean_l1': 1.0452831,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-3): 3 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.49739637374878,\n",
       "   3.57890940507253,\n",
       "   2.60085244178772,\n",
       "   2.4304906129837036,\n",
       "   2.0969531695048014,\n",
       "   2.0440466006596885,\n",
       "   2.1025697072347005,\n",
       "   1.7029109398523967,\n",
       "   1.515894881884257,\n",
       "   1.4359588980674745,\n",
       "   1.394310728708903,\n",
       "   1.311347238222758,\n",
       "   1.2137246529261272,\n",
       "   1.097214905420939,\n",
       "   1.1428720275561015,\n",
       "   1.0952348430951437,\n",
       "   0.9003873546918233,\n",
       "   0.9480450987815857],\n",
       "  'val_losses': [5.00822377204895,\n",
       "   5.053091764450073,\n",
       "   4.195011258125305,\n",
       "   3.4643179178237915,\n",
       "   3.457829713821411,\n",
       "   3.0754257440567017,\n",
       "   2.5689390897750854,\n",
       "   2.6112687587738037,\n",
       "   2.388378620147705,\n",
       "   2.5807727575302124,\n",
       "   2.276558518409729,\n",
       "   2.470563292503357,\n",
       "   2.3781731724739075,\n",
       "   2.2957292795181274,\n",
       "   2.4504817724227905,\n",
       "   2.471406579017639,\n",
       "   2.195766806602478,\n",
       "   2.356907844543457]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.716 -3.676016\n",
       "  1   -4.450 -1.289106\n",
       "  2   -4.800 -7.056798\n",
       "  3   -2.780 -4.594312\n",
       "  4   -4.376 -4.930987\n",
       "  ..     ...       ...\n",
       "  44  -0.600 -1.165941\n",
       "  45  -6.860 -6.963514\n",
       "  46  -5.400 -4.209304\n",
       "  47  -4.799 -3.611122\n",
       "  48  -3.538 -3.716649\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 132.33516001701355,\n",
       "  'mean_mse': 1.6471345,\n",
       "  'mean_l1': 1.0135108,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.945291058222453,\n",
       "   3.587288411458333,\n",
       "   3.541937494277954,\n",
       "   3.5056164105733236,\n",
       "   2.896666749318441,\n",
       "   2.877412470181783,\n",
       "   2.642811377843221,\n",
       "   2.443241095542908,\n",
       "   2.250983381271362,\n",
       "   2.15710608959198,\n",
       "   2.3322124004364015,\n",
       "   2.0314594984054564,\n",
       "   2.065905968348185,\n",
       "   1.8407833536465963,\n",
       "   1.8275076468785605,\n",
       "   1.816658322016398,\n",
       "   1.6596821387608847,\n",
       "   1.6316904783248902,\n",
       "   1.605325730641683,\n",
       "   1.614430514971415,\n",
       "   1.4708269516626993,\n",
       "   1.5112516244252523,\n",
       "   1.5569212039311726,\n",
       "   1.360679030418396,\n",
       "   1.3908493121465046,\n",
       "   1.3476514259974162,\n",
       "   1.230542206764221,\n",
       "   1.2017580648263295,\n",
       "   1.3586074749628703,\n",
       "   1.1691328724225363,\n",
       "   1.1473181962966919,\n",
       "   1.1595088521639505,\n",
       "   1.164898649851481,\n",
       "   1.1955866773923238,\n",
       "   1.2885208050409953,\n",
       "   1.1466874082883198,\n",
       "   1.1815638025601705,\n",
       "   1.1180203278859457,\n",
       "   1.0595049103101095,\n",
       "   1.2038564483324687,\n",
       "   1.0080324729283652,\n",
       "   1.0652195413907368,\n",
       "   0.9856443166732788,\n",
       "   0.9246434917052587,\n",
       "   0.9739167600870132,\n",
       "   0.9958492040634155,\n",
       "   1.0421390652656555,\n",
       "   1.054638636112213,\n",
       "   0.9182016650835673,\n",
       "   0.8834205071131388,\n",
       "   0.9083370844523112,\n",
       "   0.9558862924575806,\n",
       "   0.9350004156430562,\n",
       "   0.8421208977699279,\n",
       "   0.8998262206713359,\n",
       "   0.8141794393459956,\n",
       "   0.826331639289856,\n",
       "   0.8392591079076132,\n",
       "   0.8895400444666545,\n",
       "   0.8517005642255148,\n",
       "   0.8913140376408895,\n",
       "   0.8584467768669128,\n",
       "   0.8110671599706014],\n",
       "  'val_losses': [4.7977612018585205,\n",
       "   4.750352382659912,\n",
       "   4.277527332305908,\n",
       "   4.3526952266693115,\n",
       "   4.7468581199646,\n",
       "   4.224782228469849,\n",
       "   4.124480962753296,\n",
       "   4.1018226146698,\n",
       "   3.880392551422119,\n",
       "   3.963715434074402,\n",
       "   3.682823896408081,\n",
       "   4.065856099128723,\n",
       "   3.418911337852478,\n",
       "   3.2565236687660217,\n",
       "   3.464102268218994,\n",
       "   3.1370410919189453,\n",
       "   3.187678098678589,\n",
       "   2.977403998374939,\n",
       "   2.8857494592666626,\n",
       "   3.193879723548889,\n",
       "   3.0818679332733154,\n",
       "   2.5652838945388794,\n",
       "   2.562027335166931,\n",
       "   2.466700792312622,\n",
       "   2.614130735397339,\n",
       "   2.346063733100891,\n",
       "   2.549059271812439,\n",
       "   2.3726905584335327,\n",
       "   2.3998522758483887,\n",
       "   2.2447386980056763,\n",
       "   2.1810163259506226,\n",
       "   2.148801803588867,\n",
       "   2.249336361885071,\n",
       "   2.409506916999817,\n",
       "   2.3820592164993286,\n",
       "   2.132306694984436,\n",
       "   2.1903238892555237,\n",
       "   2.201590418815613,\n",
       "   2.2265095114707947,\n",
       "   2.0174277424812317,\n",
       "   2.341083526611328,\n",
       "   2.0870487093925476,\n",
       "   2.037146508693695,\n",
       "   2.0391087532043457,\n",
       "   2.1259623765945435,\n",
       "   2.1992145776748657,\n",
       "   2.0903429985046387,\n",
       "   2.101384997367859,\n",
       "   2.230637788772583,\n",
       "   2.1667639017105103,\n",
       "   2.1234359741210938,\n",
       "   2.008319139480591,\n",
       "   1.954413652420044,\n",
       "   2.0459821224212646,\n",
       "   2.00609689950943,\n",
       "   2.0076249837875366,\n",
       "   2.192350387573242,\n",
       "   1.878682553768158,\n",
       "   1.9634883999824524,\n",
       "   2.144663691520691,\n",
       "   2.005502223968506,\n",
       "   2.12035471200943,\n",
       "   1.9534494876861572]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.173 -5.217965\n",
       "  1   -6.237 -3.683458\n",
       "  2   -2.982 -2.866821\n",
       "  3   -2.281 -2.412659\n",
       "  4   -3.638 -3.177356\n",
       "  ..     ...       ...\n",
       "  44  -5.696 -5.200188\n",
       "  45  -3.672 -3.613599\n",
       "  46  -4.950 -3.413758\n",
       "  47  -4.799 -3.916160\n",
       "  48  -1.990 -1.152834\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 173.7259006500244,\n",
       "  'mean_mse': 1.7892882,\n",
       "  'mean_l1': 0.9884324,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.235064872105917,\n",
       "   3.906927156448364,\n",
       "   3.9548787117004394,\n",
       "   3.67581737836202,\n",
       "   3.3619855523109434,\n",
       "   3.3892197450002035,\n",
       "   3.0703970432281493,\n",
       "   2.952799407641093,\n",
       "   2.9001489957173665,\n",
       "   2.906503979365031,\n",
       "   2.828603967030843,\n",
       "   2.6139252026875814,\n",
       "   2.681765874226888,\n",
       "   2.49174108505249,\n",
       "   2.477358277638753,\n",
       "   2.3976162830988565,\n",
       "   2.6343391021092732,\n",
       "   2.2299591143925985,\n",
       "   2.3756600936253864,\n",
       "   2.2066854079564413,\n",
       "   2.2512543121973674,\n",
       "   2.130640510718028,\n",
       "   2.3543972174326577,\n",
       "   1.9995224197705588,\n",
       "   2.331769275665283,\n",
       "   1.9919974327087402,\n",
       "   2.0391488949457806,\n",
       "   2.0999361435572306,\n",
       "   2.1118929624557494,\n",
       "   1.8962196111679077,\n",
       "   1.975174109141032,\n",
       "   1.7915151437123618,\n",
       "   1.8748744567235311,\n",
       "   1.7885026931762695,\n",
       "   1.7166349013646445,\n",
       "   1.7913164695103962,\n",
       "   1.729564126332601,\n",
       "   1.6524001042048135,\n",
       "   1.8007649580637615,\n",
       "   1.6673998912175496,\n",
       "   1.6864861408869425,\n",
       "   1.8412624677022298,\n",
       "   1.5662119388580322,\n",
       "   1.5375996549924216,\n",
       "   1.5210541943709055,\n",
       "   1.6455175161361695,\n",
       "   1.5214349746704101,\n",
       "   1.5325339476267497,\n",
       "   1.4290941546360652,\n",
       "   1.4792454322179158,\n",
       "   1.5488646030426025,\n",
       "   1.4546636899312337,\n",
       "   1.4917824268341064,\n",
       "   1.55228537718455,\n",
       "   1.4417789101600647,\n",
       "   1.5914779345194499,\n",
       "   1.4486642201741537,\n",
       "   1.3091846148173014,\n",
       "   1.4833432594935099,\n",
       "   1.4297301133473714,\n",
       "   1.3348918199539184,\n",
       "   1.2993499835332234,\n",
       "   1.8893879175186157,\n",
       "   1.3496885855992635,\n",
       "   1.2836102883021037,\n",
       "   1.4316569646199544,\n",
       "   1.2590817133585612,\n",
       "   1.2843393087387085,\n",
       "   1.3283305366834004,\n",
       "   1.2659079988797506,\n",
       "   1.341923475265503,\n",
       "   1.2488208333651225,\n",
       "   1.236944392323494,\n",
       "   1.2531178951263429,\n",
       "   1.2927002429962158,\n",
       "   1.2613478660583497,\n",
       "   1.2523432890574138,\n",
       "   1.2729725281397501],\n",
       "  'val_losses': [6.291925430297852,\n",
       "   4.666605472564697,\n",
       "   4.398192882537842,\n",
       "   4.410966634750366,\n",
       "   4.422075510025024,\n",
       "   4.4018731117248535,\n",
       "   4.24116063117981,\n",
       "   4.835934638977051,\n",
       "   3.9734373092651367,\n",
       "   3.934871792793274,\n",
       "   3.882776975631714,\n",
       "   3.8344552516937256,\n",
       "   3.8845964670181274,\n",
       "   3.8530967235565186,\n",
       "   3.9455504417419434,\n",
       "   3.786601185798645,\n",
       "   3.559007406234741,\n",
       "   3.3665318489074707,\n",
       "   3.4118770360946655,\n",
       "   3.524281144142151,\n",
       "   3.214576482772827,\n",
       "   3.1799858808517456,\n",
       "   3.0990757942199707,\n",
       "   3.107992172241211,\n",
       "   3.6485456228256226,\n",
       "   3.215678572654724,\n",
       "   3.102047324180603,\n",
       "   3.196839690208435,\n",
       "   2.8511667251586914,\n",
       "   2.9279024600982666,\n",
       "   2.6167157888412476,\n",
       "   3.0569640398025513,\n",
       "   2.7023247480392456,\n",
       "   2.9093217849731445,\n",
       "   2.812457323074341,\n",
       "   2.643639087677002,\n",
       "   2.4760671854019165,\n",
       "   2.4104167819023132,\n",
       "   2.421326756477356,\n",
       "   2.415332794189453,\n",
       "   2.444832444190979,\n",
       "   2.505725622177124,\n",
       "   2.4141165018081665,\n",
       "   2.6211867332458496,\n",
       "   2.4751266837120056,\n",
       "   2.3192025423049927,\n",
       "   2.3208200931549072,\n",
       "   2.206902027130127,\n",
       "   2.4853997230529785,\n",
       "   2.1766485571861267,\n",
       "   2.1063283681869507,\n",
       "   2.1038944721221924,\n",
       "   2.1957225799560547,\n",
       "   2.064142644405365,\n",
       "   2.1026896834373474,\n",
       "   2.0459816455841064,\n",
       "   2.0083749294281006,\n",
       "   2.009794771671295,\n",
       "   2.0663393139839172,\n",
       "   2.1626868844032288,\n",
       "   2.146670699119568,\n",
       "   2.0430206060409546,\n",
       "   1.9025830626487732,\n",
       "   2.250451683998108,\n",
       "   1.9659748673439026,\n",
       "   1.9433345794677734,\n",
       "   1.888201653957367,\n",
       "   2.1756285429000854,\n",
       "   2.1789193153381348,\n",
       "   1.8998750448226929,\n",
       "   2.1251752376556396,\n",
       "   2.0611928701400757,\n",
       "   1.843493103981018,\n",
       "   1.9847648739814758,\n",
       "   1.9075644612312317,\n",
       "   1.8831360936164856,\n",
       "   1.9174998998641968,\n",
       "   1.9506009221076965]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.360 -4.397575\n",
       "  1   -2.943 -2.037645\n",
       "  2   -1.990 -1.889651\n",
       "  3   -3.168 -3.374565\n",
       "  4    0.790 -0.719204\n",
       "  ..     ...       ...\n",
       "  44  -6.020 -4.963580\n",
       "  45  -7.800 -6.204294\n",
       "  46  -3.246 -6.425611\n",
       "  47  -2.266 -2.427482\n",
       "  48  -5.190 -4.575899\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 100.02480506896973,\n",
       "  'mean_mse': 2.0325143,\n",
       "  'mean_l1': 1.1379886,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.043306620915731,\n",
       "   3.5944544712702435,\n",
       "   3.313303844134013,\n",
       "   3.2027958552042644,\n",
       "   3.052220884958903,\n",
       "   2.9550562381744383,\n",
       "   2.880932402610779,\n",
       "   2.542711450656255,\n",
       "   2.4068700790405275,\n",
       "   2.6290339787801105,\n",
       "   2.484961978594462,\n",
       "   2.1477288246154784,\n",
       "   2.325848094622294,\n",
       "   2.4191579977671305,\n",
       "   2.107650566101074,\n",
       "   1.961033042271932,\n",
       "   1.989248243967692,\n",
       "   1.9538150946299235,\n",
       "   2.0642181793848673,\n",
       "   1.8656604687372844,\n",
       "   1.7336098670959472,\n",
       "   1.7654872020085652,\n",
       "   1.9334880113601685,\n",
       "   1.624602778752645,\n",
       "   1.6626282811164856,\n",
       "   1.5766398827234904,\n",
       "   1.5907240152359008,\n",
       "   1.5456985314687093,\n",
       "   1.6906537850697836,\n",
       "   1.534473975499471,\n",
       "   1.5708049376805624,\n",
       "   1.4409317016601562,\n",
       "   1.484707760810852,\n",
       "   1.4680222749710083,\n",
       "   1.4395926554997762,\n",
       "   1.4265024503072103,\n",
       "   1.4348366578420004,\n",
       "   1.3872535467147826,\n",
       "   1.4042895595232645,\n",
       "   1.4529824018478394,\n",
       "   1.3434956192970275,\n",
       "   1.358979300657908,\n",
       "   1.3506789127985637,\n",
       "   1.3830251892407734,\n",
       "   1.4059051950772603,\n",
       "   1.3077828844388326,\n",
       "   1.4667471170425415,\n",
       "   1.4107090711593628,\n",
       "   1.4109071731567382,\n",
       "   1.376673658688863,\n",
       "   1.2418956637382508],\n",
       "  'val_losses': [5.366374969482422,\n",
       "   4.804888963699341,\n",
       "   4.463354825973511,\n",
       "   4.540805220603943,\n",
       "   4.439721345901489,\n",
       "   4.133311152458191,\n",
       "   4.340534210205078,\n",
       "   4.408755421638489,\n",
       "   4.2245423793792725,\n",
       "   4.019870162010193,\n",
       "   3.9530715942382812,\n",
       "   4.132264614105225,\n",
       "   3.758673071861267,\n",
       "   3.5295931100845337,\n",
       "   3.544015049934387,\n",
       "   3.392014980316162,\n",
       "   3.2736364603042603,\n",
       "   3.206416964530945,\n",
       "   3.0528743267059326,\n",
       "   3.140665650367737,\n",
       "   3.0990618467330933,\n",
       "   2.9416117668151855,\n",
       "   2.76787531375885,\n",
       "   2.8019782304763794,\n",
       "   2.524381697177887,\n",
       "   2.616325855255127,\n",
       "   2.636218547821045,\n",
       "   2.551678776741028,\n",
       "   2.5733591318130493,\n",
       "   2.7756656408309937,\n",
       "   2.440447211265564,\n",
       "   2.414895534515381,\n",
       "   2.3839077949523926,\n",
       "   2.353758215904236,\n",
       "   2.4718663692474365,\n",
       "   2.3576704263687134,\n",
       "   2.455046057701111,\n",
       "   2.2597488164901733,\n",
       "   2.2316280603408813,\n",
       "   2.181851327419281,\n",
       "   2.30606746673584,\n",
       "   2.3003960847854614,\n",
       "   2.480267286300659,\n",
       "   2.3742631673812866,\n",
       "   2.2351760864257812,\n",
       "   2.2359910011291504,\n",
       "   2.141849637031555,\n",
       "   2.1206193566322327,\n",
       "   2.171928644180298,\n",
       "   2.5969573259353638,\n",
       "   2.241114914417267]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.460 -4.028867\n",
       "  1   -4.120 -4.616905\n",
       "  2   -4.047 -4.782241\n",
       "  3   -0.600 -0.506450\n",
       "  4   -4.805 -2.679377\n",
       "  ..     ...       ...\n",
       "  44  -4.450 -2.007952\n",
       "  45  -4.160 -4.778201\n",
       "  46  -3.246 -4.765976\n",
       "  47  -1.990 -1.320613\n",
       "  48   0.790 -1.050286\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 110.2060215473175,\n",
       "  'mean_mse': 1.4099262,\n",
       "  'mean_l1': 0.94572675,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1): GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.4427191893259685,\n",
       "   3.574559958775838,\n",
       "   2.6997859319051107,\n",
       "   2.2144374370574953,\n",
       "   2.298208777109782,\n",
       "   1.7327657063802084,\n",
       "   1.7129679520924885,\n",
       "   1.668175506591797,\n",
       "   1.370224944750468,\n",
       "   1.209744123617808,\n",
       "   1.1898431698481242,\n",
       "   1.0076388239860534,\n",
       "   0.918153977394104,\n",
       "   0.9570265968640645,\n",
       "   0.94552001953125,\n",
       "   0.7741625169912975,\n",
       "   0.8534547865390778,\n",
       "   0.6665771087010701,\n",
       "   0.6506136000156403,\n",
       "   0.6378915786743165,\n",
       "   0.6727407077948252,\n",
       "   0.6937333544095358,\n",
       "   0.5586989124615988,\n",
       "   0.5429770290851593,\n",
       "   0.643044360478719,\n",
       "   0.5805116792519888,\n",
       "   0.5116048594315846,\n",
       "   0.47604157452782,\n",
       "   0.4897767980893453,\n",
       "   0.5875731746355692,\n",
       "   0.5114895035823186,\n",
       "   0.43883378704388937,\n",
       "   0.4496256152788798,\n",
       "   0.4739614804585775,\n",
       "   0.49622581601142884,\n",
       "   0.5408326466878255,\n",
       "   0.4529938836892446,\n",
       "   0.44036513566970825,\n",
       "   0.46384825706481936,\n",
       "   0.46645211974779766,\n",
       "   0.4425264378388723,\n",
       "   0.49903277307748795,\n",
       "   0.3964999516805013,\n",
       "   0.4022910535335541,\n",
       "   0.3659035181005796,\n",
       "   0.42747968435287476,\n",
       "   0.37931588987509407,\n",
       "   0.400265900293986,\n",
       "   0.372096860408783],\n",
       "  'val_losses': [6.355213165283203,\n",
       "   4.384799003601074,\n",
       "   4.080850124359131,\n",
       "   4.022688508033752,\n",
       "   3.3501944541931152,\n",
       "   3.2095720767974854,\n",
       "   2.801798939704895,\n",
       "   2.5541670322418213,\n",
       "   2.4196447134017944,\n",
       "   2.2191327810287476,\n",
       "   2.9886990785598755,\n",
       "   2.152320683002472,\n",
       "   2.1667126417160034,\n",
       "   2.3296241760253906,\n",
       "   2.415518283843994,\n",
       "   2.3622108697891235,\n",
       "   2.8133013248443604,\n",
       "   2.1019785404205322,\n",
       "   1.871316134929657,\n",
       "   1.824893057346344,\n",
       "   1.7375760078430176,\n",
       "   1.780831754207611,\n",
       "   1.8685851693153381,\n",
       "   1.763094425201416,\n",
       "   1.7539460062980652,\n",
       "   2.127846896648407,\n",
       "   1.6315020322799683,\n",
       "   1.6818280816078186,\n",
       "   1.742031753063202,\n",
       "   2.285056948661804,\n",
       "   1.6786348819732666,\n",
       "   2.0446653366088867,\n",
       "   1.6408622860908508,\n",
       "   1.65879225730896,\n",
       "   1.6110304594039917,\n",
       "   1.6809520721435547,\n",
       "   1.9453443884849548,\n",
       "   1.824248194694519,\n",
       "   2.0889941453933716,\n",
       "   1.7311366200447083,\n",
       "   1.7671726942062378,\n",
       "   2.551396131515503,\n",
       "   1.5728156566619873,\n",
       "   1.6634268760681152,\n",
       "   1.9838042855262756,\n",
       "   1.9600629806518555,\n",
       "   2.0491570234298706,\n",
       "   1.8099430203437805,\n",
       "   1.7031543850898743]},\n",
       " {'pred_df':     y_real     y_pred\n",
       "  0   -2.160  -3.108237\n",
       "  1   -3.610  -3.863874\n",
       "  2   -0.400   0.113562\n",
       "  3   -6.800 -11.058136\n",
       "  4   -4.799  -4.219340\n",
       "  ..     ...        ...\n",
       "  44  -8.040  -6.901672\n",
       "  45   0.300   0.437045\n",
       "  46  -4.805  -3.072567\n",
       "  47  -4.328  -4.739083\n",
       "  48  -4.310  -4.315476\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 104.78479027748108,\n",
       "  'mean_mse': 1.8919091,\n",
       "  'mean_l1': 1.0370202,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1): GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.785741313298543,\n",
       "   3.7646498044331866,\n",
       "   3.4144665161768595,\n",
       "   3.4425427754720053,\n",
       "   3.2247940858205157,\n",
       "   2.7240519086519877,\n",
       "   3.0228676160176593,\n",
       "   2.4627180337905883,\n",
       "   2.559419584274292,\n",
       "   2.4355833212534588,\n",
       "   2.129523817698161,\n",
       "   2.2281705220540364,\n",
       "   2.089461835225423,\n",
       "   2.0679917335510254,\n",
       "   1.9344168265660604,\n",
       "   2.023661708831787,\n",
       "   1.6479500889778138,\n",
       "   1.8056557893753051,\n",
       "   1.57073468764623,\n",
       "   1.5602928201357524,\n",
       "   1.4022178848584492,\n",
       "   1.50942173798879,\n",
       "   1.2587907195091248,\n",
       "   1.2946054140726726,\n",
       "   1.4738390604654947,\n",
       "   1.293553884824117,\n",
       "   1.1447327395280202,\n",
       "   1.3474334279696147,\n",
       "   1.230616851647695,\n",
       "   1.282665228843689,\n",
       "   1.294161864121755,\n",
       "   1.1463866631189983,\n",
       "   1.1328646620114644,\n",
       "   1.0868144353230795,\n",
       "   1.0931465705235799,\n",
       "   1.2073758999506632,\n",
       "   1.1844244639078776,\n",
       "   1.2029752254486084,\n",
       "   1.1587805549303691,\n",
       "   1.0626352111498514,\n",
       "   1.189889629681905,\n",
       "   1.243028450012207,\n",
       "   1.0505330721537272,\n",
       "   1.0365302006403605,\n",
       "   0.9996488690376282,\n",
       "   1.0987308700879415],\n",
       "  'val_losses': [5.889253616333008,\n",
       "   4.72131085395813,\n",
       "   4.262749195098877,\n",
       "   4.220305919647217,\n",
       "   4.406778335571289,\n",
       "   4.193254470825195,\n",
       "   3.8982547521591187,\n",
       "   4.048707604408264,\n",
       "   3.6419901847839355,\n",
       "   3.6620630025863647,\n",
       "   3.561252236366272,\n",
       "   3.279687523841858,\n",
       "   3.2396823167800903,\n",
       "   3.079803228378296,\n",
       "   2.867832660675049,\n",
       "   2.701830267906189,\n",
       "   2.561572849750519,\n",
       "   2.560309648513794,\n",
       "   2.299859046936035,\n",
       "   2.796580672264099,\n",
       "   2.132231891155243,\n",
       "   2.0723979473114014,\n",
       "   2.123043656349182,\n",
       "   2.223407745361328,\n",
       "   2.1015493869781494,\n",
       "   1.9195129871368408,\n",
       "   1.9753564596176147,\n",
       "   2.562209725379944,\n",
       "   1.9799488186836243,\n",
       "   2.2244428396224976,\n",
       "   1.8860917687416077,\n",
       "   2.022955298423767,\n",
       "   1.949242889881134,\n",
       "   2.0689135789871216,\n",
       "   1.998752474784851,\n",
       "   2.186123251914978,\n",
       "   2.0690691471099854,\n",
       "   2.154858350753784,\n",
       "   1.8300862908363342,\n",
       "   1.923154890537262,\n",
       "   2.2014448642730713,\n",
       "   1.8274247646331787,\n",
       "   2.015146851539612,\n",
       "   1.9148960709571838,\n",
       "   1.8766781091690063,\n",
       "   1.9326991438865662]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -0.742 -0.557152\n",
       "  1   -2.932 -1.595945\n",
       "  2   -3.171 -5.518779\n",
       "  3    0.790  0.243831\n",
       "  4   -3.590 -4.425595\n",
       "  ..     ...       ...\n",
       "  44  -6.780 -4.630441\n",
       "  45  -2.060  0.588917\n",
       "  46  -3.638 -2.637447\n",
       "  47  -1.899 -1.441021\n",
       "  48  -3.451 -5.007474\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 47.67151641845703,\n",
       "  'mean_mse': 2.0093634,\n",
       "  'mean_l1': 1.0690587,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1): GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.073008759816488,\n",
       "   3.7157350381215415,\n",
       "   3.32558118502299,\n",
       "   2.7809561173121136,\n",
       "   2.5636314392089843,\n",
       "   2.112135736147563,\n",
       "   2.0252259890238444,\n",
       "   1.7575559695561727,\n",
       "   1.9520272413889568,\n",
       "   1.4391539613405864,\n",
       "   1.531131927172343,\n",
       "   1.510452159245809,\n",
       "   1.2314326564470928,\n",
       "   1.192093801498413,\n",
       "   1.3783155043919881,\n",
       "   1.3954944968223573,\n",
       "   1.2202879031499227,\n",
       "   1.2769907395044962,\n",
       "   1.1176810622215272,\n",
       "   1.0572860638300579,\n",
       "   1.2611928542455038,\n",
       "   1.0535303552945454],\n",
       "  'val_losses': [4.977444171905518,\n",
       "   4.287316918373108,\n",
       "   4.347637891769409,\n",
       "   4.251515865325928,\n",
       "   3.6717053651809692,\n",
       "   3.7380775213241577,\n",
       "   3.086276888847351,\n",
       "   2.805670380592346,\n",
       "   3.156769633293152,\n",
       "   2.683694362640381,\n",
       "   2.451813578605652,\n",
       "   2.1851366758346558,\n",
       "   2.0396859645843506,\n",
       "   1.92270827293396,\n",
       "   2.384679079055786,\n",
       "   2.0445117950439453,\n",
       "   2.000381052494049,\n",
       "   1.957908570766449,\n",
       "   1.8689634203910828,\n",
       "   1.9717297554016113,\n",
       "   1.9244312644004822,\n",
       "   2.0236083269119263]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.450 -1.362120\n",
       "  1   -3.246 -5.587661\n",
       "  2   -6.020 -2.915780\n",
       "  3   -2.281 -1.792104\n",
       "  4   -3.043 -2.927058\n",
       "  ..     ...       ...\n",
       "  44  -5.915 -4.728582\n",
       "  45  -2.120 -1.579075\n",
       "  46  -2.160 -1.714383\n",
       "  47  -4.805 -2.583008\n",
       "  48  -6.860 -9.275180\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 57.60003733634949,\n",
       "  'mean_mse': 1.6011462,\n",
       "  'mean_l1': 0.98818207,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1): GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.852421871821085,\n",
       "   3.656949345270793,\n",
       "   2.768098990122477,\n",
       "   2.297875150044759,\n",
       "   1.953535944223404,\n",
       "   2.49912592569987,\n",
       "   1.5406248331069947,\n",
       "   1.39239750901858,\n",
       "   1.4097813606262206,\n",
       "   1.7118794957796732,\n",
       "   1.2525969584782919,\n",
       "   1.1496537605921426,\n",
       "   1.0590336839358012,\n",
       "   0.9508767902851105,\n",
       "   0.9956630110740662,\n",
       "   0.926795486609141,\n",
       "   0.9495459000269572,\n",
       "   0.8376064757506053,\n",
       "   0.8863598823547363,\n",
       "   0.916980501015981,\n",
       "   0.8849126855532329,\n",
       "   0.8532828191916147,\n",
       "   0.7495162884394327,\n",
       "   0.7614214936892192,\n",
       "   0.7285911480585734,\n",
       "   0.7729980945587158],\n",
       "  'val_losses': [5.741752624511719,\n",
       "   4.180520296096802,\n",
       "   4.035657167434692,\n",
       "   3.808906316757202,\n",
       "   3.351807117462158,\n",
       "   3.2086949348449707,\n",
       "   2.691059112548828,\n",
       "   2.3873575925827026,\n",
       "   2.194881319999695,\n",
       "   2.541013717651367,\n",
       "   2.066045582294464,\n",
       "   2.2027580738067627,\n",
       "   2.555814802646637,\n",
       "   2.0747352838516235,\n",
       "   2.487694263458252,\n",
       "   2.30522757768631,\n",
       "   1.8176023960113525,\n",
       "   2.052335739135742,\n",
       "   2.579906702041626,\n",
       "   2.0353400707244873,\n",
       "   2.1510218381881714,\n",
       "   1.8755725622177124,\n",
       "   1.9954568147659302,\n",
       "   1.8218814134597778,\n",
       "   1.9551422595977783,\n",
       "   2.1198349595069885]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.700 -3.707612\n",
       "  1   -4.047 -4.068165\n",
       "  2   -4.380 -4.667560\n",
       "  3   -7.280 -2.831876\n",
       "  4   -1.250 -0.633400\n",
       "  ..     ...       ...\n",
       "  44  -3.401 -0.944873\n",
       "  45  -5.220 -6.107625\n",
       "  46  -5.000 -6.082987\n",
       "  47  -8.040 -7.444954\n",
       "  48  -3.583 -1.074572\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 55.659629583358765,\n",
       "  'mean_mse': 1.8009849,\n",
       "  'mean_l1': 1.0430713,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-2): 2 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.34276933670044,\n",
       "   2.9789872725804645,\n",
       "   2.116306487719218,\n",
       "   2.0784606178601583,\n",
       "   1.7847564776738485,\n",
       "   1.722631780306498,\n",
       "   1.3607106884320577,\n",
       "   1.0265510429938633,\n",
       "   1.1878350377082825,\n",
       "   0.8507044672966003,\n",
       "   0.845521334807078,\n",
       "   0.7402618527412415,\n",
       "   0.8123700261116028,\n",
       "   0.6905491809050243,\n",
       "   0.6220678965250651,\n",
       "   0.7557331621646881,\n",
       "   0.5361954430739085,\n",
       "   0.5054988940556844,\n",
       "   0.477348667383194,\n",
       "   0.5255701025327046,\n",
       "   0.4845680832862854,\n",
       "   0.5484412550926209],\n",
       "  'val_losses': [7.527266025543213,\n",
       "   4.317305326461792,\n",
       "   4.473250865936279,\n",
       "   3.59374737739563,\n",
       "   2.9069727659225464,\n",
       "   2.5388253927230835,\n",
       "   2.7092514038085938,\n",
       "   1.9515966773033142,\n",
       "   2.5306025743484497,\n",
       "   1.9077092409133911,\n",
       "   1.986954391002655,\n",
       "   2.309567868709564,\n",
       "   2.7808170318603516,\n",
       "   2.0675268173217773,\n",
       "   1.8732044100761414,\n",
       "   2.303085148334503,\n",
       "   1.8834678530693054,\n",
       "   1.8180585503578186,\n",
       "   1.8917153477668762,\n",
       "   1.9948680400848389,\n",
       "   2.1245731115341187,\n",
       "   1.8925426006317139]},\n",
       " {'pred_df':     y_real     y_pred\n",
       "  0   -2.780  -4.927492\n",
       "  1   -3.460  -2.914627\n",
       "  2   -6.680  -7.264969\n",
       "  3   -1.960  -5.691004\n",
       "  4   -9.332 -11.131464\n",
       "  ..     ...        ...\n",
       "  44  -4.376  -4.297855\n",
       "  45  -2.100  -2.546299\n",
       "  46  -0.600  -1.433258\n",
       "  47  -2.943  -1.726588\n",
       "  48  -3.168  -2.359449\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 61.139070987701416,\n",
       "  'mean_mse': 1.7126126,\n",
       "  'mean_l1': 1.0208821,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-2): 2 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.662073103586833,\n",
       "   3.4798676490783693,\n",
       "   2.815758530298869,\n",
       "   2.557519006729126,\n",
       "   1.9063228766123455,\n",
       "   1.5499456644058227,\n",
       "   1.4024151682853698,\n",
       "   1.4157876054445901,\n",
       "   1.4465644796689352,\n",
       "   1.1075726389884948,\n",
       "   1.1221062421798706,\n",
       "   1.0320793290932972,\n",
       "   1.231226642926534,\n",
       "   1.0668995698293051,\n",
       "   0.9496736327807108,\n",
       "   0.8665236115455628,\n",
       "   0.8108981291453043,\n",
       "   0.7820781628290813,\n",
       "   0.8461377859115601,\n",
       "   0.9633005301157633,\n",
       "   0.655882332722346,\n",
       "   0.777535355091095,\n",
       "   0.7068614502747853,\n",
       "   0.6316643079121907,\n",
       "   0.6808383981386821],\n",
       "  'val_losses': [7.379740238189697,\n",
       "   4.850696563720703,\n",
       "   3.9984995126724243,\n",
       "   3.511600971221924,\n",
       "   2.739283323287964,\n",
       "   3.4350035190582275,\n",
       "   1.9860585927963257,\n",
       "   3.2241783142089844,\n",
       "   3.475441813468933,\n",
       "   3.618142247200012,\n",
       "   1.8243513703346252,\n",
       "   2.0275917053222656,\n",
       "   1.7344157695770264,\n",
       "   1.8422213792800903,\n",
       "   2.004574418067932,\n",
       "   1.9953952431678772,\n",
       "   1.859565645456314,\n",
       "   1.9337937831878662,\n",
       "   2.1058470010757446,\n",
       "   1.8105491399765015,\n",
       "   1.999980628490448,\n",
       "   1.8836288452148438,\n",
       "   2.05374014377594,\n",
       "   1.7879199981689453,\n",
       "   1.7227038741111755]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.451 -4.779144\n",
       "  1   -2.982 -2.902013\n",
       "  2   -8.000 -8.693788\n",
       "  3   -3.401 -1.783852\n",
       "  4   -3.931 -6.801219\n",
       "  ..     ...       ...\n",
       "  44  -3.120 -2.615776\n",
       "  45  -4.634 -3.999017\n",
       "  46  -8.040 -7.504797\n",
       "  47  -5.915 -4.069627\n",
       "  48  -2.461 -2.174668\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 63.88862228393555,\n",
       "  'mean_mse': 1.5591028,\n",
       "  'mean_l1': 0.9641618,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-2): 2 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.724641640981038,\n",
       "   3.2405948479970297,\n",
       "   2.7562174638112387,\n",
       "   2.327031397819519,\n",
       "   2.488456622759501,\n",
       "   1.8955879211425781,\n",
       "   1.3262966871261597,\n",
       "   1.149099882443746,\n",
       "   1.206854224205017,\n",
       "   0.9862392107645671,\n",
       "   0.9029893318812052,\n",
       "   0.8669053534666697,\n",
       "   0.9494571288426717,\n",
       "   0.7345464487870534,\n",
       "   0.7078447202841441,\n",
       "   0.7228469908237457,\n",
       "   0.6943046649297079,\n",
       "   0.6430440088113148,\n",
       "   0.5777037064234416,\n",
       "   0.6082498013973237,\n",
       "   0.5457244515419006,\n",
       "   0.528263121843338,\n",
       "   0.5256103018919627,\n",
       "   0.5312773764133454,\n",
       "   0.8212112625439961],\n",
       "  'val_losses': [7.4876549243927,\n",
       "   4.48910927772522,\n",
       "   4.1736671924591064,\n",
       "   3.614588499069214,\n",
       "   3.1594247817993164,\n",
       "   2.8047667741775513,\n",
       "   2.4472532272338867,\n",
       "   2.9216099977493286,\n",
       "   2.3289071321487427,\n",
       "   2.714454770088196,\n",
       "   2.1162400245666504,\n",
       "   2.197865307331085,\n",
       "   1.7942971587181091,\n",
       "   1.9990423321723938,\n",
       "   2.2948150038719177,\n",
       "   1.7480729818344116,\n",
       "   1.9239487648010254,\n",
       "   1.6620429158210754,\n",
       "   1.9322085976600647,\n",
       "   1.7303301095962524,\n",
       "   1.6787391901016235,\n",
       "   1.6573885679244995,\n",
       "   2.005995452404022,\n",
       "   1.6130343079566956,\n",
       "   2.027686059474945]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.960 -3.061427\n",
       "  1   -3.094 -2.646559\n",
       "  2    0.300  0.101171\n",
       "  3   -7.280 -4.704209\n",
       "  4   -4.883 -5.127007\n",
       "  ..     ...       ...\n",
       "  44  -2.780 -4.872384\n",
       "  45  -6.237 -4.554849\n",
       "  46  -5.270 -5.216556\n",
       "  47  -3.171 -4.704692\n",
       "  48  -2.266 -1.036525\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 119.7274158000946,\n",
       "  'mean_mse': 1.3445579,\n",
       "  'mean_l1': 0.91734964,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-3): 3 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.997266594568888,\n",
       "   3.4073105653127036,\n",
       "   2.6577735424041746,\n",
       "   1.9768929998079936,\n",
       "   2.8083236535390217,\n",
       "   1.523839779694875,\n",
       "   1.4750170151392619,\n",
       "   1.0403019726276397,\n",
       "   0.8391595999399821,\n",
       "   0.7119554897149404,\n",
       "   0.7387814919153849,\n",
       "   0.735261615117391,\n",
       "   0.8060756862163544,\n",
       "   0.48990914424260457,\n",
       "   0.49175785779953,\n",
       "   0.529194884498914,\n",
       "   0.5588477432727814,\n",
       "   0.4887303014596303,\n",
       "   0.43468825817108153,\n",
       "   0.45769544740517937,\n",
       "   0.3503338168064753,\n",
       "   0.4130909244219462,\n",
       "   0.5225945035616557,\n",
       "   0.3326550384362539,\n",
       "   0.2719820261001587,\n",
       "   0.3107207934061686,\n",
       "   0.3190627947449684,\n",
       "   0.2697036415338516,\n",
       "   0.24143485923608143,\n",
       "   0.27023606896400454,\n",
       "   0.2905574043591817,\n",
       "   0.20543181349833806,\n",
       "   0.2464164356390635,\n",
       "   0.2537288079659144,\n",
       "   0.18281590044498444,\n",
       "   0.23841182788213094,\n",
       "   0.19092273910840352,\n",
       "   0.2280499170223872,\n",
       "   0.22044076720873515,\n",
       "   0.5497188210487366,\n",
       "   0.17473512788613638],\n",
       "  'val_losses': [8.138221263885498,\n",
       "   4.1494786739349365,\n",
       "   3.832362651824951,\n",
       "   2.878631591796875,\n",
       "   3.2479583024978638,\n",
       "   2.2439175844192505,\n",
       "   2.376542806625366,\n",
       "   2.298895239830017,\n",
       "   1.8673423528671265,\n",
       "   1.99545156955719,\n",
       "   1.9656548500061035,\n",
       "   1.6513543128967285,\n",
       "   1.5859372019767761,\n",
       "   1.6887513399124146,\n",
       "   1.462891012430191,\n",
       "   1.66126149892807,\n",
       "   1.8047664761543274,\n",
       "   2.1562540531158447,\n",
       "   1.6349666714668274,\n",
       "   1.5589298009872437,\n",
       "   1.6275710463523865,\n",
       "   1.4757039546966553,\n",
       "   1.306786596775055,\n",
       "   1.5582677125930786,\n",
       "   1.4897821545600891,\n",
       "   1.4352673292160034,\n",
       "   1.4022602438926697,\n",
       "   1.5355104804039001,\n",
       "   1.5897476077079773,\n",
       "   1.3281122148036957,\n",
       "   1.2724449634552002,\n",
       "   1.3665205240249634,\n",
       "   1.3014752864837646,\n",
       "   1.883782982826233,\n",
       "   1.3452016115188599,\n",
       "   1.3794365525245667,\n",
       "   1.200577735900879,\n",
       "   1.322144091129303,\n",
       "   1.4336069822311401,\n",
       "   3.501347303390503,\n",
       "   1.329557329416275]},\n",
       " {'pred_df':     y_real     y_pred\n",
       "  0   -6.800  -7.775433\n",
       "  1   -3.610  -4.712630\n",
       "  2   -4.925  -4.461947\n",
       "  3   -3.060  -2.055159\n",
       "  4   -4.450  -3.288847\n",
       "  ..     ...        ...\n",
       "  44  -9.018 -10.068431\n",
       "  45  -1.960  -5.738014\n",
       "  46  -4.328  -4.299870\n",
       "  47  -5.915  -4.970231\n",
       "  48  -6.726  -6.762408\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 89.12075686454773,\n",
       "  'mean_mse': 1.5420439,\n",
       "  'mean_l1': 0.9525486,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-3): 3 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.397082916895548,\n",
       "   3.386433219909668,\n",
       "   2.5965967814127606,\n",
       "   2.035945097605387,\n",
       "   1.8028272151947022,\n",
       "   1.8403213183085123,\n",
       "   1.2019319772720336,\n",
       "   1.0983475248018901,\n",
       "   1.2063802202542624,\n",
       "   1.0934446811676026,\n",
       "   0.9905281523863475,\n",
       "   1.2039677143096923,\n",
       "   1.4436219498515128,\n",
       "   1.1217278053363164,\n",
       "   0.6882359544436137,\n",
       "   0.6605024496714275,\n",
       "   0.6564949075380961,\n",
       "   0.587386836608251,\n",
       "   0.6837453921635945,\n",
       "   0.5717532992362976,\n",
       "   0.48455968300501506,\n",
       "   0.6459628800551097,\n",
       "   0.48184358278910316,\n",
       "   0.49802066187063854,\n",
       "   0.5830984810988108,\n",
       "   0.41552898089090984,\n",
       "   0.43149564067522683,\n",
       "   0.39501422544320425,\n",
       "   1.104667564233144,\n",
       "   0.40110060572624207,\n",
       "   0.3724062263965607,\n",
       "   0.37009296789765356],\n",
       "  'val_losses': [6.597899913787842,\n",
       "   4.386729001998901,\n",
       "   3.6985974311828613,\n",
       "   2.757695198059082,\n",
       "   2.2422962188720703,\n",
       "   2.092270612716675,\n",
       "   2.214208960533142,\n",
       "   1.9957236051559448,\n",
       "   3.1413878202438354,\n",
       "   1.8512088060379028,\n",
       "   2.027015268802643,\n",
       "   1.8779352307319641,\n",
       "   1.7418474555015564,\n",
       "   1.6622678637504578,\n",
       "   2.0214349031448364,\n",
       "   1.6719638109207153,\n",
       "   1.9734755158424377,\n",
       "   1.636841058731079,\n",
       "   1.7720239758491516,\n",
       "   2.4369356632232666,\n",
       "   1.76128488779068,\n",
       "   1.628743588924408,\n",
       "   1.569149911403656,\n",
       "   1.7061023712158203,\n",
       "   1.6286100149154663,\n",
       "   2.086588501930237,\n",
       "   2.3719526529312134,\n",
       "   1.588198721408844,\n",
       "   1.6422154307365417,\n",
       "   2.3110933899879456,\n",
       "   1.6573854088783264,\n",
       "   1.73729407787323]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.883 -5.318721\n",
       "  1   -1.250 -1.407435\n",
       "  2   -6.237 -3.840011\n",
       "  3   -3.538 -4.110115\n",
       "  4   -1.960 -4.014284\n",
       "  ..     ...       ...\n",
       "  44  -0.400 -1.127836\n",
       "  45  -3.931 -6.660655\n",
       "  46  -3.460 -2.783722\n",
       "  47  -3.583 -1.419185\n",
       "  48  -1.040 -3.046901\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 74.18529200553894,\n",
       "  'mean_mse': 1.4125428,\n",
       "  'mean_l1': 0.9182079,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-3): 3 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.764206329981486,\n",
       "   2.7888723691304524,\n",
       "   2.2468196868896486,\n",
       "   1.7339480559031168,\n",
       "   1.4137729247411093,\n",
       "   1.3510558684666951,\n",
       "   1.1964921673138937,\n",
       "   0.9865239302317301,\n",
       "   1.0504745284716288,\n",
       "   0.6802463511625926,\n",
       "   0.7456328630447387,\n",
       "   0.8880279421806335,\n",
       "   0.7353670994440714,\n",
       "   0.9666596094767252,\n",
       "   0.5537395755449931,\n",
       "   0.7059964676698048,\n",
       "   0.5068225165208181,\n",
       "   0.5667162895202636,\n",
       "   0.4878642737865448,\n",
       "   0.49068126678466795,\n",
       "   0.45767229199409487,\n",
       "   0.4165221025546392,\n",
       "   0.4252887378136317,\n",
       "   0.44223751028378805,\n",
       "   0.4164534499247869],\n",
       "  'val_losses': [7.613913059234619,\n",
       "   3.9524346590042114,\n",
       "   3.4440664052963257,\n",
       "   2.408342123031616,\n",
       "   2.2151190042495728,\n",
       "   3.097168803215027,\n",
       "   2.6118576526641846,\n",
       "   2.0390413403511047,\n",
       "   2.7370537519454956,\n",
       "   2.5308234691619873,\n",
       "   2.1083920001983643,\n",
       "   2.054420530796051,\n",
       "   1.9613216519355774,\n",
       "   1.9296927452087402,\n",
       "   1.8579020500183105,\n",
       "   1.7428287863731384,\n",
       "   1.7490636110305786,\n",
       "   1.895783245563507,\n",
       "   1.706177532672882,\n",
       "   1.7647840976715088,\n",
       "   2.4548202753067017,\n",
       "   1.6213191747665405,\n",
       "   1.7346253395080566,\n",
       "   1.6913295984268188,\n",
       "   1.8185877799987793]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.950 -2.848641\n",
       "  1   -4.450 -1.761169\n",
       "  2   -1.740 -3.872021\n",
       "  3   -5.915 -4.427392\n",
       "  4   -3.620 -3.708654\n",
       "  ..     ...       ...\n",
       "  44  -7.800 -6.215059\n",
       "  45  -1.990 -3.622454\n",
       "  46  -3.094 -2.581136\n",
       "  47  -4.173 -5.031294\n",
       "  48  -4.632 -3.103903\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 85.2419102191925,\n",
       "  'mean_mse': 1.8617127,\n",
       "  'mean_l1': 1.0775058,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.174742285410563,\n",
       "   3.486490273475647,\n",
       "   3.314666430155436,\n",
       "   3.1710458596547446,\n",
       "   2.9539145628611245,\n",
       "   2.6613083918889364,\n",
       "   2.4266401688257853,\n",
       "   2.455661145846049,\n",
       "   2.2064697186152142,\n",
       "   2.1788471937179565,\n",
       "   1.990475300947825,\n",
       "   1.988573932647705,\n",
       "   1.877614943186442,\n",
       "   1.826125200589498,\n",
       "   1.9081061840057374,\n",
       "   1.8904594898223877,\n",
       "   1.630012309551239,\n",
       "   1.606362235546112,\n",
       "   1.5987867951393127,\n",
       "   1.5792814786235492,\n",
       "   1.4662824591000876,\n",
       "   1.6571126619974772,\n",
       "   1.4746261596679688,\n",
       "   1.454619860649109,\n",
       "   1.3937086502710978,\n",
       "   1.3557453155517578,\n",
       "   1.2868611296017964,\n",
       "   1.2337231278419494,\n",
       "   1.343877895673116,\n",
       "   1.265749498208364,\n",
       "   1.2137006163597106,\n",
       "   1.2028904239336649,\n",
       "   1.1636350194613139,\n",
       "   1.2235068003336589,\n",
       "   1.1158121267954508,\n",
       "   1.126529542605082,\n",
       "   1.1734354178110757,\n",
       "   1.0427069107691447,\n",
       "   1.0156525353590646,\n",
       "   1.1439487258593242,\n",
       "   0.9986991643905639],\n",
       "  'val_losses': [4.780035018920898,\n",
       "   4.526657819747925,\n",
       "   4.269282817840576,\n",
       "   4.1916433572769165,\n",
       "   4.340789079666138,\n",
       "   4.336601495742798,\n",
       "   4.340749025344849,\n",
       "   3.963874936103821,\n",
       "   4.137503147125244,\n",
       "   4.002792239189148,\n",
       "   4.211902141571045,\n",
       "   3.4973970651626587,\n",
       "   3.5175909996032715,\n",
       "   3.319368600845337,\n",
       "   3.1397522687911987,\n",
       "   3.1314568519592285,\n",
       "   3.0227606296539307,\n",
       "   3.4178332090377808,\n",
       "   3.265476703643799,\n",
       "   2.9848510026931763,\n",
       "   2.7095972299575806,\n",
       "   2.714337944984436,\n",
       "   2.8548550605773926,\n",
       "   2.4904496669769287,\n",
       "   2.572519540786743,\n",
       "   2.9416937828063965,\n",
       "   2.488821268081665,\n",
       "   2.7166448831558228,\n",
       "   2.403883934020996,\n",
       "   2.4091822504997253,\n",
       "   2.6312737464904785,\n",
       "   2.3018122911453247,\n",
       "   2.4652628302574158,\n",
       "   2.3303136825561523,\n",
       "   2.2732189893722534,\n",
       "   2.341541051864624,\n",
       "   2.1038413643836975,\n",
       "   2.115937054157257,\n",
       "   2.168950915336609,\n",
       "   2.099234402179718,\n",
       "   2.313943386077881]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.590 -4.480653\n",
       "  1   -8.000 -6.272362\n",
       "  2   -1.040 -3.627057\n",
       "  3   -3.451 -4.777056\n",
       "  4   -3.401 -2.797614\n",
       "  ..     ...       ...\n",
       "  44  -4.380 -4.208463\n",
       "  45  -6.800 -8.810770\n",
       "  46  -4.160 -5.378471\n",
       "  47  -3.620 -3.090436\n",
       "  48   0.300 -0.756120\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 102.24794030189514,\n",
       "  'mean_mse': 1.951656,\n",
       "  'mean_l1': 1.0487108,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.123663489023844,\n",
       "   3.7928878466288247,\n",
       "   3.721610991160075,\n",
       "   3.7662505149841308,\n",
       "   3.3657431761423746,\n",
       "   3.4072125275929768,\n",
       "   3.159571671485901,\n",
       "   3.0825566689173383,\n",
       "   2.8779758056004843,\n",
       "   2.844613862037659,\n",
       "   2.655233097076416,\n",
       "   2.8044142882029215,\n",
       "   2.5844544569651284,\n",
       "   2.55299178759257,\n",
       "   2.44855748017629,\n",
       "   2.395296883583069,\n",
       "   2.276328508059184,\n",
       "   2.4074302117029824,\n",
       "   2.20278476079305,\n",
       "   2.2031057357788084,\n",
       "   2.0978498975435893,\n",
       "   2.0570945739746094,\n",
       "   2.117685643831889,\n",
       "   2.0313023408253987,\n",
       "   2.1719247420628864,\n",
       "   1.939509932200114,\n",
       "   1.9989542961120605,\n",
       "   2.0556677023569745,\n",
       "   1.9489162842432657,\n",
       "   1.9534507155418397,\n",
       "   1.9200783332188924,\n",
       "   1.890471132596334,\n",
       "   1.6910245974858602,\n",
       "   1.6900369644165039,\n",
       "   1.6974553346633912,\n",
       "   1.6640451431274415,\n",
       "   1.6762624979019165,\n",
       "   1.5935638745625813,\n",
       "   1.6200428883234659,\n",
       "   1.5687471707661946,\n",
       "   1.7349033117294312,\n",
       "   1.999813191095988,\n",
       "   1.587420924504598,\n",
       "   1.528463856379191,\n",
       "   1.478709133466085,\n",
       "   1.4519346197446188,\n",
       "   1.5380543231964112,\n",
       "   1.4035223205884297,\n",
       "   1.4382466554641724,\n",
       "   1.408236034711202,\n",
       "   1.6536458293596903,\n",
       "   1.4281411012013754,\n",
       "   1.4688528458277383],\n",
       "  'val_losses': [6.248069763183594,\n",
       "   4.647130608558655,\n",
       "   4.633086681365967,\n",
       "   4.890018939971924,\n",
       "   4.6595330238342285,\n",
       "   4.302891135215759,\n",
       "   4.505584239959717,\n",
       "   4.126260161399841,\n",
       "   4.413296818733215,\n",
       "   3.9301726818084717,\n",
       "   4.248853445053101,\n",
       "   3.919691324234009,\n",
       "   3.8850449323654175,\n",
       "   4.079607725143433,\n",
       "   3.6676242351531982,\n",
       "   4.039161682128906,\n",
       "   3.549307703971863,\n",
       "   3.4854835271835327,\n",
       "   3.914342164993286,\n",
       "   3.5959646701812744,\n",
       "   3.564348578453064,\n",
       "   3.0232550501823425,\n",
       "   3.032733678817749,\n",
       "   3.0410574674606323,\n",
       "   2.8444173336029053,\n",
       "   2.807013988494873,\n",
       "   2.992343306541443,\n",
       "   2.863674759864807,\n",
       "   2.6938918828964233,\n",
       "   2.9435518980026245,\n",
       "   2.6318224668502808,\n",
       "   2.530615448951721,\n",
       "   2.5232012271881104,\n",
       "   2.6304904222488403,\n",
       "   2.6098384857177734,\n",
       "   2.573166608810425,\n",
       "   2.4510154724121094,\n",
       "   2.30892813205719,\n",
       "   2.412209987640381,\n",
       "   2.359673023223877,\n",
       "   2.668672561645508,\n",
       "   2.347768187522888,\n",
       "   2.1169238686561584,\n",
       "   2.067521631717682,\n",
       "   2.1700453758239746,\n",
       "   2.08965265750885,\n",
       "   2.343041956424713,\n",
       "   1.999224305152893,\n",
       "   2.0384616255760193,\n",
       "   2.180454134941101,\n",
       "   2.0095314979553223,\n",
       "   2.007952034473419,\n",
       "   2.161353886127472]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.920 -1.752353\n",
       "  1   -4.120 -4.809168\n",
       "  2   -7.280 -3.672246\n",
       "  3   -9.332 -7.718535\n",
       "  4   -4.445 -5.523654\n",
       "  ..     ...       ...\n",
       "  44  -3.583 -2.470533\n",
       "  45  -1.250  0.316312\n",
       "  46  -3.451 -4.468856\n",
       "  47  -2.780 -3.974104\n",
       "  48  -1.800 -2.296781\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 61.545782804489136,\n",
       "  'mean_mse': 1.6940591,\n",
       "  'mean_l1': 1.0079943,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1): GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.2477401415506995,\n",
       "   3.620550028483073,\n",
       "   3.294975233078003,\n",
       "   3.1450576464335125,\n",
       "   2.89953875541687,\n",
       "   2.6579350312550862,\n",
       "   2.2139914512634276,\n",
       "   2.2797868569691975,\n",
       "   2.0268240292867024,\n",
       "   2.0189749081929524,\n",
       "   1.6052252372105917,\n",
       "   1.770095737775167,\n",
       "   1.526206910610199,\n",
       "   1.5968588829040526,\n",
       "   1.5958757162094117,\n",
       "   1.4984095176060994,\n",
       "   1.2671894232432048,\n",
       "   1.217166292667389,\n",
       "   1.133058899641037,\n",
       "   1.1589779496192931,\n",
       "   1.0652423580487569,\n",
       "   1.0576594750086465,\n",
       "   1.0762136340141297,\n",
       "   0.9731428543726603,\n",
       "   1.1374836246172586,\n",
       "   1.025819092988968,\n",
       "   0.950924277305603,\n",
       "   0.9120109756787618,\n",
       "   0.8751564939816793,\n",
       "   1.0203755060831705,\n",
       "   0.8716635465621948,\n",
       "   0.8867486596107483],\n",
       "  'val_losses': [5.920195817947388,\n",
       "   4.756272315979004,\n",
       "   4.107821941375732,\n",
       "   4.019503712654114,\n",
       "   4.242730736732483,\n",
       "   3.985804796218872,\n",
       "   4.027029395103455,\n",
       "   3.5019490718841553,\n",
       "   3.477156400680542,\n",
       "   3.186233162879944,\n",
       "   3.1896743774414062,\n",
       "   3.1627864837646484,\n",
       "   2.8434319496154785,\n",
       "   2.5959166288375854,\n",
       "   2.459216356277466,\n",
       "   2.473800778388977,\n",
       "   2.286550998687744,\n",
       "   2.495904564857483,\n",
       "   2.5185546875,\n",
       "   2.943164110183716,\n",
       "   2.064216911792755,\n",
       "   2.0475445985794067,\n",
       "   1.9660457968711853,\n",
       "   2.065414845943451,\n",
       "   1.865499198436737,\n",
       "   1.985213279724121,\n",
       "   2.046489715576172,\n",
       "   2.1289795637130737,\n",
       "   1.904891848564148,\n",
       "   2.06061053276062,\n",
       "   1.9564021229743958,\n",
       "   2.1240251064300537]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -0.742 -3.306426\n",
       "  1   -4.632 -3.192304\n",
       "  2   -2.350 -3.216864\n",
       "  3   -3.290 -4.332502\n",
       "  4   -6.237 -3.743024\n",
       "  ..     ...       ...\n",
       "  44  -2.461 -3.116206\n",
       "  45  -5.410 -3.754097\n",
       "  46  -3.094 -3.400812\n",
       "  47  -4.173 -3.752961\n",
       "  48  -4.120 -3.437395\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 20.36667513847351,\n",
       "  'mean_mse': 3.569377,\n",
       "  'mean_l1': 1.3904936,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.838812923431396,\n",
       "   3.7480372905731203,\n",
       "   3.6327201684315997,\n",
       "   3.131029538313548,\n",
       "   3.043071683247884,\n",
       "   3.150264326731364,\n",
       "   2.8686118125915527,\n",
       "   2.7502903938293457,\n",
       "   2.658682386080424,\n",
       "   2.6001410643259684],\n",
       "  'val_losses': [5.173688650131226,\n",
       "   4.842506647109985,\n",
       "   4.3522210121154785,\n",
       "   4.429385185241699,\n",
       "   4.37586236000061,\n",
       "   4.110981583595276,\n",
       "   4.385001182556152,\n",
       "   4.198763012886047,\n",
       "   4.21731960773468,\n",
       "   4.148826599121094]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.658 -5.280117\n",
       "  1   -2.920 -2.134593\n",
       "  2   -7.280 -4.105456\n",
       "  3   -4.380 -4.186152\n",
       "  4   -5.190 -5.235665\n",
       "  ..     ...       ...\n",
       "  44  -5.696 -4.324318\n",
       "  45  -4.173 -4.926448\n",
       "  46  -4.160 -4.828382\n",
       "  47  -2.982 -2.173534\n",
       "  48  -1.640 -4.106558\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 90.38357400894165,\n",
       "  'mean_mse': 1.3824158,\n",
       "  'mean_l1': 0.9193532,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1): GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.697155567010244,\n",
       "   3.6294943968455,\n",
       "   2.679663300514221,\n",
       "   2.2665980736414593,\n",
       "   2.423761836687724,\n",
       "   1.847749662399292,\n",
       "   1.774645249048869,\n",
       "   1.6892151355743408,\n",
       "   1.5640590031941732,\n",
       "   1.1962562402089436,\n",
       "   1.1426008661588034,\n",
       "   0.9727276047070821,\n",
       "   0.9274225274721781,\n",
       "   0.9505187014738719,\n",
       "   0.8983603318532308,\n",
       "   0.8042389353116354,\n",
       "   0.717446219921112,\n",
       "   0.7087628444035848,\n",
       "   0.7158392031987508,\n",
       "   0.6572810848553975,\n",
       "   0.8683585087458293,\n",
       "   0.6282491604487102,\n",
       "   0.5829587976137797,\n",
       "   0.6360097448031108,\n",
       "   0.5607897043228149,\n",
       "   0.5913512388865153,\n",
       "   0.5839413086573283,\n",
       "   0.5664740482966105,\n",
       "   0.4921505779027939,\n",
       "   0.5839085201422374,\n",
       "   0.6116559227307637,\n",
       "   0.4442047814528147,\n",
       "   0.6007363577683766,\n",
       "   0.47464922269185383,\n",
       "   0.443756095568339,\n",
       "   0.4038186490535736,\n",
       "   0.4310213347276052],\n",
       "  'val_losses': [5.671322584152222,\n",
       "   4.665076732635498,\n",
       "   4.413290977478027,\n",
       "   3.774498462677002,\n",
       "   3.4261717796325684,\n",
       "   3.188065528869629,\n",
       "   2.8700058460235596,\n",
       "   2.605080485343933,\n",
       "   2.316574215888977,\n",
       "   2.1400980949401855,\n",
       "   2.1935030817985535,\n",
       "   2.1428210735321045,\n",
       "   1.982201099395752,\n",
       "   1.7818866968154907,\n",
       "   1.7189111113548279,\n",
       "   1.7932505011558533,\n",
       "   1.7013747692108154,\n",
       "   1.7686278223991394,\n",
       "   1.6591567993164062,\n",
       "   1.7437721490859985,\n",
       "   2.0015565156936646,\n",
       "   1.561571478843689,\n",
       "   1.5776354670524597,\n",
       "   1.5119780004024506,\n",
       "   1.5493723154067993,\n",
       "   1.938244104385376,\n",
       "   1.6815602779388428,\n",
       "   1.5795126557350159,\n",
       "   1.5680994391441345,\n",
       "   1.5741857290267944,\n",
       "   1.6323628425598145,\n",
       "   1.7899580597877502,\n",
       "   1.5297780632972717,\n",
       "   1.5505638718605042,\n",
       "   1.4260262846946716,\n",
       "   1.4072437286376953,\n",
       "   1.5049896240234375]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.460 -3.808038\n",
       "  1   -4.445 -4.902585\n",
       "  2   -9.018 -9.074232\n",
       "  3   -2.920 -1.974504\n",
       "  4   -3.800 -4.072893\n",
       "  ..     ...       ...\n",
       "  44  -6.780 -4.783176\n",
       "  45  -5.915 -4.123802\n",
       "  46  -4.805 -2.830366\n",
       "  47  -5.400 -5.072154\n",
       "  48  -2.700 -3.261994\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 61.746777057647705,\n",
       "  'mean_mse': 1.8360789,\n",
       "  'mean_l1': 1.0345501,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1): GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.514932664235433,\n",
       "   3.8880661964416503,\n",
       "   3.391747315724691,\n",
       "   2.6402723948160807,\n",
       "   2.1928216934204103,\n",
       "   2.162153426806132,\n",
       "   1.8119826237360637,\n",
       "   1.8296026229858398,\n",
       "   1.4739909648895264,\n",
       "   1.4446076591809591,\n",
       "   1.3708210865656534,\n",
       "   1.2096791205306847,\n",
       "   1.2159704248110452,\n",
       "   1.2679266850153605,\n",
       "   1.192761226495107,\n",
       "   1.1054568449656168,\n",
       "   1.2445599257946014,\n",
       "   1.1052888909975687,\n",
       "   1.0824858903884889,\n",
       "   1.3096572915712992,\n",
       "   1.1812927643458049,\n",
       "   1.1312237819035849,\n",
       "   1.1707444389661152,\n",
       "   1.3153372446695963,\n",
       "   0.9589749415715535,\n",
       "   0.9300194104512532,\n",
       "   0.8891101469596226],\n",
       "  'val_losses': [5.251735687255859,\n",
       "   4.490884780883789,\n",
       "   4.0237414836883545,\n",
       "   3.820401191711426,\n",
       "   3.24476420879364,\n",
       "   2.9651440382003784,\n",
       "   2.5976101756095886,\n",
       "   2.27894127368927,\n",
       "   2.1744120717048645,\n",
       "   2.8605910539627075,\n",
       "   1.9731516242027283,\n",
       "   1.895189106464386,\n",
       "   1.8286082744598389,\n",
       "   2.142194151878357,\n",
       "   1.8993934392929077,\n",
       "   1.88331538438797,\n",
       "   1.7765344381332397,\n",
       "   1.9051274061203003,\n",
       "   2.01339590549469,\n",
       "   1.9146979451179504,\n",
       "   1.8663718700408936,\n",
       "   1.8695395588874817,\n",
       "   1.8959795236587524,\n",
       "   2.1298877000808716,\n",
       "   1.807262659072876,\n",
       "   1.832978904247284,\n",
       "   1.9276475310325623]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.040 -2.817165\n",
       "  1   -2.100 -1.959494\n",
       "  2   -4.328 -4.606182\n",
       "  3   -3.930 -2.569166\n",
       "  4   -3.021 -4.368967\n",
       "  ..     ...       ...\n",
       "  44   0.522  0.561382\n",
       "  45  -3.050 -3.328073\n",
       "  46  -0.600 -0.880946\n",
       "  47  -3.168 -2.429670\n",
       "  48  -7.280 -4.066541\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 81.78425884246826,\n",
       "  'mean_mse': 1.5742508,\n",
       "  'mean_l1': 0.98854053,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1): GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.074530982971192,\n",
       "   3.5198856830596923,\n",
       "   2.6667560338974,\n",
       "   2.400993259747823,\n",
       "   1.9783290386199952,\n",
       "   2.0563113768895467,\n",
       "   1.572551041841507,\n",
       "   1.8508058865865071,\n",
       "   1.4318724314371745,\n",
       "   1.3330941160519918,\n",
       "   1.3223862886428832,\n",
       "   1.103068200747172,\n",
       "   1.1537422021230062,\n",
       "   1.0440757066011428,\n",
       "   1.0425804058710735,\n",
       "   1.0884652654329936,\n",
       "   0.899718431631724,\n",
       "   0.8547213514645894,\n",
       "   1.1588916103045146,\n",
       "   0.8662266890207927,\n",
       "   0.8199201345443725,\n",
       "   0.8910508612791698,\n",
       "   0.8416012605031331,\n",
       "   0.7475713133811951,\n",
       "   0.8173885524272919,\n",
       "   0.743572058280309,\n",
       "   0.744111180305481,\n",
       "   0.6511248111724853,\n",
       "   0.6785952925682068,\n",
       "   0.7088031272093455],\n",
       "  'val_losses': [5.711199045181274,\n",
       "   4.566542387008667,\n",
       "   4.300166487693787,\n",
       "   3.861642837524414,\n",
       "   3.578921675682068,\n",
       "   3.925447106361389,\n",
       "   2.8700270652770996,\n",
       "   2.8329139947891235,\n",
       "   2.316581904888153,\n",
       "   4.402837038040161,\n",
       "   2.6309714317321777,\n",
       "   2.095572829246521,\n",
       "   2.270553708076477,\n",
       "   2.156752586364746,\n",
       "   2.010834574699402,\n",
       "   2.0894047021865845,\n",
       "   1.7837161421775818,\n",
       "   2.4926459789276123,\n",
       "   2.7727466821670532,\n",
       "   1.9431829452514648,\n",
       "   2.0986387729644775,\n",
       "   1.8158705830574036,\n",
       "   2.127037286758423,\n",
       "   1.9682294726371765,\n",
       "   1.6619070172309875,\n",
       "   1.8538090586662292,\n",
       "   1.9015979766845703,\n",
       "   1.8060864210128784,\n",
       "   1.804319679737091,\n",
       "   1.8130584955215454]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.538 -4.578046\n",
       "  1   -3.246 -5.588338\n",
       "  2   -3.931 -6.857920\n",
       "  3   -3.021 -3.875023\n",
       "  4   -4.376 -4.222240\n",
       "  ..     ...       ...\n",
       "  44  -1.899 -3.201994\n",
       "  45  -2.700 -4.436438\n",
       "  46  -1.640 -3.284105\n",
       "  47  -3.460 -3.741824\n",
       "  48  -1.740 -3.284105\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 97.19773483276367,\n",
       "  'mean_mse': 1.5081308,\n",
       "  'mean_l1': 0.98426825,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-2): 2 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.7045316378275555,\n",
       "   3.03013235727946,\n",
       "   2.355361493428548,\n",
       "   1.979177180926005,\n",
       "   1.493106468518575,\n",
       "   1.413118632634481,\n",
       "   1.2464031100273132,\n",
       "   1.0249300479888916,\n",
       "   0.9634333252906799,\n",
       "   0.8769636829694112,\n",
       "   0.8019458413124084,\n",
       "   0.6947366972764333,\n",
       "   0.6918728053569794,\n",
       "   0.7684538384278615,\n",
       "   0.5973086585601171,\n",
       "   0.6288760006427765,\n",
       "   0.5650225381056467,\n",
       "   0.46345476259787877,\n",
       "   0.4934823592503866,\n",
       "   0.4933450977007548,\n",
       "   0.6135962381958961,\n",
       "   0.44171130657196045,\n",
       "   0.3879989355802536,\n",
       "   0.35502240459124246,\n",
       "   0.3297151257594427,\n",
       "   0.41104146440823874,\n",
       "   0.36986152827739716,\n",
       "   0.3485427180926005,\n",
       "   0.4227592388788859,\n",
       "   0.3294753034909566,\n",
       "   0.25526787638664244,\n",
       "   0.28110849459966025,\n",
       "   0.2799996395905813,\n",
       "   0.30675174792607623],\n",
       "  'val_losses': [7.176547527313232,\n",
       "   4.220077276229858,\n",
       "   3.655253291130066,\n",
       "   2.6804070472717285,\n",
       "   2.76066517829895,\n",
       "   2.2725889682769775,\n",
       "   2.03642874956131,\n",
       "   2.022605061531067,\n",
       "   1.8047699928283691,\n",
       "   2.397676706314087,\n",
       "   1.7796209454536438,\n",
       "   1.87778902053833,\n",
       "   1.6729351878166199,\n",
       "   1.9737261533737183,\n",
       "   1.5316956639289856,\n",
       "   1.883503019809723,\n",
       "   1.9421082735061646,\n",
       "   1.7610036730766296,\n",
       "   1.7289297580718994,\n",
       "   1.8020839095115662,\n",
       "   1.9711970686912537,\n",
       "   1.5603281259536743,\n",
       "   1.5420315265655518,\n",
       "   1.9187456965446472,\n",
       "   1.580431580543518,\n",
       "   1.637789785861969,\n",
       "   1.7359310984611511,\n",
       "   1.5229772329330444,\n",
       "   1.6850435137748718,\n",
       "   1.5609481930732727,\n",
       "   1.6352115273475647,\n",
       "   1.9402745962142944,\n",
       "   1.4603542983531952,\n",
       "   1.7397090196609497]},\n",
       " {'pred_df':     y_real     y_pred\n",
       "  0    1.100   0.812080\n",
       "  1   -3.451  -4.824455\n",
       "  2   -3.043  -3.089464\n",
       "  3   -1.899  -0.767575\n",
       "  4   -7.280  -3.714620\n",
       "  ..     ...        ...\n",
       "  44  -9.018 -10.107874\n",
       "  45  -1.960  -5.627169\n",
       "  46   0.300   0.132280\n",
       "  47  -2.100  -2.564997\n",
       "  48  -4.328  -4.397968\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 102.76406359672546,\n",
       "  'mean_mse': 1.6460321,\n",
       "  'mean_l1': 0.98531115,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-2): 2 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.6520220597585045,\n",
       "   3.5719498793284097,\n",
       "   3.324696739514669,\n",
       "   2.52399906317393,\n",
       "   2.909198757012685,\n",
       "   1.987166198094686,\n",
       "   1.50885808467865,\n",
       "   1.5354398647944132,\n",
       "   1.6905773242314657,\n",
       "   1.1469646414120993,\n",
       "   1.3041603128115336,\n",
       "   1.1799888094266255,\n",
       "   1.2453105290730795,\n",
       "   1.2390637834866842,\n",
       "   0.9603030184904734,\n",
       "   0.9998088240623474,\n",
       "   0.9690784096717835,\n",
       "   1.116135342915853,\n",
       "   1.0911086638768515,\n",
       "   0.8940551479657491,\n",
       "   0.9644350568453471,\n",
       "   0.9052278558413188,\n",
       "   0.7548975537220637,\n",
       "   0.7549684385458628,\n",
       "   0.9928523222605388,\n",
       "   0.6754984974861145,\n",
       "   0.8452449182669322,\n",
       "   0.6941119194030761,\n",
       "   0.5697995007038117,\n",
       "   0.5685347537199656,\n",
       "   0.5893121456106504,\n",
       "   0.6264138917128245,\n",
       "   0.572906744480133,\n",
       "   0.5892227530479431,\n",
       "   0.5067192296187083,\n",
       "   1.0068800648053486,\n",
       "   0.5207064807415008,\n",
       "   0.5448957721392313],\n",
       "  'val_losses': [6.75551176071167,\n",
       "   4.8752686977386475,\n",
       "   4.2360999584198,\n",
       "   4.231202960014343,\n",
       "   3.759517788887024,\n",
       "   3.5927562713623047,\n",
       "   2.2336851358413696,\n",
       "   2.122866988182068,\n",
       "   2.85741651058197,\n",
       "   2.6127755641937256,\n",
       "   1.982850968837738,\n",
       "   2.209516167640686,\n",
       "   2.1414631605148315,\n",
       "   2.158070206642151,\n",
       "   2.5321452617645264,\n",
       "   2.2435145378112793,\n",
       "   1.7789186835289001,\n",
       "   2.0767406821250916,\n",
       "   2.5534379482269287,\n",
       "   1.9392924308776855,\n",
       "   1.7760902643203735,\n",
       "   2.096239686012268,\n",
       "   3.8896193504333496,\n",
       "   2.3283841013908386,\n",
       "   2.2410898208618164,\n",
       "   2.318132519721985,\n",
       "   1.860742211341858,\n",
       "   1.6494081020355225,\n",
       "   1.7979575395584106,\n",
       "   1.6492599844932556,\n",
       "   1.769931674003601,\n",
       "   2.0676573514938354,\n",
       "   1.777339518070221,\n",
       "   1.77069890499115,\n",
       "   1.6681576371192932,\n",
       "   2.0466386675834656,\n",
       "   1.9452877044677734,\n",
       "   2.3575252294540405]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.583 -1.772373\n",
       "  1   -2.676 -2.419788\n",
       "  2   -4.883 -4.998378\n",
       "  3   -8.600 -5.893351\n",
       "  4   -2.982 -2.613671\n",
       "  ..     ...       ...\n",
       "  44  -3.931 -4.917321\n",
       "  45  -4.173 -4.764044\n",
       "  46  -2.932 -0.770951\n",
       "  47  -3.610 -2.956081\n",
       "  48  -2.349 -2.449850\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 44.916502237319946,\n",
       "  'mean_mse': 1.7859038,\n",
       "  'mean_l1': 1.0385665,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-2): 2 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.751419274012248,\n",
       "   3.1128661314646404,\n",
       "   2.432578372955322,\n",
       "   2.2019104321797687,\n",
       "   1.5924269795417785,\n",
       "   1.6496015787124634,\n",
       "   1.8257479508717855,\n",
       "   1.010723320643107,\n",
       "   0.964346436659495,\n",
       "   0.9673733393351237,\n",
       "   0.7899240990479787,\n",
       "   0.8145838002363841,\n",
       "   0.7826721211274464,\n",
       "   0.8019792159398397,\n",
       "   0.6568769951661427],\n",
       "  'val_losses': [6.97704553604126,\n",
       "   3.948278546333313,\n",
       "   3.9192699193954468,\n",
       "   3.3449918031692505,\n",
       "   3.041225552558899,\n",
       "   2.6757237911224365,\n",
       "   2.0418678522109985,\n",
       "   2.050169050693512,\n",
       "   2.440160870552063,\n",
       "   2.0547935962677,\n",
       "   2.0657597184181213,\n",
       "   2.02108371257782,\n",
       "   1.9767470955848694,\n",
       "   1.994688093662262,\n",
       "   2.052045166492462]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.930 -1.781821\n",
       "  1   -6.237 -3.539665\n",
       "  2   -3.931 -6.146007\n",
       "  3   -3.120 -3.069247\n",
       "  4   -4.950 -3.332542\n",
       "  ..     ...       ...\n",
       "  44  -4.800 -5.676016\n",
       "  45  -4.450 -1.977496\n",
       "  46  -7.800 -7.836295\n",
       "  47  -0.400 -0.675439\n",
       "  48  -3.360 -4.027593\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 94.2073814868927,\n",
       "  'mean_mse': 1.5066953,\n",
       "  'mean_l1': 0.91977084,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-3): 3 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.2642953554789225,\n",
       "   2.8264591217041017,\n",
       "   2.383949788411458,\n",
       "   1.875076715151469,\n",
       "   1.4695222099622092,\n",
       "   1.2256215373675028,\n",
       "   1.2067711750666301,\n",
       "   1.0695797244707743,\n",
       "   0.8999961276849111,\n",
       "   0.775078022480011,\n",
       "   0.775729755560557,\n",
       "   0.6531143665313721,\n",
       "   0.6055829008420308,\n",
       "   0.6083834777275722,\n",
       "   0.49478425482908883,\n",
       "   0.5792015552520752,\n",
       "   0.4526822785536448,\n",
       "   0.4932593663533529,\n",
       "   0.378807133436203,\n",
       "   0.42707897325356803,\n",
       "   0.38051607757806777,\n",
       "   0.38554263512293496,\n",
       "   0.4029792626698812,\n",
       "   0.37438125908374786,\n",
       "   0.30255575974782306,\n",
       "   0.32624385356903074,\n",
       "   0.2773491973678271,\n",
       "   0.26830593347549436,\n",
       "   0.32381005187829337],\n",
       "  'val_losses': [7.492938041687012,\n",
       "   4.332202911376953,\n",
       "   4.105209231376648,\n",
       "   2.733691930770874,\n",
       "   2.0701431035995483,\n",
       "   2.6251786947250366,\n",
       "   1.801390290260315,\n",
       "   2.6817548274993896,\n",
       "   2.074555456638336,\n",
       "   2.1326920986175537,\n",
       "   2.2398940324783325,\n",
       "   1.93784499168396,\n",
       "   2.856094241142273,\n",
       "   1.818627417087555,\n",
       "   2.0917604565620422,\n",
       "   1.9350991249084473,\n",
       "   1.8312330842018127,\n",
       "   2.0920000672340393,\n",
       "   1.6048668026924133,\n",
       "   1.7674826979637146,\n",
       "   1.6387524008750916,\n",
       "   1.6070911288261414,\n",
       "   1.6151509881019592,\n",
       "   1.5928594470024109,\n",
       "   1.6110210418701172,\n",
       "   2.0260629653930664,\n",
       "   1.8176634311676025,\n",
       "   1.6140124201774597,\n",
       "   1.6192885637283325]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.990 -1.078293\n",
       "  1   -0.400 -1.312693\n",
       "  2   -5.350 -4.948602\n",
       "  3   -4.632 -3.095109\n",
       "  4   -5.000 -5.783221\n",
       "  ..     ...       ...\n",
       "  44  -8.040 -6.967280\n",
       "  45   1.100  0.474161\n",
       "  46  -4.310 -4.806045\n",
       "  47  -3.120 -3.734675\n",
       "  48  -4.376 -4.209441\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 66.85359525680542,\n",
       "  'mean_mse': 1.8014189,\n",
       "  'mean_l1': 1.0234687,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-3): 3 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.56910506884257,\n",
       "   3.628223355611165,\n",
       "   3.0145952145258588,\n",
       "   2.330331039428711,\n",
       "   1.9122302611668904,\n",
       "   1.534216837088267,\n",
       "   1.305601183573405,\n",
       "   1.153628146648407,\n",
       "   1.7173972527186077,\n",
       "   1.605151395003001,\n",
       "   1.0867914795875548,\n",
       "   0.7611921350161235,\n",
       "   0.8225385457277298,\n",
       "   0.7069302956263225,\n",
       "   0.6941907902558645,\n",
       "   0.7872749288876851,\n",
       "   1.258308760325114,\n",
       "   0.7920795063177745,\n",
       "   0.5976115643978119,\n",
       "   0.6656449735164642,\n",
       "   0.4927264392375946,\n",
       "   0.496597683429718],\n",
       "  'val_losses': [7.288322925567627,\n",
       "   4.303669810295105,\n",
       "   4.176190733909607,\n",
       "   3.235617995262146,\n",
       "   2.234539270401001,\n",
       "   2.183021664619446,\n",
       "   2.3644529581069946,\n",
       "   2.791274905204773,\n",
       "   2.4333640336990356,\n",
       "   1.8603559136390686,\n",
       "   2.5427732467651367,\n",
       "   2.0223933458328247,\n",
       "   1.8464752435684204,\n",
       "   1.8874984979629517,\n",
       "   2.601864218711853,\n",
       "   1.6181879043579102,\n",
       "   2.3066372871398926,\n",
       "   1.834376037120819,\n",
       "   1.8282458782196045,\n",
       "   1.7144312262535095,\n",
       "   1.7416044473648071,\n",
       "   1.6764919757843018]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    -1.85 -3.332029\n",
       "  1    -3.88 -3.901919\n",
       "  2    -5.19 -5.082088\n",
       "  3    -4.37 -3.952275\n",
       "  4    -2.06 -1.784104\n",
       "  ..     ...       ...\n",
       "  44   -4.95 -3.496500\n",
       "  45   -3.18 -2.880833\n",
       "  46    0.30 -0.348943\n",
       "  47   -5.22 -6.602386\n",
       "  48   -3.22 -2.255187\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 212.09859991073608,\n",
       "  'mean_mse': 1.3197293,\n",
       "  'mean_l1': 0.8923608,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-3): 3 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.40707086722056,\n",
       "   3.326164404551188,\n",
       "   2.340194320678711,\n",
       "   1.7991244316101074,\n",
       "   1.5003517230351766,\n",
       "   1.1687050422032674,\n",
       "   0.9984107096989949,\n",
       "   1.1765019237995147,\n",
       "   0.7919161558151245,\n",
       "   0.7305655280749003,\n",
       "   1.0060176114241282,\n",
       "   0.8999932289123536,\n",
       "   1.0060256401697794,\n",
       "   0.6408857007821401,\n",
       "   0.633344954252243,\n",
       "   0.5861111640930176,\n",
       "   0.8440997819105784,\n",
       "   0.6028896669546763,\n",
       "   0.4865673025449117,\n",
       "   0.5197426517804463,\n",
       "   0.5062677164872488,\n",
       "   0.5405976831912994,\n",
       "   0.5259839137395222,\n",
       "   0.4135873754819234,\n",
       "   0.4298195719718933,\n",
       "   0.42415613532066343,\n",
       "   0.4618735541899999,\n",
       "   0.37723320027192436,\n",
       "   0.35747841000556946,\n",
       "   0.3596875101327896,\n",
       "   0.36021994849046074,\n",
       "   0.3729184736808141,\n",
       "   0.33149610658486683,\n",
       "   0.32104003926118213,\n",
       "   0.2780836602052053,\n",
       "   0.3604451676209768,\n",
       "   0.28503383298714957,\n",
       "   0.4905478209257126,\n",
       "   0.31424971123536427,\n",
       "   0.25755856136480965,\n",
       "   0.23423503239949545,\n",
       "   0.2497476816177368,\n",
       "   0.2912519117196401,\n",
       "   0.24120244532823562,\n",
       "   0.3344223628441493,\n",
       "   0.5185030490159989,\n",
       "   0.2881709376970927,\n",
       "   0.30248271524906156,\n",
       "   0.30200467109680174,\n",
       "   0.1962864781419436,\n",
       "   0.23504005273183187,\n",
       "   0.3343184620141983,\n",
       "   0.20240098933378856,\n",
       "   0.19206751187642415,\n",
       "   0.2563225746154785,\n",
       "   0.29269451200962066,\n",
       "   0.19273820022741953,\n",
       "   0.3666681716839472,\n",
       "   0.19620868513981501,\n",
       "   0.22853215535481772,\n",
       "   0.278361443678538,\n",
       "   0.24917440116405487,\n",
       "   0.20993353525797526,\n",
       "   0.17153088599443436,\n",
       "   0.19004860272010168,\n",
       "   0.2076379542549451,\n",
       "   0.18860981216033298,\n",
       "   0.13954023818175,\n",
       "   0.23445352067550024],\n",
       "  'val_losses': [6.466450452804565,\n",
       "   4.222179174423218,\n",
       "   4.453060865402222,\n",
       "   2.4052928686141968,\n",
       "   3.177433133125305,\n",
       "   2.306129217147827,\n",
       "   2.293615996837616,\n",
       "   1.8121432662010193,\n",
       "   3.481683135032654,\n",
       "   1.8752644062042236,\n",
       "   1.8766987323760986,\n",
       "   1.9192352294921875,\n",
       "   1.7948001623153687,\n",
       "   1.9243338108062744,\n",
       "   1.8655750155448914,\n",
       "   1.6981155276298523,\n",
       "   2.0819919109344482,\n",
       "   1.6891852617263794,\n",
       "   2.0735905170440674,\n",
       "   1.9611162543296814,\n",
       "   1.6907581090927124,\n",
       "   1.8804249167442322,\n",
       "   1.5285276174545288,\n",
       "   1.5818603038787842,\n",
       "   1.6867707967758179,\n",
       "   1.5709826946258545,\n",
       "   1.6019265055656433,\n",
       "   2.0093138813972473,\n",
       "   1.572260320186615,\n",
       "   1.4000752568244934,\n",
       "   1.4912884831428528,\n",
       "   1.5010914206504822,\n",
       "   1.6770622730255127,\n",
       "   1.8568954467773438,\n",
       "   1.4103730916976929,\n",
       "   1.6305597424507141,\n",
       "   1.4445074796676636,\n",
       "   1.3939624428749084,\n",
       "   1.3766398429870605,\n",
       "   1.6335480213165283,\n",
       "   1.4300674200057983,\n",
       "   1.2674827575683594,\n",
       "   1.2977505922317505,\n",
       "   1.2849730849266052,\n",
       "   1.2465224862098694,\n",
       "   1.2276113629341125,\n",
       "   1.3727688789367676,\n",
       "   1.3783285021781921,\n",
       "   1.3229211568832397,\n",
       "   1.3297441601753235,\n",
       "   1.3136790990829468,\n",
       "   1.6569421291351318,\n",
       "   1.2934747338294983,\n",
       "   1.5751241445541382,\n",
       "   1.2481449842453003,\n",
       "   1.7629235982894897,\n",
       "   1.3091007471084595,\n",
       "   1.3501588702201843,\n",
       "   1.3545446991920471,\n",
       "   1.327302873134613,\n",
       "   1.2211466431617737,\n",
       "   1.4908074140548706,\n",
       "   1.3280434608459473,\n",
       "   1.1473471820354462,\n",
       "   1.5004170536994934,\n",
       "   1.3055983185768127,\n",
       "   1.3909143209457397,\n",
       "   1.3107666373252869,\n",
       "   1.3683201670646667]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.850 -4.676797\n",
       "  1   -3.620 -2.201074\n",
       "  2   -0.742 -1.837446\n",
       "  3   -1.990 -3.044973\n",
       "  4   -3.800 -4.647288\n",
       "  ..     ...       ...\n",
       "  44  -0.600 -1.374628\n",
       "  45  -3.094 -3.459895\n",
       "  46  -2.070 -3.967973\n",
       "  47  -4.380 -4.582853\n",
       "  48  -6.680 -7.212047\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 86.5464231967926,\n",
       "  'mean_mse': 1.7269427,\n",
       "  'mean_l1': 1.0320463,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-2): 2 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.353042395909627,\n",
       "   3.723142210642497,\n",
       "   3.3823254903157554,\n",
       "   2.7994486490885415,\n",
       "   2.2550918181737263,\n",
       "   2.4497951666514077,\n",
       "   1.7633214155832926,\n",
       "   1.6128611326217652,\n",
       "   1.4963276704152426,\n",
       "   1.7033564408620199,\n",
       "   1.3775328397750854,\n",
       "   1.2292208790779113,\n",
       "   1.1958197037378946,\n",
       "   1.3929201046625772,\n",
       "   1.1429921984672546,\n",
       "   0.9678916176160176,\n",
       "   0.9716665069262187,\n",
       "   1.0329679290453593,\n",
       "   0.8351223607858022,\n",
       "   0.8925190548102061,\n",
       "   0.8917552789052328,\n",
       "   0.824797777334849,\n",
       "   0.8070940295855205,\n",
       "   0.7569645524024964,\n",
       "   0.7887673914432526,\n",
       "   0.7147916277249654,\n",
       "   0.7968287984530131,\n",
       "   0.7264912287394206,\n",
       "   0.6776065111160279,\n",
       "   0.7052091717720032,\n",
       "   0.6249284863471984,\n",
       "   0.6273440798123677,\n",
       "   0.6079844991366069,\n",
       "   0.6927105287710825,\n",
       "   0.6428845226764679],\n",
       "  'val_losses': [5.341078758239746,\n",
       "   4.444480895996094,\n",
       "   4.152070999145508,\n",
       "   3.7806293964385986,\n",
       "   3.758775234222412,\n",
       "   3.1971601247787476,\n",
       "   3.0713526010513306,\n",
       "   3.0864930152893066,\n",
       "   2.6783560514450073,\n",
       "   2.37494033575058,\n",
       "   2.704307198524475,\n",
       "   2.037241280078888,\n",
       "   1.959632396697998,\n",
       "   2.0441941022872925,\n",
       "   2.264379620552063,\n",
       "   2.118360161781311,\n",
       "   1.8722230195999146,\n",
       "   1.7007485032081604,\n",
       "   1.7573012113571167,\n",
       "   2.6659477949142456,\n",
       "   2.1023552417755127,\n",
       "   2.180076837539673,\n",
       "   2.0006536841392517,\n",
       "   1.9477099180221558,\n",
       "   2.090415596961975,\n",
       "   1.7686470746994019,\n",
       "   1.981950044631958,\n",
       "   1.7256784439086914,\n",
       "   1.6896644234657288,\n",
       "   1.6904293298721313,\n",
       "   1.7595267295837402,\n",
       "   1.6793152689933777,\n",
       "   1.7028295397758484,\n",
       "   1.6114453077316284,\n",
       "   1.6834620833396912]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.171 -4.775625\n",
       "  1   -5.696 -4.404055\n",
       "  2   -4.743 -4.066800\n",
       "  3   -5.350 -5.210062\n",
       "  4   -1.850 -4.242517\n",
       "  ..     ...       ...\n",
       "  44  -1.740 -4.226952\n",
       "  45  -5.410 -4.405966\n",
       "  46  -5.915 -4.748731\n",
       "  47  -4.632 -3.113589\n",
       "  48  -3.120 -2.411524\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 154.3371205329895,\n",
       "  'mean_mse': 1.5143825,\n",
       "  'mean_l1': 0.9769274,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.78141222000122,\n",
       "   3.947382164001465,\n",
       "   3.2586157162984213,\n",
       "   3.027138908704122,\n",
       "   3.104379916191101,\n",
       "   2.6838523546854653,\n",
       "   2.458636514345805,\n",
       "   2.3696961402893066,\n",
       "   2.1455208102862042,\n",
       "   2.1141607840855916,\n",
       "   2.0310468395551045,\n",
       "   2.136605413754781,\n",
       "   1.9366800626118978,\n",
       "   1.8448521892229717,\n",
       "   1.7321442802747091,\n",
       "   1.6725133419036866,\n",
       "   1.851586929957072,\n",
       "   1.638120174407959,\n",
       "   1.6200696070988974,\n",
       "   1.6327510197957358,\n",
       "   1.5058824300765992,\n",
       "   1.409020225207011,\n",
       "   1.4084062933921815,\n",
       "   1.3466606378555297,\n",
       "   1.355268406867981,\n",
       "   1.3995265086491904,\n",
       "   1.3145152807235718,\n",
       "   1.3309612274169922,\n",
       "   1.210201581319173,\n",
       "   1.1866767724355063,\n",
       "   1.2556374788284301,\n",
       "   1.1635055383046469,\n",
       "   1.1953783551851909,\n",
       "   1.173200915257136,\n",
       "   1.1758343935012818,\n",
       "   1.1580337504545848,\n",
       "   1.1623635490735371,\n",
       "   1.0583876808484396,\n",
       "   1.0504556814829509,\n",
       "   1.091907000541687,\n",
       "   1.0498607476552329,\n",
       "   1.0314139435688654,\n",
       "   1.0116921146710713,\n",
       "   1.0478591283162435,\n",
       "   0.9344545821348826,\n",
       "   0.9893434445063273,\n",
       "   0.9794944763183594,\n",
       "   0.9988781611124674,\n",
       "   1.0613121469815572,\n",
       "   1.0922998706499736,\n",
       "   0.8815768480300903,\n",
       "   0.877604079246521,\n",
       "   0.9223553101221721,\n",
       "   0.926701299349467,\n",
       "   0.8857365767161052,\n",
       "   0.8584308664004008,\n",
       "   0.8758772214253744,\n",
       "   0.7977355321248373,\n",
       "   0.8239835063616435,\n",
       "   0.777287037173907,\n",
       "   0.9351033687591552,\n",
       "   1.009716562430064,\n",
       "   0.7814968228340149,\n",
       "   0.7690121968587239,\n",
       "   0.8404250264167785,\n",
       "   0.8264698266983033,\n",
       "   0.840442951520284],\n",
       "  'val_losses': [4.578457951545715,\n",
       "   4.586205720901489,\n",
       "   4.342673301696777,\n",
       "   4.374501466751099,\n",
       "   4.072246074676514,\n",
       "   4.2855541706085205,\n",
       "   4.335641860961914,\n",
       "   3.888889193534851,\n",
       "   4.203026533126831,\n",
       "   3.843336820602417,\n",
       "   4.134811758995056,\n",
       "   3.6156160831451416,\n",
       "   3.7888338565826416,\n",
       "   3.7300877571105957,\n",
       "   3.4330174922943115,\n",
       "   3.1975477933883667,\n",
       "   3.260403037071228,\n",
       "   2.956175208091736,\n",
       "   2.786512017250061,\n",
       "   3.1538480520248413,\n",
       "   2.753044843673706,\n",
       "   2.5925440788269043,\n",
       "   2.756929874420166,\n",
       "   2.5731091499328613,\n",
       "   2.753626227378845,\n",
       "   2.5016099214553833,\n",
       "   2.665733575820923,\n",
       "   2.823458671569824,\n",
       "   2.364748001098633,\n",
       "   2.3871384263038635,\n",
       "   2.3310742378234863,\n",
       "   2.306632876396179,\n",
       "   2.425312042236328,\n",
       "   2.269805669784546,\n",
       "   2.2100592851638794,\n",
       "   2.2915916442871094,\n",
       "   2.249808192253113,\n",
       "   2.305001378059387,\n",
       "   2.6102540493011475,\n",
       "   2.0660916566848755,\n",
       "   2.133913040161133,\n",
       "   2.205876588821411,\n",
       "   2.659510612487793,\n",
       "   2.283031940460205,\n",
       "   2.2404712438583374,\n",
       "   2.1847116947174072,\n",
       "   2.2146838903427124,\n",
       "   1.9933799505233765,\n",
       "   2.019553005695343,\n",
       "   2.112749218940735,\n",
       "   2.0771195888519287,\n",
       "   2.254979133605957,\n",
       "   2.064223289489746,\n",
       "   1.9221389293670654,\n",
       "   1.961732804775238,\n",
       "   2.113776445388794,\n",
       "   2.118955910205841,\n",
       "   1.9560971856117249,\n",
       "   1.948998510837555,\n",
       "   1.9405910968780518,\n",
       "   2.094752550125122,\n",
       "   1.859138309955597,\n",
       "   1.94846773147583,\n",
       "   2.386790633201599,\n",
       "   1.9684572219848633,\n",
       "   2.0561658143997192,\n",
       "   2.008996307849884]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.180 -1.876924\n",
       "  1   -1.990 -3.869838\n",
       "  2   -3.021 -3.896166\n",
       "  3   -0.400 -0.477791\n",
       "  4   -3.460 -3.236017\n",
       "  ..     ...       ...\n",
       "  44  -2.920 -2.766838\n",
       "  45  -2.943 -2.452864\n",
       "  46  -4.120 -5.113078\n",
       "  47  -3.690 -5.214286\n",
       "  48  -4.402 -5.397460\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 134.68536686897278,\n",
       "  'mean_mse': 1.822558,\n",
       "  'mean_l1': 1.006681,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [9.723157087961832,\n",
       "   3.972316106160482,\n",
       "   3.788187599182129,\n",
       "   3.4945667664210003,\n",
       "   3.414084959030151,\n",
       "   3.398271338144938,\n",
       "   3.041261593500773,\n",
       "   3.126904344558716,\n",
       "   2.9760283629099527,\n",
       "   2.6777212142944338,\n",
       "   2.6944719314575196,\n",
       "   2.6273591995239256,\n",
       "   2.762025896708171,\n",
       "   2.6382034540176393,\n",
       "   2.505572787920634,\n",
       "   2.348677142461141,\n",
       "   2.3627551952997843,\n",
       "   2.2676958878835043,\n",
       "   2.2413667996724445,\n",
       "   2.390355650583903,\n",
       "   2.3402374903361003,\n",
       "   2.176206525166829,\n",
       "   2.1373414675394695,\n",
       "   2.0982056140899656,\n",
       "   2.197952381769816,\n",
       "   2.0523524284362793,\n",
       "   1.8992629726727803,\n",
       "   1.9347572167714437,\n",
       "   1.8965522686640421,\n",
       "   1.8214510281880696,\n",
       "   1.8319238424301147,\n",
       "   1.777623430887858,\n",
       "   1.793222157160441,\n",
       "   1.8026230732599895,\n",
       "   1.774580438931783,\n",
       "   1.6522242267926535,\n",
       "   1.7381709734598796,\n",
       "   1.5915170828501384,\n",
       "   1.7324149052302042,\n",
       "   1.6327120304107665,\n",
       "   1.586406413714091,\n",
       "   1.625571576754252,\n",
       "   1.5290483633677165,\n",
       "   1.615532604853312,\n",
       "   1.5097016533215841,\n",
       "   1.5329003810882569,\n",
       "   1.4547541916370392,\n",
       "   1.4672762155532837,\n",
       "   1.651518750190735,\n",
       "   1.5898350358009339,\n",
       "   1.5132201353708903,\n",
       "   1.821503178278605,\n",
       "   1.5247906923294068,\n",
       "   1.4971656640370687,\n",
       "   1.360165786743164,\n",
       "   1.5961538871129355,\n",
       "   1.441890796025594,\n",
       "   1.3818645119667052,\n",
       "   1.3260329564412434,\n",
       "   1.3491742610931396,\n",
       "   1.2566549976666768,\n",
       "   1.3324375788370768,\n",
       "   1.3511059045791627],\n",
       "  'val_losses': [8.128775119781494,\n",
       "   4.7398459911346436,\n",
       "   4.809263706207275,\n",
       "   4.359564542770386,\n",
       "   4.552781820297241,\n",
       "   4.481091022491455,\n",
       "   4.415712356567383,\n",
       "   4.36147141456604,\n",
       "   3.9632097482681274,\n",
       "   4.333012342453003,\n",
       "   3.8181684017181396,\n",
       "   4.014787673950195,\n",
       "   4.261893391609192,\n",
       "   3.7168025970458984,\n",
       "   3.7523542642593384,\n",
       "   3.744349718093872,\n",
       "   3.5429701805114746,\n",
       "   3.4925376176834106,\n",
       "   3.2811721563339233,\n",
       "   3.2375799417495728,\n",
       "   3.3147530555725098,\n",
       "   3.312925100326538,\n",
       "   3.0896658897399902,\n",
       "   3.076861262321472,\n",
       "   3.136021375656128,\n",
       "   3.151864171028137,\n",
       "   2.851952075958252,\n",
       "   2.775861144065857,\n",
       "   3.1852043867111206,\n",
       "   2.8282463550567627,\n",
       "   2.7028216123580933,\n",
       "   2.646512508392334,\n",
       "   2.5283782482147217,\n",
       "   2.472824811935425,\n",
       "   2.469496965408325,\n",
       "   2.3458070158958435,\n",
       "   2.908996820449829,\n",
       "   2.363535523414612,\n",
       "   2.3160675168037415,\n",
       "   2.579076051712036,\n",
       "   2.3926076889038086,\n",
       "   2.6000611782073975,\n",
       "   2.294936239719391,\n",
       "   2.255107045173645,\n",
       "   2.254607141017914,\n",
       "   2.224293828010559,\n",
       "   2.0991581678390503,\n",
       "   2.1654419898986816,\n",
       "   2.1075470447540283,\n",
       "   2.288080930709839,\n",
       "   2.1083595752716064,\n",
       "   2.111170530319214,\n",
       "   2.029752731323242,\n",
       "   1.9861725568771362,\n",
       "   2.197936534881592,\n",
       "   1.9659138917922974,\n",
       "   2.0559813380241394,\n",
       "   1.8921509981155396,\n",
       "   1.9022729396820068,\n",
       "   1.9088236689567566,\n",
       "   1.8152714371681213,\n",
       "   1.8874749541282654,\n",
       "   1.860451340675354]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.634 -5.142281\n",
       "  1   -2.676 -4.289343\n",
       "  2   -1.250 -0.248242\n",
       "  3   -4.805 -2.049648\n",
       "  4   -2.350 -2.533318\n",
       "  ..     ...       ...\n",
       "  44  -5.220 -4.637780\n",
       "  45  -3.360 -4.444846\n",
       "  46  -3.451 -5.005308\n",
       "  47  -8.600 -4.249710\n",
       "  48  -3.610 -3.548602\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 111.1754400730133,\n",
       "  'mean_mse': 2.3401985,\n",
       "  'mean_l1': 1.2164152,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.976139132181803,\n",
       "   3.6558825333913165,\n",
       "   3.4741816679636637,\n",
       "   3.1496331771214803,\n",
       "   3.2070292154947917,\n",
       "   2.967969870567322,\n",
       "   2.975836928685506,\n",
       "   2.9493549903233847,\n",
       "   2.5528523047765095,\n",
       "   2.4478584051132204,\n",
       "   2.3650713602701825,\n",
       "   2.2947258631388348,\n",
       "   2.319528881708781,\n",
       "   2.2399781346321106,\n",
       "   2.0631715168555576,\n",
       "   2.1078133821487426,\n",
       "   2.0393380641937258,\n",
       "   2.028585704167684,\n",
       "   2.023983124891917,\n",
       "   2.277285623550415,\n",
       "   1.8685922384262086,\n",
       "   1.8117717663447062,\n",
       "   1.7507020264863968,\n",
       "   1.9011095762252808,\n",
       "   1.7761082331339517,\n",
       "   1.7247474352518717,\n",
       "   1.7176404237747191,\n",
       "   1.8469853083292642,\n",
       "   1.9135029792785645,\n",
       "   1.6340128262837728,\n",
       "   1.8603137652079265,\n",
       "   1.6126042127609252,\n",
       "   1.6320900559425353,\n",
       "   1.5593448599179587,\n",
       "   1.5878915588061016,\n",
       "   1.5483518441518147,\n",
       "   1.6267190456390381,\n",
       "   1.492891326546669,\n",
       "   1.6372495571772256,\n",
       "   1.4634022871653238,\n",
       "   1.5660221338272096,\n",
       "   1.4575994849205016,\n",
       "   1.4987467924753826,\n",
       "   1.4513673941294352,\n",
       "   1.4702264308929442,\n",
       "   1.4516944567362466,\n",
       "   1.4757100502649942,\n",
       "   1.5446012179056803,\n",
       "   1.4915186007817587,\n",
       "   1.4158921321233113,\n",
       "   1.479189399878184,\n",
       "   1.4196668903032938,\n",
       "   1.363601549466451,\n",
       "   1.4351313591003418],\n",
       "  'val_losses': [5.149785757064819,\n",
       "   4.7731406688690186,\n",
       "   4.3693578243255615,\n",
       "   4.275295734405518,\n",
       "   4.337310791015625,\n",
       "   4.188045501708984,\n",
       "   4.319306254386902,\n",
       "   4.091863989830017,\n",
       "   4.114433526992798,\n",
       "   4.0932124853134155,\n",
       "   4.116500735282898,\n",
       "   3.8769118785858154,\n",
       "   3.755706548690796,\n",
       "   3.6506422758102417,\n",
       "   3.730109453201294,\n",
       "   3.8657013177871704,\n",
       "   3.5228092670440674,\n",
       "   3.4114677906036377,\n",
       "   3.299758553504944,\n",
       "   3.1538079977035522,\n",
       "   3.1061094999313354,\n",
       "   3.0595868825912476,\n",
       "   3.314086675643921,\n",
       "   3.100292444229126,\n",
       "   3.006862759590149,\n",
       "   2.901922106742859,\n",
       "   2.8606698513031006,\n",
       "   3.1112990379333496,\n",
       "   2.731208324432373,\n",
       "   2.8020782470703125,\n",
       "   3.018336057662964,\n",
       "   2.758845329284668,\n",
       "   2.7027151584625244,\n",
       "   2.774930238723755,\n",
       "   2.927550792694092,\n",
       "   2.6276293992996216,\n",
       "   2.607168436050415,\n",
       "   3.019209146499634,\n",
       "   2.7571520805358887,\n",
       "   2.6266770362854004,\n",
       "   2.9385697841644287,\n",
       "   2.709452271461487,\n",
       "   2.5236076712608337,\n",
       "   2.678193211555481,\n",
       "   2.659858226776123,\n",
       "   2.570083498954773,\n",
       "   2.649032950401306,\n",
       "   2.659735918045044,\n",
       "   2.5928338766098022,\n",
       "   2.613495111465454,\n",
       "   2.521508812904358,\n",
       "   2.54390287399292,\n",
       "   3.0634531378746033,\n",
       "   2.668123483657837]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.360 -4.541660\n",
       "  1   -3.451 -4.585077\n",
       "  2   -3.246 -4.630690\n",
       "  3   -4.445 -5.096489\n",
       "  4   -2.160 -1.940367\n",
       "  ..     ...       ...\n",
       "  44  -1.640 -4.706675\n",
       "  45  -7.800 -7.874587\n",
       "  46  -8.040 -6.497537\n",
       "  47  -4.632 -3.011063\n",
       "  48  -3.120 -2.552452\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 66.83803844451904,\n",
       "  'mean_mse': 1.651778,\n",
       "  'mean_l1': 1.0066594,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1): GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.754922819137573,\n",
       "   3.448891011873881,\n",
       "   3.1635785420735676,\n",
       "   2.339509359995524,\n",
       "   2.0343477725982666,\n",
       "   1.97093292872111,\n",
       "   1.6179592291514078,\n",
       "   1.4879606008529662,\n",
       "   1.4218174457550048,\n",
       "   1.3185269395510355,\n",
       "   1.2383618116378785,\n",
       "   1.335339399178823,\n",
       "   1.0414857427279154,\n",
       "   1.1614855488141378,\n",
       "   0.8959870398044586,\n",
       "   1.0816720684369405,\n",
       "   0.9333336671193441,\n",
       "   0.7974230051040649,\n",
       "   0.7999957501888275,\n",
       "   0.8291784067948659,\n",
       "   0.8665677905082703,\n",
       "   0.7754931569099426,\n",
       "   0.7627224544684092,\n",
       "   0.7267019907633464,\n",
       "   0.612966650724411,\n",
       "   0.6058200736840565,\n",
       "   0.6386146545410156],\n",
       "  'val_losses': [4.967777967453003,\n",
       "   4.339522361755371,\n",
       "   4.848111867904663,\n",
       "   3.956032872200012,\n",
       "   3.5049980878829956,\n",
       "   2.9370510578155518,\n",
       "   2.7166091203689575,\n",
       "   2.609068751335144,\n",
       "   2.4135221242904663,\n",
       "   2.594233274459839,\n",
       "   2.191667675971985,\n",
       "   2.117099404335022,\n",
       "   1.9561786651611328,\n",
       "   2.5245108604431152,\n",
       "   1.8452730774879456,\n",
       "   1.890494704246521,\n",
       "   1.853551983833313,\n",
       "   1.8531871438026428,\n",
       "   1.9260281920433044,\n",
       "   1.846798300743103,\n",
       "   2.184593915939331,\n",
       "   1.5684674680233002,\n",
       "   1.832694411277771,\n",
       "   2.051918089389801,\n",
       "   1.5938907265663147,\n",
       "   1.7629018425941467,\n",
       "   1.8852385878562927]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.290 -4.319493\n",
       "  1   -3.401 -1.254318\n",
       "  2   -2.932 -1.191105\n",
       "  3   -4.950 -4.235526\n",
       "  4   -4.380 -4.723194\n",
       "  ..     ...       ...\n",
       "  44  -4.799 -4.208801\n",
       "  45  -2.266 -0.899722\n",
       "  46  -4.800 -6.557124\n",
       "  47  -4.632 -2.872554\n",
       "  48  -6.680 -7.235574\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 106.41787147521973,\n",
       "  'mean_mse': 1.856957,\n",
       "  'mean_l1': 1.0778279,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1): GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.546227677663167,\n",
       "   4.093090995152791,\n",
       "   3.2479660987854,\n",
       "   2.993641455968221,\n",
       "   2.726315212249756,\n",
       "   2.302233338356018,\n",
       "   2.1727069139480593,\n",
       "   1.9967038790384928,\n",
       "   2.011329968770345,\n",
       "   1.768958576520284,\n",
       "   1.6078675111134848,\n",
       "   1.4939406077067057,\n",
       "   1.4216073671976726,\n",
       "   1.3224531014760335,\n",
       "   1.2756139914194742,\n",
       "   1.481288739045461,\n",
       "   1.0978594978650411,\n",
       "   1.204451362291972,\n",
       "   1.0716915329297383,\n",
       "   1.1165599346160888,\n",
       "   1.1073806484540303,\n",
       "   1.0738663911819457,\n",
       "   1.0317591389020284,\n",
       "   0.9990814884503683,\n",
       "   1.0811328013737997,\n",
       "   0.9675758997599284,\n",
       "   0.9405581692854563,\n",
       "   1.0423674583435059,\n",
       "   1.0268611987431844,\n",
       "   0.9916384140650432,\n",
       "   0.9365155200163523,\n",
       "   0.9514853398005167,\n",
       "   0.9062705596288045,\n",
       "   0.8733923554420471,\n",
       "   0.9082447290420532,\n",
       "   0.8579875747362773,\n",
       "   0.8621262451012929,\n",
       "   0.8442028403282166,\n",
       "   0.9410718639691671,\n",
       "   0.9661393602689107,\n",
       "   0.9445151130358378,\n",
       "   0.8224117120107015,\n",
       "   0.8320190747578938,\n",
       "   0.7851339817047119],\n",
       "  'val_losses': [5.267224073410034,\n",
       "   4.56651771068573,\n",
       "   4.078495264053345,\n",
       "   4.1467366218566895,\n",
       "   4.155186772346497,\n",
       "   3.288289189338684,\n",
       "   3.176786422729492,\n",
       "   2.8969026803970337,\n",
       "   2.5996205806732178,\n",
       "   2.375336766242981,\n",
       "   2.404819965362549,\n",
       "   2.0243369340896606,\n",
       "   2.3189330101013184,\n",
       "   1.9253153204917908,\n",
       "   2.3686472177505493,\n",
       "   1.955665111541748,\n",
       "   1.8180273175239563,\n",
       "   2.211801052093506,\n",
       "   1.872513234615326,\n",
       "   1.9174373149871826,\n",
       "   2.370024561882019,\n",
       "   1.861856460571289,\n",
       "   2.156222701072693,\n",
       "   1.8393905758857727,\n",
       "   2.169260025024414,\n",
       "   1.859139084815979,\n",
       "   1.7965428233146667,\n",
       "   1.8820977210998535,\n",
       "   1.6869759559631348,\n",
       "   2.3808434009552,\n",
       "   1.937132477760315,\n",
       "   1.714646339416504,\n",
       "   1.8142211437225342,\n",
       "   1.837402582168579,\n",
       "   1.7642988562583923,\n",
       "   1.7497347593307495,\n",
       "   1.7373696565628052,\n",
       "   1.839460015296936,\n",
       "   1.7838212847709656,\n",
       "   1.8792792558670044,\n",
       "   1.6998389959335327,\n",
       "   1.644055962562561,\n",
       "   1.6767640113830566,\n",
       "   1.92571359872818]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.120 -2.376304\n",
       "  1   -2.060 -1.331519\n",
       "  2   -3.583 -2.277596\n",
       "  3   -4.173 -4.466213\n",
       "  4   -0.742 -1.263129\n",
       "  ..     ...       ...\n",
       "  44  -6.726 -6.249578\n",
       "  45  -6.800 -6.988983\n",
       "  46  -1.899 -2.245976\n",
       "  47  -3.451 -4.656619\n",
       "  48  -2.982 -2.701785\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 60.79675030708313,\n",
       "  'mean_mse': 1.6038905,\n",
       "  'mean_l1': 0.9674418,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1): GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.072940572102865,\n",
       "   3.1782622655232746,\n",
       "   2.6792705217997232,\n",
       "   2.3799785216649374,\n",
       "   2.2730757077534993,\n",
       "   1.9476332028706869,\n",
       "   1.822649343808492,\n",
       "   1.6189253012339273,\n",
       "   1.497630536556244,\n",
       "   1.5609099467595418,\n",
       "   1.389980932076772,\n",
       "   1.2200518210728963,\n",
       "   1.0803817371527353,\n",
       "   1.107080590724945,\n",
       "   1.0816672682762145,\n",
       "   1.2657809058825176,\n",
       "   0.9243239680926005,\n",
       "   1.1083828846613566,\n",
       "   0.9989677747090657,\n",
       "   0.8620154162247976,\n",
       "   0.842401937643687,\n",
       "   0.8526210566361745,\n",
       "   0.8348899841308594],\n",
       "  'val_losses': [7.741069793701172,\n",
       "   4.579651117324829,\n",
       "   4.057840824127197,\n",
       "   4.110067844390869,\n",
       "   3.891737699508667,\n",
       "   3.495943784713745,\n",
       "   3.5699492692947388,\n",
       "   2.9898133277893066,\n",
       "   2.7205110788345337,\n",
       "   2.5679813623428345,\n",
       "   2.392598271369934,\n",
       "   2.1200199127197266,\n",
       "   2.0750219225883484,\n",
       "   2.553578019142151,\n",
       "   2.0432980060577393,\n",
       "   2.3935571908950806,\n",
       "   2.1069560050964355,\n",
       "   1.869186520576477,\n",
       "   1.8885726928710938,\n",
       "   2.036673128604889,\n",
       "   1.8444048762321472,\n",
       "   1.7886125445365906,\n",
       "   1.8079136610031128]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.021 -3.363185\n",
       "  1   -2.461 -2.447241\n",
       "  2    0.300 -0.192227\n",
       "  3   -2.266 -1.526514\n",
       "  4   -6.680 -7.833176\n",
       "  ..     ...       ...\n",
       "  44  -3.168 -2.683333\n",
       "  45  -3.050 -3.161764\n",
       "  46  -2.060 -1.808496\n",
       "  47  -5.220 -6.444306\n",
       "  48  -6.860 -6.816429\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 83.60545754432678,\n",
       "  'mean_mse': 1.6740845,\n",
       "  'mean_l1': 1.020093,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-2): 2 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.268502712249756,\n",
       "   3.1452491760253904,\n",
       "   2.565869156519572,\n",
       "   2.0910613377889,\n",
       "   1.6948509534200034,\n",
       "   1.6854620536168416,\n",
       "   1.3052071491877237,\n",
       "   1.0063267330328622,\n",
       "   0.9196913878122965,\n",
       "   0.8402914315462112,\n",
       "   0.7562365969022115,\n",
       "   0.734334933757782,\n",
       "   0.7162372628847758,\n",
       "   0.6156203369299571,\n",
       "   0.595520826180776,\n",
       "   0.6245347539583842,\n",
       "   0.6438841819763184,\n",
       "   0.5104531347751617,\n",
       "   0.5238113204638163,\n",
       "   0.4725218693415324,\n",
       "   0.4769589444001516,\n",
       "   0.6335200130939483,\n",
       "   0.5157014389832815,\n",
       "   0.44188672105471294,\n",
       "   0.47424043019612633,\n",
       "   0.37723405758539835,\n",
       "   0.3970838367938995,\n",
       "   0.3677882527311643,\n",
       "   0.3860196053981781],\n",
       "  'val_losses': [6.598782777786255,\n",
       "   4.225024342536926,\n",
       "   4.018308401107788,\n",
       "   3.015848159790039,\n",
       "   2.7324801683425903,\n",
       "   3.406049609184265,\n",
       "   2.0671133995056152,\n",
       "   2.306903839111328,\n",
       "   1.8866612911224365,\n",
       "   2.1092551350593567,\n",
       "   1.9437360763549805,\n",
       "   2.0101717710494995,\n",
       "   1.903612494468689,\n",
       "   1.8877804279327393,\n",
       "   1.8570073246955872,\n",
       "   1.733864665031433,\n",
       "   1.7758542895317078,\n",
       "   1.8942546844482422,\n",
       "   1.934529960155487,\n",
       "   2.3342628479003906,\n",
       "   1.6108340620994568,\n",
       "   1.9174825549125671,\n",
       "   2.9064656496047974,\n",
       "   1.7248717546463013,\n",
       "   1.7544026374816895,\n",
       "   1.691841959953308,\n",
       "   1.7188074588775635,\n",
       "   1.8329099416732788,\n",
       "   1.7078469395637512]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.043 -3.231172\n",
       "  1   -3.021 -3.789410\n",
       "  2   -4.310 -4.440560\n",
       "  3   -2.281 -2.076280\n",
       "  4   -6.726 -6.941482\n",
       "  ..     ...       ...\n",
       "  44  -5.270 -5.187517\n",
       "  45  -2.160 -2.308421\n",
       "  46  -5.915 -4.783627\n",
       "  47  -1.740 -4.036005\n",
       "  48  -0.600 -1.319974\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 87.70620942115784,\n",
       "  'mean_mse': 1.7030256,\n",
       "  'mean_l1': 1.0071673,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-2): 2 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.902012666066487,\n",
       "   3.4678861618041994,\n",
       "   2.5865296204884847,\n",
       "   2.186267280578613,\n",
       "   1.747592520713806,\n",
       "   1.7251641352971394,\n",
       "   1.3480452179908753,\n",
       "   1.4621613343556723,\n",
       "   1.276534660657247,\n",
       "   1.2483313123385111,\n",
       "   1.0474345584710438,\n",
       "   1.1655805468559266,\n",
       "   1.0278911511103312,\n",
       "   1.222378913561503,\n",
       "   0.9258241126934688,\n",
       "   1.0714401006698608,\n",
       "   0.8129940390586853,\n",
       "   0.8456024249394735,\n",
       "   0.9982463399569194,\n",
       "   1.163621966044108,\n",
       "   0.7947483380635579,\n",
       "   0.770458588997523,\n",
       "   0.655124674240748,\n",
       "   0.6955805877844493,\n",
       "   0.9251616835594177,\n",
       "   0.6860614856084187,\n",
       "   0.8028227647145589,\n",
       "   0.7853810747464498,\n",
       "   0.5840147256851196,\n",
       "   0.9398567914962769,\n",
       "   0.9449513037999471,\n",
       "   0.6429727474848429,\n",
       "   0.6583889464537303],\n",
       "  'val_losses': [6.398402214050293,\n",
       "   4.7464659214019775,\n",
       "   5.220945477485657,\n",
       "   3.7853363752365112,\n",
       "   2.493410110473633,\n",
       "   2.1494388580322266,\n",
       "   2.1510531306266785,\n",
       "   2.303162157535553,\n",
       "   2.182749390602112,\n",
       "   2.5165825486183167,\n",
       "   2.9234025478363037,\n",
       "   1.99680095911026,\n",
       "   1.9630910158157349,\n",
       "   2.4707387685775757,\n",
       "   1.8150746822357178,\n",
       "   1.7705679535865784,\n",
       "   1.7227990627288818,\n",
       "   1.8352262377738953,\n",
       "   2.0756863355636597,\n",
       "   1.7086706757545471,\n",
       "   1.7847586274147034,\n",
       "   1.9837911128997803,\n",
       "   1.8401280641555786,\n",
       "   1.8127161264419556,\n",
       "   1.800608217716217,\n",
       "   2.208808660507202,\n",
       "   1.6740624904632568,\n",
       "   1.5486390590667725,\n",
       "   1.9235364198684692,\n",
       "   1.554086685180664,\n",
       "   1.9037116765975952,\n",
       "   1.7279767394065857,\n",
       "   2.840929865837097]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.460 -2.634695\n",
       "  1   -1.960 -4.120321\n",
       "  2   -1.716 -3.465843\n",
       "  3   -6.680 -7.516984\n",
       "  4   -4.310 -4.745263\n",
       "  ..     ...       ...\n",
       "  44  -3.638 -4.062076\n",
       "  45  -4.173 -4.914526\n",
       "  46  -1.899 -1.982857\n",
       "  47  -3.590 -4.909767\n",
       "  48  -6.780 -5.931993\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 67.3187186717987,\n",
       "  'mean_mse': 1.4718605,\n",
       "  'mean_l1': 0.97173643,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-2): 2 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.440802192687988,\n",
       "   3.041417868932088,\n",
       "   2.2681787888209026,\n",
       "   2.054979165395101,\n",
       "   1.9410732507705688,\n",
       "   1.3591925998528798,\n",
       "   1.2220377365748087,\n",
       "   1.0765693187713623,\n",
       "   0.8833478649457296,\n",
       "   0.8444732030232748,\n",
       "   0.7935601353645325,\n",
       "   0.8456106384595236,\n",
       "   0.8217475215593973,\n",
       "   0.7952316284179688,\n",
       "   0.726595417658488,\n",
       "   0.6533349593480428,\n",
       "   0.5824656615654628,\n",
       "   0.5423167089621226,\n",
       "   0.5988771259784699,\n",
       "   0.7458657701810201,\n",
       "   0.5137353072563807,\n",
       "   0.4789551705121994,\n",
       "   0.4714927573998769,\n",
       "   0.45974997878074647,\n",
       "   0.5206519345442454],\n",
       "  'val_losses': [6.4979331493377686,\n",
       "   4.324288964271545,\n",
       "   3.9099262952804565,\n",
       "   3.323926329612732,\n",
       "   3.343189239501953,\n",
       "   2.809817910194397,\n",
       "   2.1428640484809875,\n",
       "   1.9588038325309753,\n",
       "   1.9906660318374634,\n",
       "   2.0064552426338196,\n",
       "   2.2156805992126465,\n",
       "   2.047455847263336,\n",
       "   1.9371128678321838,\n",
       "   2.1477545499801636,\n",
       "   2.5425164699554443,\n",
       "   1.8988527059555054,\n",
       "   1.8662924766540527,\n",
       "   1.7671626806259155,\n",
       "   1.8874264359474182,\n",
       "   1.98451429605484,\n",
       "   1.6603593230247498,\n",
       "   1.8323006629943848,\n",
       "   1.7868078351020813,\n",
       "   1.5507776141166687,\n",
       "   1.6840729713439941]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    1.100  0.269158\n",
       "  1   -1.990 -2.369974\n",
       "  2   -3.583 -1.205523\n",
       "  3   -4.160 -4.423572\n",
       "  4    0.522  0.166504\n",
       "  ..     ...       ...\n",
       "  44  -3.050 -2.787744\n",
       "  45  -3.658 -5.290947\n",
       "  46  -3.094 -1.596551\n",
       "  47  -5.410 -5.463043\n",
       "  48  -1.740 -3.791111\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 85.84224772453308,\n",
       "  'mean_mse': 1.5601823,\n",
       "  'mean_l1': 0.97538316,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-3): 3 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.569883950551351,\n",
       "   3.034221363067627,\n",
       "   2.3153396447499595,\n",
       "   1.690371823310852,\n",
       "   1.3957640012105306,\n",
       "   1.1690835138161977,\n",
       "   1.3822863817214965,\n",
       "   0.7998097568750382,\n",
       "   0.8032810360193252,\n",
       "   0.8356256723403931,\n",
       "   0.6296702027320862,\n",
       "   0.6789606054623921,\n",
       "   0.7199318548043568,\n",
       "   0.5948629756768544,\n",
       "   0.5710047920544942,\n",
       "   0.6002537270387014,\n",
       "   0.43813107907772064,\n",
       "   0.4731358249982198,\n",
       "   0.4661088148752848,\n",
       "   0.3973530799150467,\n",
       "   0.3345001374681791,\n",
       "   0.320114740729332,\n",
       "   0.36721019744873046,\n",
       "   0.4124867449204127,\n",
       "   0.4170350233713786,\n",
       "   0.3469901978969574,\n",
       "   0.32388932158549627],\n",
       "  'val_losses': [7.017329931259155,\n",
       "   3.9722119569778442,\n",
       "   4.218116521835327,\n",
       "   2.9096391201019287,\n",
       "   3.4457831382751465,\n",
       "   1.9439358115196228,\n",
       "   2.0812620520591736,\n",
       "   1.9386767148971558,\n",
       "   1.8910473585128784,\n",
       "   2.0925233364105225,\n",
       "   1.7385567426681519,\n",
       "   1.6362255215644836,\n",
       "   1.5888793468475342,\n",
       "   1.6565969586372375,\n",
       "   1.5160281956195831,\n",
       "   1.6556270718574524,\n",
       "   1.5518428683280945,\n",
       "   2.253220319747925,\n",
       "   1.469965934753418,\n",
       "   1.6196647882461548,\n",
       "   1.4680045247077942,\n",
       "   1.3123032450675964,\n",
       "   1.3228400647640228,\n",
       "   1.5400536060333252,\n",
       "   1.501109778881073,\n",
       "   1.405044972896576,\n",
       "   1.4896451234817505]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.743 -5.415396\n",
       "  1   -4.380 -4.648195\n",
       "  2   -3.800 -4.602296\n",
       "  3   -3.460 -2.594400\n",
       "  4   -1.716 -2.731036\n",
       "  ..     ...       ...\n",
       "  44  -0.400 -0.355207\n",
       "  45  -3.171 -5.425719\n",
       "  46  -2.461 -1.894738\n",
       "  47  -2.320 -5.716946\n",
       "  48   0.522  1.173372\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 56.688167095184326,\n",
       "  'mean_mse': 2.0193145,\n",
       "  'mean_l1': 1.0633003,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-2): 2 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.919505087534587,\n",
       "   3.801771291097005,\n",
       "   3.628612009684245,\n",
       "   3.4186704953511557,\n",
       "   2.875413242975871,\n",
       "   2.524122428894043,\n",
       "   2.246767290433248,\n",
       "   1.9866862773895264,\n",
       "   1.806011160214742,\n",
       "   1.6671919385592142,\n",
       "   1.609346361955007,\n",
       "   1.3495384295781454,\n",
       "   1.3452325145403543,\n",
       "   1.2105895082155864,\n",
       "   1.2194044748942057,\n",
       "   1.0892964353164036,\n",
       "   1.4047284126281738,\n",
       "   1.0713305036226908,\n",
       "   1.234663756688436,\n",
       "   1.047330117225647,\n",
       "   1.173850703239441,\n",
       "   1.1189155836900075,\n",
       "   0.9655985792477926,\n",
       "   1.0242412408192954,\n",
       "   1.1359057346979777,\n",
       "   0.9060448845227559,\n",
       "   0.9261064251263936,\n",
       "   1.0020691752433777],\n",
       "  'val_losses': [4.915143966674805,\n",
       "   4.6242698431015015,\n",
       "   4.592833518981934,\n",
       "   4.299367189407349,\n",
       "   4.164515256881714,\n",
       "   4.257638573646545,\n",
       "   4.104982376098633,\n",
       "   3.6002432107925415,\n",
       "   2.7635159492492676,\n",
       "   4.1007561683654785,\n",
       "   2.1547630429267883,\n",
       "   2.7786046266555786,\n",
       "   1.9874586462974548,\n",
       "   2.1113513708114624,\n",
       "   2.492039203643799,\n",
       "   2.071836531162262,\n",
       "   2.654226064682007,\n",
       "   2.048064172267914,\n",
       "   2.151816725730896,\n",
       "   2.7778314352035522,\n",
       "   2.1030935049057007,\n",
       "   1.958819568157196,\n",
       "   1.9432916641235352,\n",
       "   2.3289068937301636,\n",
       "   2.0036988258361816,\n",
       "   1.9730139374732971,\n",
       "   2.003524959087372,\n",
       "   2.0032742023468018]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.690 -4.775919\n",
       "  1   -2.349 -2.105265\n",
       "  2   -1.990 -3.210150\n",
       "  3   -5.270 -5.320063\n",
       "  4   -2.700 -3.949620\n",
       "  ..     ...       ...\n",
       "  44  -3.583 -1.547848\n",
       "  45  -6.680 -7.456219\n",
       "  46  -3.620 -2.640229\n",
       "  47  -3.460 -3.844339\n",
       "  48  -8.600 -7.245573\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 64.35391759872437,\n",
       "  'mean_mse': 1.7359356,\n",
       "  'mean_l1': 1.0216274,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-3): 3 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.1268049875895185,\n",
       "   3.6817992528279624,\n",
       "   2.7418872356414794,\n",
       "   2.228608127435048,\n",
       "   2.166959110895793,\n",
       "   1.9553836027781168,\n",
       "   1.3943222641944886,\n",
       "   1.122137153148651,\n",
       "   1.226460619767507,\n",
       "   0.8712400356928508,\n",
       "   0.9006167531013489,\n",
       "   1.0534931222597759,\n",
       "   0.7722554524739583,\n",
       "   0.7243471721808116,\n",
       "   0.5616828342278798,\n",
       "   1.1275323271751403,\n",
       "   0.7057875514030456,\n",
       "   0.6159703135490417,\n",
       "   0.4512657890717188,\n",
       "   0.4448881144324938,\n",
       "   0.4816448390483856],\n",
       "  'val_losses': [7.616633653640747,\n",
       "   4.249775648117065,\n",
       "   3.729538917541504,\n",
       "   3.6662039756774902,\n",
       "   2.7679476737976074,\n",
       "   2.264239549636841,\n",
       "   2.139521062374115,\n",
       "   2.0883034467697144,\n",
       "   2.0838980674743652,\n",
       "   2.8039298057556152,\n",
       "   1.9768473505973816,\n",
       "   5.447279453277588,\n",
       "   1.9014573693275452,\n",
       "   1.6677229404449463,\n",
       "   2.052555799484253,\n",
       "   3.2509037256240845,\n",
       "   1.6294493675231934,\n",
       "   1.635851263999939,\n",
       "   1.7043462991714478,\n",
       "   1.6279845237731934,\n",
       "   2.16845840215683]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.266 -1.226910\n",
       "  1   -4.799 -3.727183\n",
       "  2   -3.401 -1.519470\n",
       "  3   -2.700 -3.166243\n",
       "  4   -5.400 -3.758743\n",
       "  ..     ...       ...\n",
       "  44  -3.538 -4.217453\n",
       "  45  -5.696 -4.953875\n",
       "  46  -1.800 -1.739479\n",
       "  47  -3.180 -2.457747\n",
       "  48  -2.350 -2.717939\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 40.68567895889282,\n",
       "  'mean_mse': 1.8478087,\n",
       "  'mean_l1': 1.0434966,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [256],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 256)\n",
       "      (1-3): 3 x GCNConv(256, 256)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.634893107414245,\n",
       "   2.3376156171162923,\n",
       "   2.0515415191650392,\n",
       "   1.6059410452842713,\n",
       "   1.7726537307103476,\n",
       "   1.1938969373703003,\n",
       "   1.0710371613502503,\n",
       "   0.9586428761482239,\n",
       "   0.9747897962729136,\n",
       "   0.9542229851086934,\n",
       "   0.814555017153422,\n",
       "   0.8473138173421224,\n",
       "   0.6077413856983185],\n",
       "  'val_losses': [7.71239161491394,\n",
       "   3.95448899269104,\n",
       "   3.1582521200180054,\n",
       "   2.7956639528274536,\n",
       "   2.274980068206787,\n",
       "   3.6850459575653076,\n",
       "   1.9855486750602722,\n",
       "   1.9679373502731323,\n",
       "   1.8766868114471436,\n",
       "   2.6180593967437744,\n",
       "   2.146872878074646,\n",
       "   1.7681270837783813,\n",
       "   2.0982413291931152]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.925 -4.990974\n",
       "  1   -1.040 -4.106925\n",
       "  2   -3.050 -3.985588\n",
       "  3   -4.799 -3.868484\n",
       "  4   -8.040 -6.117837\n",
       "  ..     ...       ...\n",
       "  44  -6.680 -6.218597\n",
       "  45  -2.350 -2.702636\n",
       "  46  -3.180 -2.662462\n",
       "  47  -3.460 -4.293444\n",
       "  48  -2.932 -2.097146\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 120.46023106575012,\n",
       "  'mean_mse': 1.6078476,\n",
       "  'mean_l1': 1.0165713,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [7.161103010177612,\n",
       "   3.428114819526672,\n",
       "   3.35667405128479,\n",
       "   3.0511794408162434,\n",
       "   2.4774443387985228,\n",
       "   2.421925926208496,\n",
       "   2.3543070554733276,\n",
       "   2.1192230860392254,\n",
       "   2.03243309656779,\n",
       "   2.099289313952128,\n",
       "   1.8925792217254638,\n",
       "   1.808626389503479,\n",
       "   1.671017551422119,\n",
       "   1.5967272261778513,\n",
       "   1.9347739140192668,\n",
       "   1.8019349098205566,\n",
       "   1.62653644879659,\n",
       "   1.4690576513608298,\n",
       "   1.4384892145792643,\n",
       "   1.4022543708483377,\n",
       "   1.3111137946446736,\n",
       "   1.265724774201711,\n",
       "   1.1929544230302176,\n",
       "   1.2097315271695455,\n",
       "   1.326298224925995,\n",
       "   1.1095312476158141,\n",
       "   1.0702459186315536,\n",
       "   1.0764652927716574,\n",
       "   1.120324726899465,\n",
       "   1.1296634674072266,\n",
       "   1.0124539375305175,\n",
       "   1.1037899533907571,\n",
       "   1.0281390070915222,\n",
       "   1.0342524965604147,\n",
       "   0.9641868789990743,\n",
       "   0.9745431343714396,\n",
       "   1.012855859597524,\n",
       "   1.1663466970125833,\n",
       "   0.9147118469079335,\n",
       "   0.9073293407758077,\n",
       "   0.8684727549552917,\n",
       "   0.954341455300649,\n",
       "   0.8519364913304647,\n",
       "   0.780122576157252,\n",
       "   0.8954982002576192,\n",
       "   0.8251519680023194,\n",
       "   0.8405254403750102,\n",
       "   0.8639356096585592,\n",
       "   0.8366804639498393,\n",
       "   0.7555564105510711,\n",
       "   0.7243876377741496,\n",
       "   0.7592803070942561,\n",
       "   0.7424743473529816,\n",
       "   0.7414609710375468,\n",
       "   0.754745618502299,\n",
       "   0.8660991787910461,\n",
       "   0.6655121107896169],\n",
       "  'val_losses': [4.647766351699829,\n",
       "   4.262270450592041,\n",
       "   4.202139973640442,\n",
       "   4.290571689605713,\n",
       "   4.118311882019043,\n",
       "   4.253251075744629,\n",
       "   3.7361245155334473,\n",
       "   3.8932541608810425,\n",
       "   3.5977977514266968,\n",
       "   3.4791765213012695,\n",
       "   3.275314211845398,\n",
       "   3.049333930015564,\n",
       "   3.058652400970459,\n",
       "   3.075390100479126,\n",
       "   2.8300923109054565,\n",
       "   2.6651734113693237,\n",
       "   2.915804147720337,\n",
       "   2.5018038749694824,\n",
       "   3.1636765003204346,\n",
       "   2.7848575115203857,\n",
       "   2.6066362857818604,\n",
       "   2.6915271282196045,\n",
       "   2.364132881164551,\n",
       "   2.6245168447494507,\n",
       "   2.7298929691314697,\n",
       "   2.5227684378623962,\n",
       "   2.3153576850891113,\n",
       "   2.117004692554474,\n",
       "   2.2465509176254272,\n",
       "   2.0769028067588806,\n",
       "   2.749289393424988,\n",
       "   2.9638360738754272,\n",
       "   2.5879839658737183,\n",
       "   2.3246673345565796,\n",
       "   2.4358808994293213,\n",
       "   2.478208065032959,\n",
       "   2.466086506843567,\n",
       "   2.613953113555908,\n",
       "   2.1586272716522217,\n",
       "   2.295310616493225,\n",
       "   2.108807682991028,\n",
       "   2.1943017840385437,\n",
       "   1.97443425655365,\n",
       "   2.0849545001983643,\n",
       "   2.211854934692383,\n",
       "   2.108104407787323,\n",
       "   2.021301805973053,\n",
       "   2.2015578150749207,\n",
       "   2.5071299076080322,\n",
       "   2.0669476985931396,\n",
       "   2.2579204440116882,\n",
       "   1.928950011730194,\n",
       "   1.9624272584915161,\n",
       "   2.134493350982666,\n",
       "   1.958773136138916,\n",
       "   2.1716614365577698,\n",
       "   2.1588879227638245]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.883 -3.830776\n",
       "  1   -6.800 -8.486073\n",
       "  2   -4.950 -3.574743\n",
       "  3   -4.402 -5.497548\n",
       "  4   -2.160 -3.329063\n",
       "  ..     ...       ...\n",
       "  44  -2.461 -2.272261\n",
       "  45  -2.932 -1.936812\n",
       "  46  -4.925 -4.278619\n",
       "  47  -6.780 -4.111721\n",
       "  48  -3.880 -3.844900\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 118.97260618209839,\n",
       "  'mean_mse': 1.8444607,\n",
       "  'mean_l1': 1.00636,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.538896989822388,\n",
       "   3.921331262588501,\n",
       "   3.6223820368448894,\n",
       "   3.455670642852783,\n",
       "   3.272725470860799,\n",
       "   3.5993426005045572,\n",
       "   2.8270631949106853,\n",
       "   3.0447370449701947,\n",
       "   2.8016274134318033,\n",
       "   2.689176829655965,\n",
       "   2.55896901289622,\n",
       "   2.45984001159668,\n",
       "   2.5048139015833537,\n",
       "   2.317934787273407,\n",
       "   2.299494727452596,\n",
       "   2.2915306011835734,\n",
       "   2.1837483565012614,\n",
       "   2.0789885679880777,\n",
       "   1.9806388735771179,\n",
       "   2.04292885462443,\n",
       "   1.8833027402559916,\n",
       "   1.9477627913157145,\n",
       "   1.8155795693397523,\n",
       "   1.9598149220148722,\n",
       "   1.8455987056096395,\n",
       "   1.905335545539856,\n",
       "   1.6622305472691854,\n",
       "   1.680516036351522,\n",
       "   1.7114749749501545,\n",
       "   1.7349000692367553,\n",
       "   1.5447985132535298,\n",
       "   1.5560184121131897,\n",
       "   1.5342289090156556,\n",
       "   1.6571555058161418,\n",
       "   1.738116486867269,\n",
       "   1.4942724386850992,\n",
       "   1.5825242559115091,\n",
       "   1.4193735678990682,\n",
       "   1.577462371190389,\n",
       "   1.3783984859784444,\n",
       "   1.376951805750529,\n",
       "   1.3994988600413005,\n",
       "   1.6857121070226033,\n",
       "   1.4461411794026693,\n",
       "   1.3125985423723856,\n",
       "   1.516693607966105,\n",
       "   1.4029092222452164,\n",
       "   1.3274290839831033,\n",
       "   1.2879943052927654,\n",
       "   1.3111836194992066,\n",
       "   1.3181182742118835,\n",
       "   1.4400930643081664,\n",
       "   1.4408497969309488,\n",
       "   1.2681605497996011,\n",
       "   1.2656251748402914,\n",
       "   1.3838488737742105,\n",
       "   1.3724616845448812,\n",
       "   1.2478708267211913,\n",
       "   1.2564681728680929,\n",
       "   1.211077300707499],\n",
       "  'val_losses': [4.795186758041382,\n",
       "   4.559696197509766,\n",
       "   4.880471706390381,\n",
       "   4.285711407661438,\n",
       "   4.08682656288147,\n",
       "   4.117953300476074,\n",
       "   4.31600284576416,\n",
       "   3.9578447341918945,\n",
       "   3.905482769012451,\n",
       "   3.7724080085754395,\n",
       "   3.791958212852478,\n",
       "   3.722648501396179,\n",
       "   3.8294384479522705,\n",
       "   3.468674898147583,\n",
       "   3.5530935525894165,\n",
       "   3.56325364112854,\n",
       "   3.341636538505554,\n",
       "   3.333606481552124,\n",
       "   3.064475893974304,\n",
       "   2.8493250608444214,\n",
       "   2.833864688873291,\n",
       "   2.861475706100464,\n",
       "   2.667765259742737,\n",
       "   2.9963914155960083,\n",
       "   2.575904607772827,\n",
       "   2.5335439443588257,\n",
       "   2.4848129749298096,\n",
       "   2.4641246795654297,\n",
       "   2.6772252321243286,\n",
       "   2.416331648826599,\n",
       "   2.61994332075119,\n",
       "   2.225102186203003,\n",
       "   2.1930102109909058,\n",
       "   2.104760766029358,\n",
       "   2.1409561038017273,\n",
       "   2.172837793827057,\n",
       "   2.034467875957489,\n",
       "   2.021925985813141,\n",
       "   2.0216275453567505,\n",
       "   2.0081841349601746,\n",
       "   2.06156325340271,\n",
       "   2.0763521790504456,\n",
       "   1.991240382194519,\n",
       "   1.9206219911575317,\n",
       "   2.188098967075348,\n",
       "   2.0659204721450806,\n",
       "   1.904434621334076,\n",
       "   1.8196459412574768,\n",
       "   1.820082187652588,\n",
       "   1.8969078063964844,\n",
       "   1.8670242428779602,\n",
       "   1.884015142917633,\n",
       "   1.8665366172790527,\n",
       "   1.8479579091072083,\n",
       "   1.8874124884605408,\n",
       "   1.8445420861244202,\n",
       "   1.989138662815094,\n",
       "   1.8358039259910583,\n",
       "   1.9646804928779602,\n",
       "   2.032650351524353]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.266 -2.734367\n",
       "  1   -5.410 -3.664066\n",
       "  2   -3.610 -3.619539\n",
       "  3   -3.672 -2.241530\n",
       "  4   -1.899 -2.374017\n",
       "  ..     ...       ...\n",
       "  44  -5.696 -4.914598\n",
       "  45  -5.190 -2.580973\n",
       "  46  -2.281 -2.879607\n",
       "  47  -4.634 -5.712202\n",
       "  48  -4.376 -5.215378\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 92.11775040626526,\n",
       "  'mean_mse': 2.1823046,\n",
       "  'mean_l1': 1.1898158,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.603158473968506,\n",
       "   3.54010108311971,\n",
       "   3.2827938715616862,\n",
       "   3.253002325693766,\n",
       "   2.9220967928568524,\n",
       "   2.6912608544031777,\n",
       "   2.6399514198303224,\n",
       "   2.3746980587641398,\n",
       "   2.38921586672465,\n",
       "   2.320687993367513,\n",
       "   2.1745237509409585,\n",
       "   2.103290549914042,\n",
       "   2.0033154845237733,\n",
       "   1.9771350781122843,\n",
       "   1.8413976510365804,\n",
       "   1.916582743326823,\n",
       "   1.721120798587799,\n",
       "   1.9172334273656209,\n",
       "   1.699989162882169,\n",
       "   1.6735040028889974,\n",
       "   1.7095227003097535,\n",
       "   1.6487154006958007,\n",
       "   1.6749516169230143,\n",
       "   1.5718335131804149,\n",
       "   1.5587653716405232,\n",
       "   1.475080394744873,\n",
       "   1.5155341943105063,\n",
       "   1.4551644881566366,\n",
       "   1.4884483655293783,\n",
       "   1.435084080696106,\n",
       "   1.3754801591237387,\n",
       "   1.3760312080383301,\n",
       "   1.4465034087498982,\n",
       "   1.312741720676422,\n",
       "   1.316314947605133,\n",
       "   1.4474598248799642,\n",
       "   1.3806384364763895,\n",
       "   1.4037348906199136,\n",
       "   1.5478406230608621,\n",
       "   1.4021317124366761,\n",
       "   1.2284446954727173,\n",
       "   1.264672537644704,\n",
       "   1.3118054389953613,\n",
       "   1.2432755748430888,\n",
       "   1.255113915602366,\n",
       "   1.3356617927551269],\n",
       "  'val_losses': [4.800097465515137,\n",
       "   4.470088839530945,\n",
       "   4.52939248085022,\n",
       "   4.262960910797119,\n",
       "   4.2422497272491455,\n",
       "   4.372443199157715,\n",
       "   4.386563539505005,\n",
       "   4.12489378452301,\n",
       "   3.692905068397522,\n",
       "   3.8714972734451294,\n",
       "   3.8008276224136353,\n",
       "   4.032817125320435,\n",
       "   3.340006470680237,\n",
       "   3.2780874967575073,\n",
       "   3.270957827568054,\n",
       "   3.067739963531494,\n",
       "   3.0789419412612915,\n",
       "   2.897177219390869,\n",
       "   2.86245334148407,\n",
       "   2.781373977661133,\n",
       "   2.7940025329589844,\n",
       "   2.7259424924850464,\n",
       "   2.5102750062942505,\n",
       "   2.560035228729248,\n",
       "   2.701029360294342,\n",
       "   2.9068938493728638,\n",
       "   2.437739133834839,\n",
       "   2.7252708673477173,\n",
       "   2.3266292810440063,\n",
       "   2.780318021774292,\n",
       "   2.3992202281951904,\n",
       "   2.347357392311096,\n",
       "   2.406027674674988,\n",
       "   2.5179940462112427,\n",
       "   2.2941341400146484,\n",
       "   2.3363897800445557,\n",
       "   2.550094425678253,\n",
       "   2.35506010055542,\n",
       "   2.606676697731018,\n",
       "   2.332155704498291,\n",
       "   2.2645273208618164,\n",
       "   2.542030453681946,\n",
       "   2.264038324356079,\n",
       "   2.205735921859741,\n",
       "   2.5298510789871216,\n",
       "   2.419396758079529]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.460 -2.969286\n",
       "  1   -4.445 -4.861515\n",
       "  2   -2.676 -3.403033\n",
       "  3   -4.883 -4.405097\n",
       "  4   -4.160 -5.059402\n",
       "  ..     ...       ...\n",
       "  44  -2.100 -2.136732\n",
       "  45  -3.583 -1.566174\n",
       "  46   0.790 -1.017614\n",
       "  47  -7.800 -8.324587\n",
       "  48  -4.328 -4.320602\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 55.027472734451294,\n",
       "  'mean_mse': 1.6402128,\n",
       "  'mean_l1': 0.97773814,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1): GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.115385389328003,\n",
       "   3.2097015221913656,\n",
       "   2.571314493815104,\n",
       "   2.0670448859532673,\n",
       "   2.0048087358474733,\n",
       "   1.7474104404449462,\n",
       "   1.7352945327758789,\n",
       "   1.215312111377716,\n",
       "   1.0801725745201112,\n",
       "   0.9678580661614736,\n",
       "   0.8846219837665558,\n",
       "   0.7801454782485961,\n",
       "   0.688155206044515,\n",
       "   0.764260447025299,\n",
       "   0.7946885804335276,\n",
       "   0.6348183631896973,\n",
       "   0.5880908846855164,\n",
       "   0.5765917758146922,\n",
       "   0.5315441230932871,\n",
       "   0.49166752099990846,\n",
       "   0.6027981718381246,\n",
       "   0.46303481558958687,\n",
       "   0.49734136164188386],\n",
       "  'val_losses': [6.284807920455933,\n",
       "   4.365623235702515,\n",
       "   4.869596242904663,\n",
       "   3.4600067138671875,\n",
       "   3.1091800928115845,\n",
       "   2.897254705429077,\n",
       "   2.4831444025039673,\n",
       "   2.7016173601150513,\n",
       "   2.0749324560165405,\n",
       "   1.8992448449134827,\n",
       "   1.9167845249176025,\n",
       "   1.8093850016593933,\n",
       "   2.254287898540497,\n",
       "   1.8495935201644897,\n",
       "   1.897962510585785,\n",
       "   1.7619521617889404,\n",
       "   1.84328293800354,\n",
       "   1.9824620485305786,\n",
       "   1.6847447752952576,\n",
       "   1.9995039105415344,\n",
       "   1.8471361994743347,\n",
       "   1.8289722204208374,\n",
       "   1.9529657363891602]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.190 -4.741177\n",
       "  1   -4.402 -5.535722\n",
       "  2   -3.638 -3.068355\n",
       "  3   -3.451 -5.048353\n",
       "  4   -2.120 -1.011352\n",
       "  ..     ...       ...\n",
       "  44  -3.620 -2.332031\n",
       "  45  -2.060 -1.748380\n",
       "  46  -2.920 -2.369167\n",
       "  47  -4.376 -4.118341\n",
       "  48  -3.930 -2.359123\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 63.13820838928223,\n",
       "  'mean_mse': 1.8950429,\n",
       "  'mean_l1': 1.0788673,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1): GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.612101968129476,\n",
       "   3.676146459579468,\n",
       "   2.911604340871175,\n",
       "   2.5066829840342204,\n",
       "   2.3240975459416706,\n",
       "   2.1020517031351726,\n",
       "   2.473966693878174,\n",
       "   1.6025421937306723,\n",
       "   1.4249746481577554,\n",
       "   1.516823442776998,\n",
       "   1.3549718022346497,\n",
       "   1.2797163764635722,\n",
       "   1.3084586262702942,\n",
       "   1.3990949789683025,\n",
       "   1.2556865294774373,\n",
       "   1.2008286873499552,\n",
       "   1.1080209255218505,\n",
       "   1.0143152197202048,\n",
       "   1.0471457203229269,\n",
       "   0.9633166531721751,\n",
       "   1.0410672863324484,\n",
       "   0.8935471723477045,\n",
       "   0.9459318419297537,\n",
       "   0.9963562846183777,\n",
       "   0.9721633593241373,\n",
       "   0.9983711878458659,\n",
       "   1.1396273175875347,\n",
       "   0.9166524370511373,\n",
       "   0.8423993786176046],\n",
       "  'val_losses': [6.7028563022613525,\n",
       "   4.667859792709351,\n",
       "   4.73649001121521,\n",
       "   5.974591255187988,\n",
       "   3.8895293474197388,\n",
       "   2.638576865196228,\n",
       "   2.5121458768844604,\n",
       "   2.136631190776825,\n",
       "   2.3766729831695557,\n",
       "   2.766440272331238,\n",
       "   3.006111264228821,\n",
       "   2.185500979423523,\n",
       "   2.062344491481781,\n",
       "   2.353950023651123,\n",
       "   1.854068636894226,\n",
       "   2.1519581079483032,\n",
       "   2.1498119235038757,\n",
       "   1.9147917032241821,\n",
       "   1.785243809223175,\n",
       "   2.0354738235473633,\n",
       "   1.8189155459403992,\n",
       "   1.6920063495635986,\n",
       "   1.7688329815864563,\n",
       "   1.591850996017456,\n",
       "   1.621191382408142,\n",
       "   2.5920568704605103,\n",
       "   3.012566566467285,\n",
       "   2.0656168460845947,\n",
       "   1.709121286869049]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.450 -1.628393\n",
       "  1   -4.805 -2.705230\n",
       "  2   -8.600 -5.827577\n",
       "  3   -0.742 -1.530084\n",
       "  4   -9.018 -8.764167\n",
       "  ..     ...       ...\n",
       "  44  -4.370 -4.897091\n",
       "  45  -4.047 -3.831431\n",
       "  46  -5.915 -5.199202\n",
       "  47  -3.290 -4.670025\n",
       "  48  -5.400 -3.112190\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 55.42601418495178,\n",
       "  'mean_mse': 1.6213993,\n",
       "  'mean_l1': 1.0063388,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1): GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.488664754231771,\n",
       "   3.2944893995920816,\n",
       "   2.366180149714152,\n",
       "   1.9824461301167806,\n",
       "   1.6580007831255594,\n",
       "   1.4995044231414796,\n",
       "   1.376881464322408,\n",
       "   1.1549237449963887,\n",
       "   1.5719566027323404,\n",
       "   1.1806839227676391,\n",
       "   1.2169117709000905,\n",
       "   0.9403684337933859,\n",
       "   1.1226944128672283,\n",
       "   0.8823999444643656,\n",
       "   0.958212959766388,\n",
       "   0.7737188557783763,\n",
       "   0.8645314435164134,\n",
       "   0.9283008019129435,\n",
       "   0.7049829820791881,\n",
       "   0.6871602773666382,\n",
       "   0.652092432975769,\n",
       "   0.6529369453589121,\n",
       "   0.7615208903948466,\n",
       "   0.7281196097532908],\n",
       "  'val_losses': [7.065638542175293,\n",
       "   4.27268385887146,\n",
       "   4.0442997217178345,\n",
       "   3.9891393184661865,\n",
       "   2.916174054145813,\n",
       "   2.626247763633728,\n",
       "   2.332467198371887,\n",
       "   2.1238162517547607,\n",
       "   2.0072428584098816,\n",
       "   1.9845900535583496,\n",
       "   3.408939480781555,\n",
       "   1.8372395634651184,\n",
       "   1.8492262363433838,\n",
       "   1.9649469256401062,\n",
       "   1.8354475498199463,\n",
       "   2.29667866230011,\n",
       "   3.3118209838867188,\n",
       "   1.8459835052490234,\n",
       "   1.896817684173584,\n",
       "   1.888218343257904,\n",
       "   2.382852852344513,\n",
       "   1.7369003295898438,\n",
       "   2.032080292701721,\n",
       "   1.9322734475135803]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.638 -3.237664\n",
       "  1   -5.270 -5.262558\n",
       "  2   -4.450 -1.776469\n",
       "  3   -6.860 -5.819758\n",
       "  4   -1.960 -4.418615\n",
       "  ..     ...       ...\n",
       "  44  -3.880 -3.543251\n",
       "  45  -2.338 -2.081634\n",
       "  46   1.100  0.327741\n",
       "  47  -3.460 -3.019482\n",
       "  48  -1.250 -0.714327\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 63.00387263298035,\n",
       "  'mean_mse': 1.4591501,\n",
       "  'mean_l1': 0.9459748,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-2): 2 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.1631246169408165,\n",
       "   2.850373168786367,\n",
       "   2.002741058667501,\n",
       "   1.7125341892242432,\n",
       "   1.4995198090871176,\n",
       "   1.4070470730463664,\n",
       "   0.9926964282989502,\n",
       "   0.9197231610616048,\n",
       "   0.6813493549823761,\n",
       "   0.7280309756596883,\n",
       "   0.5784981330235799,\n",
       "   0.5435352543989818,\n",
       "   0.5663781121373177,\n",
       "   0.5161249200503032,\n",
       "   0.6258274972438812,\n",
       "   0.5627778987089793,\n",
       "   0.44400458931922915,\n",
       "   0.36347524424393973,\n",
       "   0.4943838596343994,\n",
       "   0.3601762374242147,\n",
       "   0.42049246430397036,\n",
       "   0.3133689602216085,\n",
       "   0.3673112362623215],\n",
       "  'val_losses': [5.370327472686768,\n",
       "   5.017819404602051,\n",
       "   3.9223384857177734,\n",
       "   2.6895722150802612,\n",
       "   3.442449450492859,\n",
       "   3.6887245178222656,\n",
       "   1.9629883766174316,\n",
       "   1.8709101676940918,\n",
       "   1.6774851083755493,\n",
       "   1.8016515374183655,\n",
       "   2.095796287059784,\n",
       "   1.6886129975318909,\n",
       "   2.017474412918091,\n",
       "   1.6880120038986206,\n",
       "   1.6210159063339233,\n",
       "   1.6067194938659668,\n",
       "   1.491100013256073,\n",
       "   1.6683200597763062,\n",
       "   1.4218387007713318,\n",
       "   1.4504528045654297,\n",
       "   1.4369523525238037,\n",
       "   1.5193663239479065,\n",
       "   1.4459460973739624]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.640 -4.271675\n",
       "  1    0.300 -0.127368\n",
       "  2   -2.700 -3.868195\n",
       "  3   -3.590 -4.389209\n",
       "  4   -3.800 -3.555151\n",
       "  ..     ...       ...\n",
       "  44  -3.043 -2.903351\n",
       "  45   1.100  0.223223\n",
       "  46  -2.120 -0.597605\n",
       "  47  -3.583 -1.062719\n",
       "  48  -3.880 -4.182790\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 67.58199644088745,\n",
       "  'mean_mse': 1.531404,\n",
       "  'mean_l1': 0.9577191,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-2): 2 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.4113704840342205,\n",
       "   3.22673548857371,\n",
       "   2.73972004254659,\n",
       "   1.8870978752772014,\n",
       "   1.6956227620442708,\n",
       "   1.7646460056304931,\n",
       "   1.2465087493260703,\n",
       "   1.2544649322827657,\n",
       "   1.2311697522799174,\n",
       "   1.012803852558136,\n",
       "   0.9273838599522909,\n",
       "   1.2238861123720806,\n",
       "   0.9094461391369502,\n",
       "   0.7498059968153635,\n",
       "   0.8580318709214528,\n",
       "   0.6547668109337489,\n",
       "   0.7210982978343964,\n",
       "   0.658555809656779,\n",
       "   0.7240111470222473,\n",
       "   0.6835029204686482,\n",
       "   0.763336318731308,\n",
       "   0.602811849117279,\n",
       "   0.6123933911323547,\n",
       "   0.6086155672868093,\n",
       "   0.4809107700983683,\n",
       "   0.6384141733249028,\n",
       "   0.5712461094061534],\n",
       "  'val_losses': [4.973638296127319,\n",
       "   4.585562467575073,\n",
       "   4.130497932434082,\n",
       "   3.3504645824432373,\n",
       "   2.4999338388442993,\n",
       "   2.0674092173576355,\n",
       "   2.342736840248108,\n",
       "   2.0874244570732117,\n",
       "   2.4621078968048096,\n",
       "   2.165767192840576,\n",
       "   1.945179522037506,\n",
       "   1.731888473033905,\n",
       "   2.2700129747390747,\n",
       "   2.2240421175956726,\n",
       "   2.2731624245643616,\n",
       "   1.630290150642395,\n",
       "   2.845923066139221,\n",
       "   1.6410405039787292,\n",
       "   1.554297149181366,\n",
       "   1.7256037592887878,\n",
       "   1.624511957168579,\n",
       "   1.6310141682624817,\n",
       "   1.6118313074111938,\n",
       "   2.039756178855896,\n",
       "   1.5506992936134338,\n",
       "   1.6265012621879578,\n",
       "   1.6880984902381897]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.338 -3.272243\n",
       "  1   -2.700 -3.935925\n",
       "  2   -2.943 -1.683388\n",
       "  3   -3.451 -4.565446\n",
       "  4   -2.120 -1.385045\n",
       "  ..     ...       ...\n",
       "  44  -4.450 -1.658625\n",
       "  45  -3.171 -5.327078\n",
       "  46  -6.780 -5.431557\n",
       "  47  -4.376 -4.287602\n",
       "  48  -6.860 -6.340462\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 52.41968894004822,\n",
       "  'mean_mse': 1.9348834,\n",
       "  'mean_l1': 1.0578425,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-2): 2 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [8.587383302052816,\n",
       "   3.758803113301595,\n",
       "   3.1692336718241374,\n",
       "   2.279000812768936,\n",
       "   2.0957769711812335,\n",
       "   1.8645179510116576,\n",
       "   1.5630559225877125,\n",
       "   1.3966391722361247,\n",
       "   1.435432747999827,\n",
       "   1.1652323325475058,\n",
       "   1.080753711859385,\n",
       "   0.9931543906529744,\n",
       "   1.0997288982073465,\n",
       "   0.9826721668243408,\n",
       "   0.916241975625356,\n",
       "   1.0499714136123657,\n",
       "   1.0479299187660218,\n",
       "   1.0759918888409932,\n",
       "   0.8767612218856812,\n",
       "   0.8310966332753499,\n",
       "   0.7576993296543757,\n",
       "   1.0173118650913238,\n",
       "   0.8712899923324585,\n",
       "   0.7997681260108948,\n",
       "   0.7846134106318156,\n",
       "   0.8212815046310424,\n",
       "   0.8090949873129527,\n",
       "   0.7731008370717366],\n",
       "  'val_losses': [6.250943422317505,\n",
       "   4.721818447113037,\n",
       "   4.020096778869629,\n",
       "   3.945570230484009,\n",
       "   3.4258311986923218,\n",
       "   3.335711717605591,\n",
       "   2.7151434421539307,\n",
       "   2.506892442703247,\n",
       "   2.2425990104675293,\n",
       "   2.1319350600242615,\n",
       "   1.978590488433838,\n",
       "   1.9215730428695679,\n",
       "   1.8960609436035156,\n",
       "   1.9387415647506714,\n",
       "   1.9115036129951477,\n",
       "   2.3555718660354614,\n",
       "   1.7394391894340515,\n",
       "   1.8358365297317505,\n",
       "   1.905285120010376,\n",
       "   1.992756962776184,\n",
       "   1.8395051956176758,\n",
       "   1.7629833221435547,\n",
       "   2.000391364097595,\n",
       "   1.7866799235343933,\n",
       "   1.8268721103668213,\n",
       "   1.975570559501648,\n",
       "   1.9963564276695251,\n",
       "   1.9696314930915833]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -9.018 -8.507755\n",
       "  1    0.300  0.109815\n",
       "  2   -0.742 -1.086590\n",
       "  3   -1.960 -4.140200\n",
       "  4   -5.190 -5.420179\n",
       "  ..     ...       ...\n",
       "  44  -3.610 -2.908853\n",
       "  45  -4.632 -3.044628\n",
       "  46  -3.620 -2.153583\n",
       "  47  -3.658 -5.334556\n",
       "  48  -6.726 -6.369000\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 30.327579736709595,\n",
       "  'mean_mse': 1.5958734,\n",
       "  'mean_l1': 0.9804559,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-2): 2 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [4.878263465563456,\n",
       "   2.9082256237665813,\n",
       "   1.9798423608144124,\n",
       "   1.9717079798380535,\n",
       "   1.497808289527893,\n",
       "   1.3331233481566112,\n",
       "   0.9747632702191671,\n",
       "   0.8863340854644776,\n",
       "   1.2141563773155213,\n",
       "   0.820662792523702,\n",
       "   0.7227324604988098,\n",
       "   0.7626964410146078],\n",
       "  'val_losses': [5.192086577415466,\n",
       "   3.6693230867385864,\n",
       "   3.9463703632354736,\n",
       "   2.6461649537086487,\n",
       "   4.467209339141846,\n",
       "   2.1221486926078796,\n",
       "   1.8522105813026428,\n",
       "   1.749116063117981,\n",
       "   2.5710731744766235,\n",
       "   1.8213540315628052,\n",
       "   3.1980496644973755,\n",
       "   2.3864749670028687]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.583 -1.145309\n",
       "  1   -2.350 -2.762805\n",
       "  2   -3.590 -4.608755\n",
       "  3   -3.021 -2.556311\n",
       "  4   -3.690 -4.415973\n",
       "  ..     ...       ...\n",
       "  44  -5.400 -4.321492\n",
       "  45  -4.925 -3.930621\n",
       "  46  -8.600 -6.830998\n",
       "  47  -2.281 -3.958100\n",
       "  48  -5.270 -5.151692\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 67.09612202644348,\n",
       "  'mean_mse': 1.3578985,\n",
       "  'mean_l1': 0.90173745,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-3): 3 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.326467927296957,\n",
       "   2.482559005419413,\n",
       "   1.718406351407369,\n",
       "   1.5262416481971741,\n",
       "   1.5840433110793433,\n",
       "   1.2067474961280822,\n",
       "   0.861309798558553,\n",
       "   0.6582589705785116,\n",
       "   0.6755950291951497,\n",
       "   0.7570128122965495,\n",
       "   0.5706423660119374,\n",
       "   0.46009811758995056,\n",
       "   0.42761760552724204,\n",
       "   0.5239246010780334,\n",
       "   0.4072974850734075,\n",
       "   0.3702621142069499,\n",
       "   0.3844461441040039,\n",
       "   0.39115089178085327,\n",
       "   0.37822355528672535,\n",
       "   0.2745784282684326,\n",
       "   0.2523068696260452,\n",
       "   0.4510001758734385],\n",
       "  'val_losses': [6.178978443145752,\n",
       "   4.459656476974487,\n",
       "   5.251240253448486,\n",
       "   2.5708351135253906,\n",
       "   2.1562613248825073,\n",
       "   3.832119941711426,\n",
       "   2.034577250480652,\n",
       "   1.8367100954055786,\n",
       "   1.6920901536941528,\n",
       "   2.2438774704933167,\n",
       "   1.5897027850151062,\n",
       "   1.455044686794281,\n",
       "   1.463554322719574,\n",
       "   2.4716981649398804,\n",
       "   1.3439450860023499,\n",
       "   1.3589411973953247,\n",
       "   1.4701048135757446,\n",
       "   1.7066263556480408,\n",
       "   1.2786208391189575,\n",
       "   1.414912760257721,\n",
       "   1.4807340502738953,\n",
       "   1.7459486722946167]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.094 -2.770552\n",
       "  1   -8.000 -8.449842\n",
       "  2    1.100  0.480943\n",
       "  3   -3.880 -4.637925\n",
       "  4   -1.250 -1.460490\n",
       "  ..     ...       ...\n",
       "  44  -5.915 -4.900552\n",
       "  45  -3.220 -0.903721\n",
       "  46  -1.640 -5.094875\n",
       "  47  -6.780 -5.373189\n",
       "  48  -5.220 -6.152105\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 67.15294289588928,\n",
       "  'mean_mse': 1.9845397,\n",
       "  'mean_l1': 1.0536711,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-3): 3 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.816063797473907,\n",
       "   3.7445706367492675,\n",
       "   3.025188517570496,\n",
       "   2.12819527387619,\n",
       "   1.4901056329409281,\n",
       "   1.257153574625651,\n",
       "   1.2896929502487182,\n",
       "   1.0919327775637309,\n",
       "   0.9588426788647969,\n",
       "   1.0805211385091147,\n",
       "   0.973691189289093,\n",
       "   0.746208377679189,\n",
       "   0.6597419391075771,\n",
       "   0.6105648636817932,\n",
       "   0.7191281199455262,\n",
       "   0.6161365648110707,\n",
       "   0.49366462032000225,\n",
       "   0.4975097457567851,\n",
       "   0.586101371049881,\n",
       "   0.3911643822987874,\n",
       "   0.4205650925636292,\n",
       "   0.5362585802872976],\n",
       "  'val_losses': [4.534105062484741,\n",
       "   4.191439628601074,\n",
       "   3.675475597381592,\n",
       "   2.1681992411613464,\n",
       "   3.52310311794281,\n",
       "   1.9614938497543335,\n",
       "   1.9290031790733337,\n",
       "   2.5511423349380493,\n",
       "   2.0065548419952393,\n",
       "   2.3179529309272766,\n",
       "   3.6436731815338135,\n",
       "   1.8880839347839355,\n",
       "   1.8056584596633911,\n",
       "   1.775826632976532,\n",
       "   2.351127862930298,\n",
       "   1.6320722103118896,\n",
       "   1.7428879737854004,\n",
       "   1.5859425067901611,\n",
       "   1.5429791808128357,\n",
       "   2.064495325088501,\n",
       "   1.574112445116043,\n",
       "   1.5888835191726685]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.950 -2.637586\n",
       "  1   -2.676 -3.245943\n",
       "  2   -2.780 -4.580139\n",
       "  3   -2.160 -1.968611\n",
       "  4   -3.460 -3.206408\n",
       "  ..     ...       ...\n",
       "  44  -3.590 -5.148207\n",
       "  45  -1.899 -1.873390\n",
       "  46  -5.410 -4.564368\n",
       "  47  -4.743 -5.049098\n",
       "  48  -3.880 -4.311445\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 41.33516716957092,\n",
       "  'mean_mse': 1.9395685,\n",
       "  'mean_l1': 1.0772581,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-3): 3 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.636585172017416,\n",
       "   2.5994443893432617,\n",
       "   2.268346079190572,\n",
       "   2.1352316538492837,\n",
       "   1.7783494234085082,\n",
       "   1.2445234974225363,\n",
       "   1.2298425475756327,\n",
       "   0.9785938064257304,\n",
       "   0.6991250395774842,\n",
       "   0.6392668743928274,\n",
       "   0.6412772019704183,\n",
       "   0.5521086782217026,\n",
       "   1.1931379040082295,\n",
       "   0.6439403076966603],\n",
       "  'val_losses': [4.5827178955078125,\n",
       "   4.497818946838379,\n",
       "   3.4302639961242676,\n",
       "   3.2361884117126465,\n",
       "   2.5099308490753174,\n",
       "   3.0705902576446533,\n",
       "   1.9229764342308044,\n",
       "   2.049856424331665,\n",
       "   2.1505799293518066,\n",
       "   2.9261672496795654,\n",
       "   2.3291728496551514,\n",
       "   1.7825175523757935,\n",
       "   2.3829731941223145,\n",
       "   1.8531609177589417]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.190 -5.128437\n",
       "  1   -5.696 -4.719922\n",
       "  2   -2.461 -1.698596\n",
       "  3   -3.590 -4.068463\n",
       "  4   -2.266 -2.364183\n",
       "  ..     ...       ...\n",
       "  44  -7.280 -4.619871\n",
       "  45  -4.743 -4.034987\n",
       "  46  -2.780 -4.406020\n",
       "  47  -1.716 -3.720876\n",
       "  48  -4.799 -3.730475\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 81.3300952911377,\n",
       "  'mean_mse': 1.604228,\n",
       "  'mean_l1': 1.0115969,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.0644592126210535,\n",
       "   3.537302764256795,\n",
       "   3.270408852895101,\n",
       "   2.8156893889109296,\n",
       "   2.5194624582926433,\n",
       "   2.363441220919291,\n",
       "   2.2727659861246745,\n",
       "   2.041830849647522,\n",
       "   2.0676887035369873,\n",
       "   1.7836950421333313,\n",
       "   1.818465002377828,\n",
       "   1.693742326895396,\n",
       "   1.8296783208847045,\n",
       "   1.5622901678085328,\n",
       "   1.5108305056889852,\n",
       "   1.3983483910560608,\n",
       "   1.3866137703259787,\n",
       "   1.3958024342854818,\n",
       "   1.3779924949010214,\n",
       "   1.3103842655817668,\n",
       "   1.3265881339708965,\n",
       "   1.2516834100087484,\n",
       "   1.3250958601633707,\n",
       "   1.2137874563535054,\n",
       "   1.0978931387265523,\n",
       "   1.1807753125826517,\n",
       "   1.0797736326853433,\n",
       "   1.028235904375712,\n",
       "   1.0215441902478537,\n",
       "   1.035858158270518,\n",
       "   1.0709774176279703,\n",
       "   0.9648852586746216,\n",
       "   0.9712653199831645,\n",
       "   1.0478665471076964,\n",
       "   0.9493873834609985,\n",
       "   0.9622929851214092,\n",
       "   0.9838887174924215,\n",
       "   0.882512217760086,\n",
       "   0.9382160147031148,\n",
       "   0.865284659465154,\n",
       "   0.9591603477795919],\n",
       "  'val_losses': [4.889533519744873,\n",
       "   4.215374708175659,\n",
       "   4.177197575569153,\n",
       "   4.149670124053955,\n",
       "   4.156370520591736,\n",
       "   3.916012167930603,\n",
       "   3.919321298599243,\n",
       "   3.8387060165405273,\n",
       "   3.944521903991699,\n",
       "   3.3362174034118652,\n",
       "   3.3663617372512817,\n",
       "   3.453275680541992,\n",
       "   3.0896681547164917,\n",
       "   3.2850258350372314,\n",
       "   2.5970475673675537,\n",
       "   3.1394747495651245,\n",
       "   2.7374187707901,\n",
       "   2.500127077102661,\n",
       "   2.32402765750885,\n",
       "   2.729751467704773,\n",
       "   2.259342312812805,\n",
       "   2.5610169172286987,\n",
       "   2.257150411605835,\n",
       "   2.1722123622894287,\n",
       "   2.5628156661987305,\n",
       "   2.088613271713257,\n",
       "   1.9893751740455627,\n",
       "   2.1605740785598755,\n",
       "   2.0412334203720093,\n",
       "   2.2488404512405396,\n",
       "   1.9829161167144775,\n",
       "   2.109784483909607,\n",
       "   2.3612335920333862,\n",
       "   1.9633069038391113,\n",
       "   2.0301228761672974,\n",
       "   1.8312016129493713,\n",
       "   1.8419369459152222,\n",
       "   2.0715607404708862,\n",
       "   2.2694037556648254,\n",
       "   1.9305616617202759,\n",
       "   1.8568775653839111]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.990 -3.869467\n",
       "  1   -3.171 -5.710913\n",
       "  2   -4.883 -3.993755\n",
       "  3   -3.610 -3.774304\n",
       "  4    0.790  0.050708\n",
       "  ..     ...       ...\n",
       "  44  -2.349 -2.680202\n",
       "  45  -4.402 -5.604983\n",
       "  46  -3.460 -3.095846\n",
       "  47  -4.800 -6.298800\n",
       "  48  -2.160 -3.261268\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 132.1057891845703,\n",
       "  'mean_mse': 1.8801641,\n",
       "  'mean_l1': 1.0269458,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.425293842951457,\n",
       "   3.772551902135213,\n",
       "   3.5652429262797036,\n",
       "   3.412539561589559,\n",
       "   3.254209105173747,\n",
       "   2.99820396900177,\n",
       "   2.9261781374613443,\n",
       "   2.683033307393392,\n",
       "   2.6260818243026733,\n",
       "   2.5876661936442056,\n",
       "   2.5541353861490887,\n",
       "   2.3100507060686746,\n",
       "   2.4511041084925336,\n",
       "   2.2209583123524985,\n",
       "   2.161822136243184,\n",
       "   2.2233110030492145,\n",
       "   2.056052796045939,\n",
       "   2.0065603415171305,\n",
       "   2.019960896174113,\n",
       "   1.955646316210429,\n",
       "   2.1527857542037965,\n",
       "   2.182861097653707,\n",
       "   1.9504278580347696,\n",
       "   1.7769179900487264,\n",
       "   1.7176077286402385,\n",
       "   1.7030574321746825,\n",
       "   1.6606927851835886,\n",
       "   1.7143895467122396,\n",
       "   1.6414988001187643,\n",
       "   1.6793278296788534,\n",
       "   1.6620996236801147,\n",
       "   1.6123846371968586,\n",
       "   1.465557070573171,\n",
       "   1.5712465643882751,\n",
       "   1.5100432793299357,\n",
       "   1.6322625160217286,\n",
       "   1.573420270284017,\n",
       "   1.4055476069450379,\n",
       "   1.4159017125765483,\n",
       "   1.445636010169983,\n",
       "   1.358415949344635,\n",
       "   1.5173105080922444,\n",
       "   1.3364516814549765,\n",
       "   1.301305874188741,\n",
       "   1.5016774455706279,\n",
       "   1.4180739164352416,\n",
       "   1.3739113132158915,\n",
       "   1.29156946738561,\n",
       "   1.3829951206843059,\n",
       "   1.3197045882542928,\n",
       "   1.465583117802938,\n",
       "   1.316797125339508,\n",
       "   1.435081656773885,\n",
       "   1.3147031664848328,\n",
       "   1.2726613839467367,\n",
       "   1.17193284034729,\n",
       "   1.4215825160344442,\n",
       "   1.3278248190879822,\n",
       "   1.2985217054684957,\n",
       "   1.1429409305254619,\n",
       "   1.3678585747877756,\n",
       "   1.227881129582723,\n",
       "   1.4016926447550455,\n",
       "   1.1677274306615193,\n",
       "   1.2094934145609537,\n",
       "   1.1396318554878235,\n",
       "   1.1987533489863078,\n",
       "   1.1188687046368917,\n",
       "   1.2183702349662782,\n",
       "   1.1700251221656799],\n",
       "  'val_losses': [4.782736778259277,\n",
       "   4.979403495788574,\n",
       "   4.929900646209717,\n",
       "   4.329499244689941,\n",
       "   4.630018711090088,\n",
       "   4.919312000274658,\n",
       "   4.06149160861969,\n",
       "   3.964292883872986,\n",
       "   3.9130353927612305,\n",
       "   4.014435291290283,\n",
       "   3.7562999725341797,\n",
       "   3.6415305137634277,\n",
       "   3.5695488452911377,\n",
       "   3.571104049682617,\n",
       "   3.4912716150283813,\n",
       "   3.331940174102783,\n",
       "   3.1051859855651855,\n",
       "   2.9986789226531982,\n",
       "   3.140839695930481,\n",
       "   2.836930274963379,\n",
       "   2.7901623249053955,\n",
       "   2.735975742340088,\n",
       "   2.558424234390259,\n",
       "   2.5721834897994995,\n",
       "   2.512740731239319,\n",
       "   2.470794677734375,\n",
       "   2.352166175842285,\n",
       "   2.5047487020492554,\n",
       "   2.3493489027023315,\n",
       "   2.2809579372406006,\n",
       "   2.2965376377105713,\n",
       "   2.6413872241973877,\n",
       "   2.2746522426605225,\n",
       "   2.154685378074646,\n",
       "   2.1404757499694824,\n",
       "   2.163877844810486,\n",
       "   2.1351712942123413,\n",
       "   2.030775308609009,\n",
       "   2.0003737211227417,\n",
       "   2.110856294631958,\n",
       "   2.0660881400108337,\n",
       "   2.084670305252075,\n",
       "   2.0672271251678467,\n",
       "   1.9505372643470764,\n",
       "   2.011569023132324,\n",
       "   1.8167165517807007,\n",
       "   2.0830752849578857,\n",
       "   1.9875051975250244,\n",
       "   2.0076836943626404,\n",
       "   1.8337643146514893,\n",
       "   1.8403406143188477,\n",
       "   1.8259491324424744,\n",
       "   1.800706148147583,\n",
       "   1.7997957468032837,\n",
       "   1.8715348839759827,\n",
       "   1.8320764899253845,\n",
       "   1.773607313632965,\n",
       "   1.8597811460494995,\n",
       "   1.9160579442977905,\n",
       "   1.8600285053253174,\n",
       "   1.8458684086799622,\n",
       "   2.0485804080963135,\n",
       "   1.71968412399292,\n",
       "   1.7939468622207642,\n",
       "   1.8109198212623596,\n",
       "   1.8051740527153015,\n",
       "   1.8449349999427795,\n",
       "   1.8484301567077637,\n",
       "   1.8562195897102356,\n",
       "   1.8061076998710632]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.349 -3.448602\n",
       "  1   -2.320 -2.964998\n",
       "  2   -4.310 -4.841129\n",
       "  3   -5.270 -4.746887\n",
       "  4   -1.740 -2.871994\n",
       "  ..     ...       ...\n",
       "  44  -1.040 -3.793929\n",
       "  45  -3.220 -2.426378\n",
       "  46  -3.620 -4.841003\n",
       "  47  -2.943 -2.143482\n",
       "  48  -4.328 -5.259115\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 94.19537377357483,\n",
       "  'mean_mse': 2.0843148,\n",
       "  'mean_l1': 1.1808763,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [4.949412743250529,\n",
       "   3.5408843835194905,\n",
       "   3.137946057319641,\n",
       "   2.8983845710754395,\n",
       "   2.773865501085917,\n",
       "   2.512496882677078,\n",
       "   2.4345938046773274,\n",
       "   2.2030829111735026,\n",
       "   2.23712633450826,\n",
       "   2.514849321047465,\n",
       "   2.0058706680933636,\n",
       "   1.9119285186131796,\n",
       "   1.9160886843999227,\n",
       "   1.8108539541562398,\n",
       "   1.790674763917923,\n",
       "   1.7633643865585327,\n",
       "   1.6367267568906148,\n",
       "   1.6782343149185182,\n",
       "   1.8239435116449991,\n",
       "   1.9589574734369914,\n",
       "   1.6111868500709534,\n",
       "   1.5878566026687622,\n",
       "   1.5441763679186502,\n",
       "   1.508432682355245,\n",
       "   1.4955175161361693,\n",
       "   1.680220405260722,\n",
       "   1.4245908300081889,\n",
       "   1.5554547707239788,\n",
       "   1.5877420862515768,\n",
       "   1.4022863030433654,\n",
       "   1.3767687638600667,\n",
       "   1.4345788359642029,\n",
       "   1.3418434460957844,\n",
       "   1.4183772444725036,\n",
       "   1.3625865777333577,\n",
       "   1.3293822844823202,\n",
       "   1.314684808254242,\n",
       "   1.3266791343688964,\n",
       "   1.368805738290151,\n",
       "   1.349348211288452,\n",
       "   1.2491616090138753,\n",
       "   1.351417326927185,\n",
       "   1.2722354213396707,\n",
       "   1.490794054667155,\n",
       "   1.2355007648468017,\n",
       "   1.330396036307017,\n",
       "   1.2138851801554362,\n",
       "   1.1671287357807159,\n",
       "   1.4332426349322],\n",
       "  'val_losses': [4.977959871292114,\n",
       "   4.8421242237091064,\n",
       "   4.174388527870178,\n",
       "   4.669260740280151,\n",
       "   4.222215056419373,\n",
       "   4.245451211929321,\n",
       "   4.024522542953491,\n",
       "   3.894720673561096,\n",
       "   3.606127977371216,\n",
       "   3.48577082157135,\n",
       "   3.640005111694336,\n",
       "   3.4577765464782715,\n",
       "   3.1025688648223877,\n",
       "   3.391739845275879,\n",
       "   2.960137128829956,\n",
       "   2.8601694107055664,\n",
       "   2.6932601928710938,\n",
       "   2.98861563205719,\n",
       "   2.8283324241638184,\n",
       "   2.6738475561141968,\n",
       "   2.750805139541626,\n",
       "   2.754900813102722,\n",
       "   2.5086387991905212,\n",
       "   2.650069236755371,\n",
       "   2.4773471355438232,\n",
       "   2.617887258529663,\n",
       "   3.281464099884033,\n",
       "   2.4425315856933594,\n",
       "   2.5654590129852295,\n",
       "   2.5252562761306763,\n",
       "   2.4775561094284058,\n",
       "   2.473274350166321,\n",
       "   2.400609850883484,\n",
       "   2.487850546836853,\n",
       "   2.3825474977493286,\n",
       "   2.383056402206421,\n",
       "   2.4195362329483032,\n",
       "   2.334934115409851,\n",
       "   2.350837826728821,\n",
       "   2.4039134979248047,\n",
       "   2.3742512464523315,\n",
       "   2.3355518579483032,\n",
       "   2.5497469902038574,\n",
       "   2.4224669337272644,\n",
       "   2.252603828907013,\n",
       "   2.9093191623687744,\n",
       "   2.418065667152405,\n",
       "   2.3487768173217773,\n",
       "   2.5605868101119995]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    0.790 -1.061895\n",
       "  1   -2.943 -2.563870\n",
       "  2   -5.350 -4.956326\n",
       "  3   -4.380 -3.883598\n",
       "  4   -2.780 -3.863433\n",
       "  ..     ...       ...\n",
       "  44  -3.460 -2.780171\n",
       "  45  -4.047 -3.860673\n",
       "  46  -9.332 -8.276530\n",
       "  47  -4.805 -2.503045\n",
       "  48  -4.160 -4.929339\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 48.244731426239014,\n",
       "  'mean_mse': 1.7436559,\n",
       "  'mean_l1': 1.0229492,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1): GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.085850429534912,\n",
       "   3.2604870160420734,\n",
       "   2.567265764872233,\n",
       "   2.169866689046224,\n",
       "   1.7972540934880574,\n",
       "   1.5232500433921814,\n",
       "   1.3006569067637126,\n",
       "   1.248604408899943,\n",
       "   1.2378721555074057,\n",
       "   1.0699207385381062,\n",
       "   0.8739058136940002,\n",
       "   0.8427457491556803,\n",
       "   0.8964125514030457,\n",
       "   0.6972917973995209,\n",
       "   0.8111684123675028,\n",
       "   0.6975494662920634,\n",
       "   0.655014709631602,\n",
       "   0.5384357094764709,\n",
       "   0.6029882689317068,\n",
       "   0.5444504042466481],\n",
       "  'val_losses': [7.373641014099121,\n",
       "   4.534741163253784,\n",
       "   3.8914401531219482,\n",
       "   3.8998074531555176,\n",
       "   3.7296483516693115,\n",
       "   2.6604260206222534,\n",
       "   2.659078598022461,\n",
       "   2.577101707458496,\n",
       "   2.0849318504333496,\n",
       "   1.904001235961914,\n",
       "   1.9987289905548096,\n",
       "   2.282708764076233,\n",
       "   1.8744516372680664,\n",
       "   1.706132173538208,\n",
       "   4.319163918495178,\n",
       "   1.7360519766807556,\n",
       "   1.7765184044837952,\n",
       "   1.5819071531295776,\n",
       "   2.079329490661621,\n",
       "   2.5651168823242188]},\n",
       " {'pred_df':     y_real     y_pred\n",
       "  0   -3.168  -2.560982\n",
       "  1   -4.328  -4.046161\n",
       "  2   -2.982  -2.592783\n",
       "  3   -3.050  -4.222581\n",
       "  4   -1.640  -3.987713\n",
       "  ..     ...        ...\n",
       "  44  -9.332 -11.165266\n",
       "  45  -3.538  -4.377582\n",
       "  46  -3.180  -2.398905\n",
       "  47  -4.173  -4.761044\n",
       "  48  -4.634  -4.165519\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 88.14192914962769,\n",
       "  'mean_mse': 1.3753589,\n",
       "  'mean_l1': 0.92029667,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1): GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.889245478312175,\n",
       "   3.6795402844746907,\n",
       "   2.9227942625681558,\n",
       "   2.5383132219314577,\n",
       "   2.4702754875024158,\n",
       "   2.221409551302592,\n",
       "   1.6806244214375814,\n",
       "   1.7375809987386068,\n",
       "   1.5168711821238199,\n",
       "   1.377865735689799,\n",
       "   1.2952275355656941,\n",
       "   1.1551369508107503,\n",
       "   1.1504334688186646,\n",
       "   1.408559517065684,\n",
       "   1.1807181398073832,\n",
       "   1.0270429293314616,\n",
       "   1.1268373807271321,\n",
       "   1.126700802644094,\n",
       "   0.9490752875804901,\n",
       "   0.8784166961908341,\n",
       "   1.0846178809801736,\n",
       "   0.9513840715090434,\n",
       "   0.8432959854602814,\n",
       "   0.8800001939137777,\n",
       "   0.8409693082173665,\n",
       "   0.7980035384496053,\n",
       "   0.9496914227803548,\n",
       "   1.0872394482294718,\n",
       "   0.7793594459692638,\n",
       "   0.9996283253033956,\n",
       "   0.8567040681838989,\n",
       "   0.817302946249644,\n",
       "   1.0400903979937235,\n",
       "   0.8773759484291077,\n",
       "   0.7107234001159668,\n",
       "   0.7423551042874654,\n",
       "   0.7203515688578288,\n",
       "   0.6669400533040365,\n",
       "   0.7359811882177989],\n",
       "  'val_losses': [7.49429726600647,\n",
       "   4.15656304359436,\n",
       "   4.308865308761597,\n",
       "   3.4719910621643066,\n",
       "   4.0516440868377686,\n",
       "   2.9686818718910217,\n",
       "   2.644051432609558,\n",
       "   2.211903691291809,\n",
       "   2.001396894454956,\n",
       "   3.259691596031189,\n",
       "   1.9716084599494934,\n",
       "   2.0251572132110596,\n",
       "   2.687236785888672,\n",
       "   1.9498193264007568,\n",
       "   1.906601905822754,\n",
       "   1.9625129103660583,\n",
       "   1.7604854702949524,\n",
       "   1.7624158263206482,\n",
       "   1.7568112015724182,\n",
       "   1.7529547214508057,\n",
       "   2.219658136367798,\n",
       "   2.98134982585907,\n",
       "   1.8070380091667175,\n",
       "   1.960777759552002,\n",
       "   2.656954050064087,\n",
       "   1.679039478302002,\n",
       "   1.6394519805908203,\n",
       "   1.7116035223007202,\n",
       "   1.7690414786338806,\n",
       "   1.6604374647140503,\n",
       "   1.7548452615737915,\n",
       "   1.6532649993896484,\n",
       "   2.246589779853821,\n",
       "   1.854886770248413,\n",
       "   1.6260946393013,\n",
       "   2.0416470766067505,\n",
       "   1.6704553365707397,\n",
       "   2.158669888973236,\n",
       "   1.615647554397583]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.590 -4.814781\n",
       "  1   -1.640 -4.451844\n",
       "  2   -5.696 -4.114971\n",
       "  3   -6.680 -6.956791\n",
       "  4    0.522  0.104558\n",
       "  ..     ...       ...\n",
       "  44  -5.400 -3.046467\n",
       "  45  -3.460 -4.520383\n",
       "  46  -3.690 -4.545459\n",
       "  47  -1.740 -4.451844\n",
       "  48  -4.805 -2.665219\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 59.78573203086853,\n",
       "  'mean_mse': 1.5890216,\n",
       "  'mean_l1': 0.9904566,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1): GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.333105786641439,\n",
       "   3.284698232014974,\n",
       "   2.485779579480489,\n",
       "   2.2474241813023883,\n",
       "   1.8258853673934936,\n",
       "   1.61324253877004,\n",
       "   1.700962527592977,\n",
       "   1.2950651446978252,\n",
       "   1.4175028324127197,\n",
       "   1.1140032311280568,\n",
       "   1.012375255425771,\n",
       "   0.9395284414291382,\n",
       "   1.0158114353815715,\n",
       "   0.9482552965482076,\n",
       "   0.8418732861677806,\n",
       "   0.9258081277211507,\n",
       "   0.7968729356924693,\n",
       "   0.8912735005219777,\n",
       "   0.7368832012017568,\n",
       "   0.7928455789883931,\n",
       "   0.8012569526831309,\n",
       "   0.6711375047763188,\n",
       "   0.7060173213481903,\n",
       "   0.6934779345989227,\n",
       "   0.6573545773824055],\n",
       "  'val_losses': [7.0193493366241455,\n",
       "   4.705118775367737,\n",
       "   4.03259539604187,\n",
       "   3.575935125350952,\n",
       "   2.951680064201355,\n",
       "   2.8008954524993896,\n",
       "   3.824078679084778,\n",
       "   2.1597981452941895,\n",
       "   2.5966354608535767,\n",
       "   1.989549458026886,\n",
       "   2.2075838446617126,\n",
       "   2.1091856956481934,\n",
       "   1.9474338293075562,\n",
       "   2.0442625284194946,\n",
       "   2.1351727843284607,\n",
       "   2.3602319955825806,\n",
       "   1.866923451423645,\n",
       "   1.9671719074249268,\n",
       "   2.2768394947052,\n",
       "   1.852624773979187,\n",
       "   1.8983199000358582,\n",
       "   1.852600872516632,\n",
       "   1.8036071062088013,\n",
       "   2.2895675897598267,\n",
       "   1.762439787387848]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    0.300  0.821766\n",
       "  1   -4.380 -3.737290\n",
       "  2   -3.120 -2.203124\n",
       "  3   -4.632 -2.705108\n",
       "  4   -6.680 -7.114135\n",
       "  ..     ...       ...\n",
       "  44  -3.460 -2.822138\n",
       "  45  -3.401 -1.636554\n",
       "  46  -7.280 -3.320555\n",
       "  47  -9.332 -9.261770\n",
       "  48  -2.338 -2.373209\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 40.243985414505005,\n",
       "  'mean_mse': 1.8409495,\n",
       "  'mean_l1': 1.0334929,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [64],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 64)\n",
       "      (1-3): 3 x GCNConv(64, 64)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.921478621164957,\n",
       "   3.3805695533752442,\n",
       "   2.355951356887817,\n",
       "   1.7847785671552023,\n",
       "   1.9688591639200845,\n",
       "   1.4329816738764445,\n",
       "   1.3411994457244873,\n",
       "   1.6111612955729167,\n",
       "   1.0995673934618633,\n",
       "   1.298766303062439,\n",
       "   1.2340537707010906,\n",
       "   0.9383288939793905,\n",
       "   0.9245374798774719,\n",
       "   0.9169966220855713,\n",
       "   0.9011726975440979,\n",
       "   0.8583156188329061,\n",
       "   0.7831290205319722,\n",
       "   0.9174798250198364],\n",
       "  'val_losses': [4.510210275650024,\n",
       "   4.363311052322388,\n",
       "   3.4191945791244507,\n",
       "   2.8857754468917847,\n",
       "   3.9817118644714355,\n",
       "   2.658511996269226,\n",
       "   2.3153860569000244,\n",
       "   1.9351863861083984,\n",
       "   2.071333408355713,\n",
       "   2.547992467880249,\n",
       "   2.247682809829712,\n",
       "   2.1889787912368774,\n",
       "   1.8890631198883057,\n",
       "   2.1112001538276672,\n",
       "   1.9547640085220337,\n",
       "   2.117924451828003,\n",
       "   2.0764463543891907,\n",
       "   3.1718958616256714]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.990 -2.674916\n",
       "  1   -4.402 -4.453613\n",
       "  2   -3.043 -2.720062\n",
       "  3   -5.220 -6.031058\n",
       "  4   -3.590 -4.282947\n",
       "  ..     ...       ...\n",
       "  44  -3.880 -3.814052\n",
       "  45  -3.620 -2.371611\n",
       "  46   1.100  0.145196\n",
       "  47  -2.120 -1.253493\n",
       "  48  -2.281 -2.512279\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 57.468727827072144,\n",
       "  'mean_mse': 1.3890363,\n",
       "  'mean_l1': 0.9292477,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-2): 2 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.57041056950887,\n",
       "   2.9571667035420734,\n",
       "   1.9419193665186565,\n",
       "   2.201305039723714,\n",
       "   1.4294984896977743,\n",
       "   1.1068021774291992,\n",
       "   1.0674439827601114,\n",
       "   0.875285788377126,\n",
       "   1.0560059189796447,\n",
       "   0.6979152202606201,\n",
       "   0.628532596429189,\n",
       "   0.5669588367144267,\n",
       "   0.5391178329785665,\n",
       "   0.9329804519812266,\n",
       "   0.43331381181875867,\n",
       "   0.4279849469661713,\n",
       "   0.4347470819950104,\n",
       "   0.5069070180257161,\n",
       "   0.37968921264012656,\n",
       "   0.3016573568185171],\n",
       "  'val_losses': [5.345263957977295,\n",
       "   4.278628826141357,\n",
       "   3.3929848670959473,\n",
       "   2.4032500982284546,\n",
       "   2.36327588558197,\n",
       "   1.9026752710342407,\n",
       "   2.026625156402588,\n",
       "   1.7795436382293701,\n",
       "   2.0187628269195557,\n",
       "   1.6393779516220093,\n",
       "   1.8185058236122131,\n",
       "   1.8365819454193115,\n",
       "   1.518277108669281,\n",
       "   2.2537275552749634,\n",
       "   1.8534162044525146,\n",
       "   1.9249022603034973,\n",
       "   2.392277956008911,\n",
       "   1.9163323640823364,\n",
       "   1.7185968160629272,\n",
       "   1.5597025752067566]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.925 -4.157102\n",
       "  1   -3.930 -2.106251\n",
       "  2   -5.190 -5.394334\n",
       "  3   -5.915 -4.471602\n",
       "  4   -3.180 -2.838755\n",
       "  ..     ...       ...\n",
       "  44  -5.190 -4.983026\n",
       "  45  -8.000 -8.308099\n",
       "  46  -6.726 -6.720501\n",
       "  47  -4.310 -4.757555\n",
       "  48  -6.860 -6.745210\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 59.35958409309387,\n",
       "  'mean_mse': 1.8720727,\n",
       "  'mean_l1': 1.0377985,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-2): 2 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.172077178955078,\n",
       "   3.5647356033325197,\n",
       "   2.9767056624094645,\n",
       "   2.1520880858103433,\n",
       "   1.7391915162404379,\n",
       "   1.6544248541196187,\n",
       "   1.2658785422643026,\n",
       "   1.2307894786198934,\n",
       "   1.3011102596918742,\n",
       "   1.129083025455475,\n",
       "   1.0715850869814554,\n",
       "   0.8488601764043172,\n",
       "   0.7962860186894735,\n",
       "   0.8783785939216614,\n",
       "   0.7528220256169637,\n",
       "   1.2700981577237447,\n",
       "   0.6204366823037465,\n",
       "   0.5986603875954946,\n",
       "   0.6981779297192892,\n",
       "   0.8630035579204559,\n",
       "   0.6497958819071452],\n",
       "  'val_losses': [6.194053411483765,\n",
       "   4.761253833770752,\n",
       "   4.029978394508362,\n",
       "   3.616931438446045,\n",
       "   2.621457099914551,\n",
       "   3.919649362564087,\n",
       "   2.13657283782959,\n",
       "   2.664306163787842,\n",
       "   2.1295979619026184,\n",
       "   2.990012526512146,\n",
       "   2.0915659070014954,\n",
       "   2.559690833091736,\n",
       "   2.3912702202796936,\n",
       "   2.157921552658081,\n",
       "   1.8145843148231506,\n",
       "   1.748426616191864,\n",
       "   1.9719685912132263,\n",
       "   2.31281054019928,\n",
       "   1.7404351830482483,\n",
       "   1.70188307762146,\n",
       "   2.662437319755554]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    0.790 -0.763751\n",
       "  1   -4.173 -4.309295\n",
       "  2   -2.350 -1.689789\n",
       "  3   -4.120 -4.387368\n",
       "  4   -1.250 -1.011487\n",
       "  ..     ...       ...\n",
       "  44  -4.450 -3.160471\n",
       "  45  -3.168 -2.965822\n",
       "  46  -0.400 -0.828437\n",
       "  47  -2.160 -0.550151\n",
       "  48  -3.021 -4.069745\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 118.68316435813904,\n",
       "  'mean_mse': 1.1413404,\n",
       "  'mean_l1': 0.8306447,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 3,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-2): 2 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.276305929819743,\n",
       "   2.7551814715067544,\n",
       "   2.172399973869324,\n",
       "   1.9111753145853678,\n",
       "   1.5196457942326864,\n",
       "   1.3579975525538126,\n",
       "   1.5912052114804587,\n",
       "   0.8855922063191731,\n",
       "   1.0940584063529968,\n",
       "   0.7260751674572626,\n",
       "   0.7263133565584818,\n",
       "   0.6998354911804199,\n",
       "   0.6764309386412303,\n",
       "   0.7142012059688568,\n",
       "   0.6798917094866435,\n",
       "   0.7001176377137502,\n",
       "   0.5733494689067204,\n",
       "   0.4956848363081614,\n",
       "   0.4717773278554281,\n",
       "   0.4301865334312121,\n",
       "   0.46083070039749147,\n",
       "   0.49675084948539733,\n",
       "   0.5010472734769186,\n",
       "   0.4234298825263977,\n",
       "   0.5054035723209381,\n",
       "   0.5390744686126709,\n",
       "   0.36630011796951295,\n",
       "   0.34781697889169055,\n",
       "   0.38674030900001527,\n",
       "   0.3920864085356394,\n",
       "   0.31417901714642843,\n",
       "   0.3339966545502345,\n",
       "   0.2915983299414317,\n",
       "   0.6654661377271016,\n",
       "   0.26023195683956146,\n",
       "   0.29921746520946424,\n",
       "   0.36377205749352776,\n",
       "   0.2711353619893392,\n",
       "   0.3468029876550039,\n",
       "   0.28550214767456056,\n",
       "   0.21844830587506295,\n",
       "   0.2470493386189143,\n",
       "   0.21954181492328645,\n",
       "   0.22011531790097555,\n",
       "   0.24123812317848206],\n",
       "  'val_losses': [5.147090673446655,\n",
       "   4.569255471229553,\n",
       "   3.9269649982452393,\n",
       "   3.804302453994751,\n",
       "   3.4180679321289062,\n",
       "   2.278719127178192,\n",
       "   3.5853748321533203,\n",
       "   1.8356034755706787,\n",
       "   3.7693684101104736,\n",
       "   2.026527225971222,\n",
       "   1.7707767486572266,\n",
       "   1.9011829197406769,\n",
       "   1.8364561796188354,\n",
       "   1.8727329969406128,\n",
       "   1.7713812589645386,\n",
       "   1.6123420596122742,\n",
       "   1.7464343905448914,\n",
       "   1.570300281047821,\n",
       "   1.680954098701477,\n",
       "   1.6482242941856384,\n",
       "   1.624617099761963,\n",
       "   1.634355366230011,\n",
       "   1.6551965475082397,\n",
       "   1.4700992107391357,\n",
       "   1.3270991146564484,\n",
       "   1.3568106293678284,\n",
       "   1.4277786910533905,\n",
       "   1.3213879466056824,\n",
       "   1.5633885860443115,\n",
       "   1.6209736466407776,\n",
       "   1.355139434337616,\n",
       "   1.4201116561889648,\n",
       "   1.356402337551117,\n",
       "   1.434184730052948,\n",
       "   1.3944816589355469,\n",
       "   1.3057633638381958,\n",
       "   1.4501351714134216,\n",
       "   1.2304680943489075,\n",
       "   1.5037423968315125,\n",
       "   1.2738173007965088,\n",
       "   1.312983512878418,\n",
       "   1.3191908597946167,\n",
       "   1.331243097782135,\n",
       "   1.543928861618042,\n",
       "   1.4745458960533142]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.583 -1.286339\n",
       "  1   -2.281 -2.717685\n",
       "  2   -2.982 -2.771941\n",
       "  3   -4.120 -4.322486\n",
       "  4    1.100 -0.068517\n",
       "  ..     ...       ...\n",
       "  44  -3.220 -2.506079\n",
       "  45  -3.360 -4.309008\n",
       "  46  -5.000 -6.072544\n",
       "  47   0.300  0.003474\n",
       "  48  -6.237 -3.673577\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 54.04732584953308,\n",
       "  'mean_mse': 1.4627488,\n",
       "  'mean_l1': 0.94003797,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-3): 3 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.392179934183757,\n",
       "   2.9941375573476154,\n",
       "   2.342135453224182,\n",
       "   1.7978655735651652,\n",
       "   1.0295830607414245,\n",
       "   1.0734341144561768,\n",
       "   0.9167412837346395,\n",
       "   0.9891850471496582,\n",
       "   0.6672223846117655,\n",
       "   0.6173356990019481,\n",
       "   0.5700449675321579,\n",
       "   0.5376297016938527,\n",
       "   0.5100300133228302,\n",
       "   0.43612816333770754,\n",
       "   0.37960152824719745,\n",
       "   0.5546432415644328,\n",
       "   0.33352035681406655],\n",
       "  'val_losses': [5.952134609222412,\n",
       "   4.129997491836548,\n",
       "   3.5315558910369873,\n",
       "   2.4357837438583374,\n",
       "   2.3901556730270386,\n",
       "   3.158355474472046,\n",
       "   1.8499410152435303,\n",
       "   1.7526260018348694,\n",
       "   2.1594064235687256,\n",
       "   1.8140061497688293,\n",
       "   1.794334053993225,\n",
       "   1.5780407786369324,\n",
       "   1.749314308166504,\n",
       "   1.7574803233146667,\n",
       "   1.9322311282157898,\n",
       "   1.4498639106750488,\n",
       "   1.5028563737869263]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.690 -4.955885\n",
       "  1   -6.860 -6.365164\n",
       "  2   -3.538 -5.352445\n",
       "  3   -5.350 -4.899615\n",
       "  4   -0.600 -0.458876\n",
       "  ..     ...       ...\n",
       "  44  -6.020 -3.653396\n",
       "  45  -3.021 -2.663688\n",
       "  46  -8.040 -7.376993\n",
       "  47  -1.640 -5.354976\n",
       "  48   0.300 -0.360216\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 74.51984000205994,\n",
       "  'mean_mse': 2.1495795,\n",
       "  'mean_l1': 1.0803291,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-3): 3 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.281142139434815,\n",
       "   2.5723173300425213,\n",
       "   2.6445910692214967,\n",
       "   1.6934791723887126,\n",
       "   1.4471424698829651,\n",
       "   1.3115486264228822,\n",
       "   1.4425510068734486,\n",
       "   0.9958810389041901,\n",
       "   1.0863446176052094,\n",
       "   1.0142685810724894,\n",
       "   0.9238508621851603,\n",
       "   0.7390464017788569,\n",
       "   0.6633205711841583,\n",
       "   0.5816135783990224,\n",
       "   0.7364608168601989,\n",
       "   0.7941118995348613,\n",
       "   0.8481314162413279,\n",
       "   0.6581111510594686,\n",
       "   0.584846992790699,\n",
       "   0.6242722441752752,\n",
       "   0.42872954507668815,\n",
       "   0.43431909481684366,\n",
       "   0.44144696891307833,\n",
       "   0.6250213245550792],\n",
       "  'val_losses': [6.413945436477661,\n",
       "   6.712869644165039,\n",
       "   2.8079930543899536,\n",
       "   2.3235036730766296,\n",
       "   2.434917449951172,\n",
       "   2.159362554550171,\n",
       "   2.1662193536758423,\n",
       "   1.8889608979225159,\n",
       "   1.7300578951835632,\n",
       "   1.7710343599319458,\n",
       "   5.544610500335693,\n",
       "   1.7240992784500122,\n",
       "   2.1188965439796448,\n",
       "   1.9505867958068848,\n",
       "   2.312012791633606,\n",
       "   1.661035180091858,\n",
       "   1.6360514760017395,\n",
       "   2.4482617378234863,\n",
       "   1.424003690481186,\n",
       "   1.7657683491706848,\n",
       "   2.3897844552993774,\n",
       "   2.2517741918563843,\n",
       "   1.6814226508140564,\n",
       "   1.620259940624237]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.168 -2.648682\n",
       "  1   -3.043 -3.030872\n",
       "  2   -0.600 -1.135587\n",
       "  3   -3.460 -4.266187\n",
       "  4   -5.350 -5.068391\n",
       "  ..     ...       ...\n",
       "  44  -1.716 -3.345226\n",
       "  45  -4.632 -3.797182\n",
       "  46  -2.160 -0.966319\n",
       "  47  -3.120 -3.147783\n",
       "  48  -4.173 -5.040417\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 74.26049518585205,\n",
       "  'mean_mse': 1.603379,\n",
       "  'mean_l1': 0.9704132,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 4,\n",
       "  'linear_sizes': [512],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1-3): 3 x GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.354712931315104,\n",
       "   3.0367062727610272,\n",
       "   2.113501191139221,\n",
       "   1.8027012904485067,\n",
       "   1.3309707005818685,\n",
       "   1.0446754535039267,\n",
       "   0.9307840983072917,\n",
       "   0.9655680855115255,\n",
       "   0.7512043674786886,\n",
       "   0.7274940848350525,\n",
       "   0.6337849656740825,\n",
       "   0.5040454516808192,\n",
       "   0.49808507760365806,\n",
       "   0.5644235769907634,\n",
       "   0.5112118154764176,\n",
       "   0.6722526331742604,\n",
       "   0.37693359951178235,\n",
       "   0.3531424601872762,\n",
       "   0.33937869071960447,\n",
       "   0.3747556507587433,\n",
       "   0.3230595211187998,\n",
       "   0.2883413498600324,\n",
       "   0.34796959161758423],\n",
       "  'val_losses': [4.717737436294556,\n",
       "   4.056332111358643,\n",
       "   3.513658881187439,\n",
       "   4.1941077709198,\n",
       "   2.7863279581069946,\n",
       "   2.3066391944885254,\n",
       "   1.9875290989875793,\n",
       "   2.144748091697693,\n",
       "   2.397502303123474,\n",
       "   1.8306815028190613,\n",
       "   1.6791594624519348,\n",
       "   2.1745075583457947,\n",
       "   1.7946072816848755,\n",
       "   1.8416088223457336,\n",
       "   1.8123627305030823,\n",
       "   2.1476175785064697,\n",
       "   1.6009905338287354,\n",
       "   1.541029930114746,\n",
       "   1.689861536026001,\n",
       "   1.675083875656128,\n",
       "   1.7323864698410034,\n",
       "   1.6034753322601318,\n",
       "   1.8482192158699036]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.168 -2.790989\n",
       "  1   -5.270 -4.984582\n",
       "  2   -5.000 -5.842559\n",
       "  3   -3.583 -2.310667\n",
       "  4   -3.021 -3.932881\n",
       "  ..     ...       ...\n",
       "  44  -3.050 -3.761748\n",
       "  45  -4.047 -4.485241\n",
       "  46  -0.400 -0.891010\n",
       "  47  -5.270 -5.369308\n",
       "  48  -3.800 -3.807286\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 114.96953773498535,\n",
       "  'mean_mse': 1.469752,\n",
       "  'mean_l1': 0.9646034,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.460893535614014,\n",
       "   3.3053714116414388,\n",
       "   2.996780840555827,\n",
       "   2.7062415281931558,\n",
       "   2.5123700141906737,\n",
       "   2.2644894043604533,\n",
       "   2.0091598550478618,\n",
       "   2.065835404396057,\n",
       "   1.9240055243174234,\n",
       "   1.8749874194463094,\n",
       "   1.7215201218922933,\n",
       "   1.664340321222941,\n",
       "   1.5708036820093791,\n",
       "   1.4914166569709777,\n",
       "   1.657657019297282,\n",
       "   1.6795880953470865,\n",
       "   1.3409617304801942,\n",
       "   1.4764663934707642,\n",
       "   1.5864237944285076,\n",
       "   1.35597163438797,\n",
       "   1.246141827106476,\n",
       "   1.2216541488965353,\n",
       "   1.2492430210113525,\n",
       "   1.3233588616053262,\n",
       "   1.2089020649592082,\n",
       "   1.0759772380193076,\n",
       "   1.0808136860529582,\n",
       "   1.117723858356476,\n",
       "   1.1690441449483235,\n",
       "   1.0012296219666799,\n",
       "   0.9802988409996033,\n",
       "   1.0422899921735127,\n",
       "   0.9331240773200988,\n",
       "   0.9423888981342315,\n",
       "   0.9318444053332011,\n",
       "   0.96583358446757,\n",
       "   0.943009485801061,\n",
       "   0.9883657693862915,\n",
       "   0.8189489583174387,\n",
       "   0.8179605523745219,\n",
       "   0.905906077226003,\n",
       "   0.8915776968002319,\n",
       "   0.8820718546708425,\n",
       "   0.9883418003718059,\n",
       "   0.7611720775564511,\n",
       "   0.7311112622419993,\n",
       "   0.7677103956540425,\n",
       "   0.7068884551525116,\n",
       "   0.7397945900758107,\n",
       "   0.7112533370653789,\n",
       "   0.8529099563757578,\n",
       "   0.7506644686063131,\n",
       "   0.7513755957285563,\n",
       "   0.8362306634585063,\n",
       "   0.6654544730981191,\n",
       "   0.6934340675671895],\n",
       "  'val_losses': [4.721304893493652,\n",
       "   4.2501091957092285,\n",
       "   4.3329176902771,\n",
       "   4.220370411872864,\n",
       "   4.047242879867554,\n",
       "   3.8894773721694946,\n",
       "   3.786988139152527,\n",
       "   3.602694511413574,\n",
       "   3.3813083171844482,\n",
       "   3.239850401878357,\n",
       "   3.260163426399231,\n",
       "   3.0324596166610718,\n",
       "   2.7456244230270386,\n",
       "   2.671657085418701,\n",
       "   2.4684311151504517,\n",
       "   2.932692766189575,\n",
       "   2.5089056491851807,\n",
       "   2.569092094898224,\n",
       "   2.904569387435913,\n",
       "   2.9200559854507446,\n",
       "   2.3567525148391724,\n",
       "   2.2476601600646973,\n",
       "   2.455693483352661,\n",
       "   2.4657965898513794,\n",
       "   2.1544572710990906,\n",
       "   2.199878215789795,\n",
       "   2.112418055534363,\n",
       "   2.1946581602096558,\n",
       "   2.0933507680892944,\n",
       "   2.0663257837295532,\n",
       "   2.0392426252365112,\n",
       "   2.463679552078247,\n",
       "   2.1569467782974243,\n",
       "   1.990294635295868,\n",
       "   2.0220797657966614,\n",
       "   1.9349034428596497,\n",
       "   2.340972065925598,\n",
       "   2.0501492023468018,\n",
       "   1.9596527814865112,\n",
       "   2.295674979686737,\n",
       "   1.9421598315238953,\n",
       "   2.2525304555892944,\n",
       "   1.9055794477462769,\n",
       "   2.042370557785034,\n",
       "   1.9981231689453125,\n",
       "   2.0781830549240112,\n",
       "   1.9023975133895874,\n",
       "   1.995675265789032,\n",
       "   1.9184020161628723,\n",
       "   1.9050199389457703,\n",
       "   2.482667088508606,\n",
       "   1.9485749006271362,\n",
       "   2.4653431177139282,\n",
       "   2.1391139030456543,\n",
       "   1.9644229412078857,\n",
       "   1.7996534705162048]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    0.522  1.215715\n",
       "  1   -3.930 -3.249879\n",
       "  2   -4.160 -5.571055\n",
       "  3   -4.632 -2.987319\n",
       "  4   -3.690 -5.313398\n",
       "  ..     ...       ...\n",
       "  44  -2.676 -3.356917\n",
       "  45  -4.370 -4.183956\n",
       "  46  -3.638 -3.223486\n",
       "  47  -1.960 -5.433923\n",
       "  48  -4.743 -5.492200\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 126.30165219306946,\n",
       "  'mean_mse': 1.8817054,\n",
       "  'mean_l1': 1.0146599,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.394847885767619,\n",
       "   3.8304225126902263,\n",
       "   3.739187542597453,\n",
       "   3.3901585578918456,\n",
       "   3.215804688135783,\n",
       "   3.041636085510254,\n",
       "   3.0208436012268067,\n",
       "   2.7632538159688314,\n",
       "   2.689856831232707,\n",
       "   2.7231632232666017,\n",
       "   2.8343285163243612,\n",
       "   2.6925907452901203,\n",
       "   2.413608916600545,\n",
       "   2.5368046204249066,\n",
       "   2.395000155766805,\n",
       "   2.1470585385958354,\n",
       "   2.2676985343297322,\n",
       "   2.245636208852132,\n",
       "   2.2124742110570272,\n",
       "   2.0310941696166993,\n",
       "   1.9775200764338174,\n",
       "   2.062639896074931,\n",
       "   1.83917133808136,\n",
       "   1.838121755917867,\n",
       "   1.885765806833903,\n",
       "   1.7781473398208618,\n",
       "   1.7223703265190125,\n",
       "   1.816443888346354,\n",
       "   1.7722032149632772,\n",
       "   1.8300199190775552,\n",
       "   1.6487407128016154,\n",
       "   1.867510231335958,\n",
       "   1.8629326979319254,\n",
       "   1.5906405369440715,\n",
       "   1.5501362403233847,\n",
       "   1.5495017131169637,\n",
       "   1.546202834447225,\n",
       "   1.4877070903778076,\n",
       "   1.5647517522176106,\n",
       "   1.4591879367828369,\n",
       "   1.4867590586344401,\n",
       "   1.542919643719991,\n",
       "   1.3613800009091694,\n",
       "   1.3581735809644064,\n",
       "   1.3786582191785177,\n",
       "   1.3962706168492636,\n",
       "   1.5451562722524008,\n",
       "   1.3308836976687113,\n",
       "   1.3233241001764933,\n",
       "   1.3482051610946655,\n",
       "   1.4319624304771423,\n",
       "   1.3869316577911377,\n",
       "   1.2742964545885722,\n",
       "   1.5234782695770264,\n",
       "   1.267130692799886,\n",
       "   1.3423450787862141,\n",
       "   1.2921083887418112,\n",
       "   1.2839564005533854,\n",
       "   1.281571618715922,\n",
       "   1.1923414587974548,\n",
       "   1.3001257757345834,\n",
       "   1.2618585109710694,\n",
       "   1.1680637439092],\n",
       "  'val_losses': [4.96381151676178,\n",
       "   4.383811712265015,\n",
       "   4.515052795410156,\n",
       "   4.327801465988159,\n",
       "   4.7202208042144775,\n",
       "   4.040412783622742,\n",
       "   4.219944715499878,\n",
       "   4.245787858963013,\n",
       "   3.930233359336853,\n",
       "   4.267172813415527,\n",
       "   3.6742721796035767,\n",
       "   4.041872024536133,\n",
       "   3.81680691242218,\n",
       "   3.533230185508728,\n",
       "   3.4895366430282593,\n",
       "   3.2851901054382324,\n",
       "   3.1178672313690186,\n",
       "   3.0662381649017334,\n",
       "   3.272809863090515,\n",
       "   3.011082410812378,\n",
       "   2.911936044692993,\n",
       "   2.980865955352783,\n",
       "   2.9115734100341797,\n",
       "   2.884190082550049,\n",
       "   3.1510647535324097,\n",
       "   2.728224754333496,\n",
       "   2.6615949869155884,\n",
       "   2.4402629137039185,\n",
       "   2.714514970779419,\n",
       "   2.9544286727905273,\n",
       "   2.3784868717193604,\n",
       "   2.5257574915885925,\n",
       "   2.217587113380432,\n",
       "   2.459881901741028,\n",
       "   2.1168872714042664,\n",
       "   2.2383307218551636,\n",
       "   2.1449915170669556,\n",
       "   2.162105143070221,\n",
       "   2.076786756515503,\n",
       "   2.472561836242676,\n",
       "   2.112360119819641,\n",
       "   2.346325635910034,\n",
       "   2.0351349115371704,\n",
       "   2.0943799018859863,\n",
       "   1.9979429244995117,\n",
       "   2.197139024734497,\n",
       "   2.1615136861801147,\n",
       "   2.0967005491256714,\n",
       "   2.3608720302581787,\n",
       "   1.8930200934410095,\n",
       "   1.8975490927696228,\n",
       "   2.106508255004883,\n",
       "   1.8998534679412842,\n",
       "   1.8814623951911926,\n",
       "   1.9449415802955627,\n",
       "   2.3220096230506897,\n",
       "   1.9303457736968994,\n",
       "   1.8850314021110535,\n",
       "   2.1191105246543884,\n",
       "   1.9106283783912659,\n",
       "   1.933988332748413,\n",
       "   1.882604718208313,\n",
       "   1.8425482511520386]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.402 -3.612380\n",
       "  1   -7.280 -5.293952\n",
       "  2   -6.860 -6.899556\n",
       "  3   -5.915 -5.492591\n",
       "  4   -2.920 -2.162036\n",
       "  ..     ...       ...\n",
       "  44  -1.850 -3.623159\n",
       "  45  -9.332 -6.441239\n",
       "  46  -3.290 -4.568270\n",
       "  47  -2.932 -2.076247\n",
       "  48  -4.805 -2.389947\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 104.8253436088562,\n",
       "  'mean_mse': 2.114384,\n",
       "  'mean_l1': 1.1975539,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 1,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [5.240368684132894,\n",
       "   3.3634606838226317,\n",
       "   3.256433931986491,\n",
       "   3.211833349863688,\n",
       "   3.0091402769088744,\n",
       "   2.627226463953654,\n",
       "   2.4162627935409544,\n",
       "   2.535336172580719,\n",
       "   2.2421523571014403,\n",
       "   2.551069990793864,\n",
       "   2.040095778306325,\n",
       "   2.1395307938257853,\n",
       "   1.906940221786499,\n",
       "   1.7997585813204446,\n",
       "   2.214860971768697,\n",
       "   1.7766079266866048,\n",
       "   1.7453355630238852,\n",
       "   1.7316576878229777,\n",
       "   1.8021760304768881,\n",
       "   1.6596229076385498,\n",
       "   1.6068535765012106,\n",
       "   1.659638237953186,\n",
       "   1.6744867324829102,\n",
       "   1.5881659110387167,\n",
       "   1.6131478309631349,\n",
       "   1.6074153582255046,\n",
       "   1.7122745116551716,\n",
       "   1.4981324990590414,\n",
       "   1.479649011294047,\n",
       "   1.5876391251881918,\n",
       "   1.6120713075002036,\n",
       "   1.734814699490865,\n",
       "   1.4918617407480876,\n",
       "   1.3879695455233256,\n",
       "   1.326880391438802,\n",
       "   1.3324152072270712,\n",
       "   1.4399351636568705,\n",
       "   1.5296937187512716,\n",
       "   1.320359989007314,\n",
       "   1.2859510858853658,\n",
       "   1.3071768045425416,\n",
       "   1.3225938399632773,\n",
       "   1.3628857533137004,\n",
       "   1.3775888085365295,\n",
       "   1.2964809934298198,\n",
       "   1.2910879850387573,\n",
       "   1.3004969636599222,\n",
       "   1.3952212611834207,\n",
       "   1.4394694010416667,\n",
       "   1.2544897675514222,\n",
       "   1.2179297010103862,\n",
       "   1.203729546070099,\n",
       "   1.3907559792200723,\n",
       "   1.2828999002774557],\n",
       "  'val_losses': [4.749961614608765,\n",
       "   4.7378928661346436,\n",
       "   4.4295055866241455,\n",
       "   4.260161995887756,\n",
       "   4.602925777435303,\n",
       "   4.214840412139893,\n",
       "   3.865439295768738,\n",
       "   3.884578824043274,\n",
       "   3.6608290672302246,\n",
       "   3.7390451431274414,\n",
       "   3.40845263004303,\n",
       "   3.3721576929092407,\n",
       "   3.4680304527282715,\n",
       "   3.084859013557434,\n",
       "   3.019208312034607,\n",
       "   3.0295435190200806,\n",
       "   3.209122896194458,\n",
       "   2.9431076049804688,\n",
       "   2.7913783192634583,\n",
       "   2.941364288330078,\n",
       "   2.767967939376831,\n",
       "   2.9450416564941406,\n",
       "   2.7717337608337402,\n",
       "   2.857130289077759,\n",
       "   2.7399080991744995,\n",
       "   2.659800171852112,\n",
       "   2.492131233215332,\n",
       "   2.5810598134994507,\n",
       "   2.657240629196167,\n",
       "   2.4388015270233154,\n",
       "   2.596274733543396,\n",
       "   2.3899237513542175,\n",
       "   2.4236090183258057,\n",
       "   2.4331525564193726,\n",
       "   2.404285430908203,\n",
       "   2.498912751674652,\n",
       "   2.298848867416382,\n",
       "   2.3384586572647095,\n",
       "   2.412238597869873,\n",
       "   2.687868118286133,\n",
       "   2.3269673585891724,\n",
       "   2.306063175201416,\n",
       "   2.5395543575286865,\n",
       "   2.2928322553634644,\n",
       "   2.4142276644706726,\n",
       "   2.3791927099227905,\n",
       "   2.5901280641555786,\n",
       "   2.4145487546920776,\n",
       "   2.4218223094940186,\n",
       "   2.283038556575775,\n",
       "   2.2382583022117615,\n",
       "   2.6127272844314575,\n",
       "   2.628291368484497,\n",
       "   2.410444140434265]},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.376 -4.798903\n",
       "  1   -4.173 -5.361185\n",
       "  2   -3.931 -5.588262\n",
       "  3   -1.850 -5.193060\n",
       "  4   -3.460 -2.646344\n",
       "  ..     ...       ...\n",
       "  44  -2.920 -2.462980\n",
       "  45  -3.620 -3.306568\n",
       "  46  -1.040 -3.649411\n",
       "  47  -4.328 -4.714357\n",
       "  48  -3.290 -3.984887\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 77.89772081375122,\n",
       "  'mean_mse': 1.4968114,\n",
       "  'mean_l1': 0.93406403,\n",
       "  'apply_scaffold_split': True,\n",
       "  'hidden_channels': [512],\n",
       "  'gcn_layers': 2,\n",
       "  'linear_sizes': [512, 256],\n",
       "  'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': GCN_molecule_regression(\n",
       "    (convs): ModuleList(\n",
       "      (0): GCNConv(9, 512)\n",
       "      (1): GCNConv(512, 512)\n",
       "    )\n",
       "    (activation1): ReLU()\n",
       "    (activation2): ReLU()\n",
       "    (additional_layers): ModuleList()\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  ),\n",
       "  'losses': [6.025363842646281,\n",
       "   3.306340726216634,\n",
       "   2.411503537495931,\n",
       "   2.09782501856486,\n",
       "   2.44465921719869,\n",
       "   1.7696959137916566,\n",
       "   1.5167040745417277,\n",
       "   1.3924036741256713,\n",
       "   1.8430222193400065,\n",
       "   1.0692598462104796,\n",
       "   1.1132836143175762,\n",
       "   0.8747211337089539,\n",
       "   0.8102204481760661,\n",
       "   0.6917112429936727,\n",
       "   0.6542649189631145,\n",
       "   0.6516758978366852,\n",
       "   0.6722342371940613,\n",
       "   0.6221747438112895,\n",
       "   0.5922537485758463,\n",
       "   0.4692481458187103,\n",
       "   0.5857280095418295,\n",
       "   0.4368754883607229,\n",
       "   0.6104047516981761,\n",
       "   0.685337217648824,\n",
       "   0.44233947346607844,\n",
       "   0.553127912680308,\n",
       "   0.43240635792414345,\n",
       "   0.36499677300453187,\n",
       "   0.3965531011422475,\n",
       "   0.35645262598991395,\n",
       "   0.338143598039945,\n",
       "   0.3337471842765808,\n",
       "   0.2986340383688609,\n",
       "   0.4396439681450526],\n",
       "  'val_losses': [7.2607502937316895,\n",
       "   4.048226475715637,\n",
       "   3.957685351371765,\n",
       "   3.4010661840438843,\n",
       "   3.476060390472412,\n",
       "   4.366774916648865,\n",
       "   2.5412198305130005,\n",
       "   2.870175361633301,\n",
       "   2.754744529724121,\n",
       "   2.2291051149368286,\n",
       "   1.9834312796592712,\n",
       "   1.899929404258728,\n",
       "   2.37980055809021,\n",
       "   2.3740060925483704,\n",
       "   1.7850916385650635,\n",
       "   1.69426691532135,\n",
       "   2.123362183570862,\n",
       "   2.1530656814575195,\n",
       "   3.398077368736267,\n",
       "   1.6331655979156494,\n",
       "   2.0613558888435364,\n",
       "   1.6597541570663452,\n",
       "   2.0104395747184753,\n",
       "   1.6725523471832275,\n",
       "   1.8327799439430237,\n",
       "   1.526016891002655,\n",
       "   1.5986722111701965,\n",
       "   1.9450883269309998,\n",
       "   2.083912491798401,\n",
       "   1.5103115439414978,\n",
       "   2.6140899658203125,\n",
       "   1.8584682941436768,\n",
       "   1.5490697622299194,\n",
       "   2.283315658569336]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = file1_load[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_df':     y_real    y_pred\n",
       " 0   -8.040 -5.336251\n",
       " 1   -3.094 -2.698454\n",
       " 2   -3.610 -2.995411\n",
       " 3   -3.060 -2.598282\n",
       " 4   -5.270 -4.742428\n",
       " ..     ...       ...\n",
       " 44  -4.402 -4.356841\n",
       " 45  -5.190 -3.900764\n",
       " 46  -3.290 -4.809336\n",
       " 47  -2.920 -1.933442\n",
       " 48  -1.960 -3.735151\n",
       " \n",
       " [113 rows x 2 columns],\n",
       " 'el_time': 128.49914526939392,\n",
       " 'mean_mse': 1.8223633,\n",
       " 'mean_l1': 1.0543776,\n",
       " 'apply_scaffold_split': True,\n",
       " 'hidden_channels': [64],\n",
       " 'gcn_layers': 1,\n",
       " 'linear_sizes': [],\n",
       " 'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       " 'apply_random_aggregations': False,\n",
       " 'learning_rate': 0.001,\n",
       " 'model_type': 'GNN',\n",
       " 'model': GCN_molecule_regression(\n",
       "   (convs): ModuleList(\n",
       "     (0): GCNConv(9, 64)\n",
       "   )\n",
       "   (activation1): ReLU()\n",
       "   (activation2): ReLU()\n",
       "   (additional_layers): ModuleList()\n",
       "   (out): Linear(in_features=128, out_features=1, bias=True)\n",
       " ),\n",
       " 'losses': [10.245486164093018,\n",
       "  3.849641434351603,\n",
       "  3.633398485183716,\n",
       "  3.4766549110412597,\n",
       "  3.339778693517049,\n",
       "  3.5214232842127484,\n",
       "  3.2416025002797446,\n",
       "  2.9120702385902404,\n",
       "  2.816925279299418,\n",
       "  2.808077510197957,\n",
       "  2.6306906859079997,\n",
       "  2.606770881017049,\n",
       "  2.6311336517333985,\n",
       "  2.7143933614095053,\n",
       "  2.6068966229756674,\n",
       "  2.2894060055414838,\n",
       "  2.262121494611104,\n",
       "  2.2059902350107827,\n",
       "  2.1610281626383463,\n",
       "  2.1791641394297283,\n",
       "  2.085332091649373,\n",
       "  2.0199548403422036,\n",
       "  1.9446157018343608,\n",
       "  1.8561254223187764,\n",
       "  2.0748777548472086,\n",
       "  1.8563391129175821,\n",
       "  1.8418890317281087,\n",
       "  1.8521492242813111,\n",
       "  1.7990753253300984,\n",
       "  1.7074095010757446,\n",
       "  1.9949644843737284,\n",
       "  1.7774877945582073,\n",
       "  1.6270771503448487,\n",
       "  1.6270374139149983,\n",
       "  1.5656809409459431,\n",
       "  1.57162051598231,\n",
       "  1.6783667008082073,\n",
       "  1.617337457338969,\n",
       "  1.4464350779851278,\n",
       "  1.4525826692581176,\n",
       "  1.5193050980567933,\n",
       "  1.522053631146749,\n",
       "  1.4185364683469137,\n",
       "  1.4243167042732239,\n",
       "  1.39568084081014,\n",
       "  1.363304030895233,\n",
       "  1.3865405082702638,\n",
       "  1.4009225726127625,\n",
       "  1.4180922945340475,\n",
       "  1.3560147205988566,\n",
       "  1.2944121440251668,\n",
       "  1.3145299514134725,\n",
       "  1.3101358532905578,\n",
       "  1.248644999663035,\n",
       "  1.2321911056836445,\n",
       "  1.271419676144918,\n",
       "  1.1820587933063507,\n",
       "  1.415858018398285,\n",
       "  1.2401572704315185,\n",
       "  1.2433702985445658,\n",
       "  1.1960076014200847,\n",
       "  1.4211961348851523,\n",
       "  1.1815643032391867,\n",
       "  1.2196959614753724,\n",
       "  1.1699199000994365,\n",
       "  1.2902218461036683,\n",
       "  1.0983460863431296,\n",
       "  1.1357225974400837,\n",
       "  1.1272162556648255,\n",
       "  1.1050981998443603,\n",
       "  1.2107107957204184,\n",
       "  1.1125417470932006,\n",
       "  1.1203450481096904],\n",
       " 'val_losses': [9.414766788482666,\n",
       "  4.771497964859009,\n",
       "  4.543305158615112,\n",
       "  4.523425817489624,\n",
       "  4.411806106567383,\n",
       "  4.129918694496155,\n",
       "  4.248782396316528,\n",
       "  4.1452189683914185,\n",
       "  4.371139287948608,\n",
       "  4.2445409297943115,\n",
       "  4.247758150100708,\n",
       "  4.2427321672439575,\n",
       "  3.9053685665130615,\n",
       "  3.9647570848464966,\n",
       "  4.206765413284302,\n",
       "  4.0055296421051025,\n",
       "  3.738456964492798,\n",
       "  3.864161491394043,\n",
       "  3.8042213916778564,\n",
       "  3.7483909130096436,\n",
       "  3.570444703102112,\n",
       "  3.624173641204834,\n",
       "  3.356778144836426,\n",
       "  3.368768334388733,\n",
       "  3.3618701696395874,\n",
       "  3.208799719810486,\n",
       "  3.183034300804138,\n",
       "  3.065619111061096,\n",
       "  3.0749263763427734,\n",
       "  3.2763105630874634,\n",
       "  2.8235484957695007,\n",
       "  3.0142343044281006,\n",
       "  2.863064169883728,\n",
       "  2.9550375938415527,\n",
       "  2.9008709192276,\n",
       "  3.053530693054199,\n",
       "  2.6746084690093994,\n",
       "  2.72660493850708,\n",
       "  3.1129775047302246,\n",
       "  2.633130192756653,\n",
       "  2.8202348947525024,\n",
       "  2.963721513748169,\n",
       "  2.851326107978821,\n",
       "  2.7047502994537354,\n",
       "  2.524585485458374,\n",
       "  2.7012192010879517,\n",
       "  2.458508014678955,\n",
       "  2.5134702920913696,\n",
       "  2.4972957372665405,\n",
       "  2.791144847869873,\n",
       "  2.6746705770492554,\n",
       "  2.313979923725128,\n",
       "  2.31086802482605,\n",
       "  2.604888677597046,\n",
       "  2.4409942030906677,\n",
       "  2.5828351974487305,\n",
       "  2.2431362867355347,\n",
       "  2.3486424684524536,\n",
       "  2.2528598308563232,\n",
       "  2.5660794973373413,\n",
       "  2.2910666465759277,\n",
       "  2.3367894887924194,\n",
       "  2.486027240753174,\n",
       "  2.162380337715149,\n",
       "  2.294910192489624,\n",
       "  2.1547319293022156,\n",
       "  2.3537654876708984,\n",
       "  2.053794801235199,\n",
       "  2.2453209161758423,\n",
       "  2.093329071998596,\n",
       "  2.145702600479126,\n",
       "  2.3778370022773743,\n",
       "  2.1022821068763733]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_real</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.040</td>\n",
       "      <td>-5.336251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.094</td>\n",
       "      <td>-2.698454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.610</td>\n",
       "      <td>-2.995411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.060</td>\n",
       "      <td>-2.598282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.270</td>\n",
       "      <td>-4.742428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-4.402</td>\n",
       "      <td>-4.356841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-5.190</td>\n",
       "      <td>-3.900764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-3.290</td>\n",
       "      <td>-4.809336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-2.920</td>\n",
       "      <td>-1.933442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-1.960</td>\n",
       "      <td>-3.735151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_real    y_pred\n",
       "0   -8.040 -5.336251\n",
       "1   -3.094 -2.698454\n",
       "2   -3.610 -2.995411\n",
       "3   -3.060 -2.598282\n",
       "4   -5.270 -4.742428\n",
       "..     ...       ...\n",
       "44  -4.402 -4.356841\n",
       "45  -5.190 -3.900764\n",
       "46  -3.290 -4.809336\n",
       "47  -2.920 -1.933442\n",
       "48  -1.960 -3.735151\n",
       "\n",
       "[113 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff[\"pred_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_df':     y_real    y_pred\n",
       " 0   -8.040 -5.336251\n",
       " 1   -3.094 -2.698454\n",
       " 2   -3.610 -2.995411\n",
       " 3   -3.060 -2.598282\n",
       " 4   -5.270 -4.742428\n",
       " ..     ...       ...\n",
       " 44  -4.402 -4.356841\n",
       " 45  -5.190 -3.900764\n",
       " 46  -3.290 -4.809336\n",
       " 47  -2.920 -1.933442\n",
       " 48  -1.960 -3.735151\n",
       " \n",
       " [113 rows x 2 columns],\n",
       " 'el_time': 128.49914526939392,\n",
       " 'mean_mse': 1.8223633,\n",
       " 'mean_l1': 1.0543776,\n",
       " 'apply_scaffold_split': True,\n",
       " 'hidden_channels': [64],\n",
       " 'gcn_layers': 1,\n",
       " 'linear_sizes': [],\n",
       " 'aggregations': ['global_mean_pool', 'global_max_pool'],\n",
       " 'apply_random_aggregations': False,\n",
       " 'learning_rate': 0.001,\n",
       " 'model_type': 'GNN',\n",
       " 'model': GCN_molecule_regression(\n",
       "   (convs): ModuleList(\n",
       "     (0): GCNConv(9, 64)\n",
       "   )\n",
       "   (activation1): ReLU()\n",
       "   (activation2): ReLU()\n",
       "   (additional_layers): ModuleList()\n",
       "   (out): Linear(in_features=128, out_features=1, bias=True)\n",
       " ),\n",
       " 'losses': [10.245486164093018,\n",
       "  3.849641434351603,\n",
       "  3.633398485183716,\n",
       "  3.4766549110412597,\n",
       "  3.339778693517049,\n",
       "  3.5214232842127484,\n",
       "  3.2416025002797446,\n",
       "  2.9120702385902404,\n",
       "  2.816925279299418,\n",
       "  2.808077510197957,\n",
       "  2.6306906859079997,\n",
       "  2.606770881017049,\n",
       "  2.6311336517333985,\n",
       "  2.7143933614095053,\n",
       "  2.6068966229756674,\n",
       "  2.2894060055414838,\n",
       "  2.262121494611104,\n",
       "  2.2059902350107827,\n",
       "  2.1610281626383463,\n",
       "  2.1791641394297283,\n",
       "  2.085332091649373,\n",
       "  2.0199548403422036,\n",
       "  1.9446157018343608,\n",
       "  1.8561254223187764,\n",
       "  2.0748777548472086,\n",
       "  1.8563391129175821,\n",
       "  1.8418890317281087,\n",
       "  1.8521492242813111,\n",
       "  1.7990753253300984,\n",
       "  1.7074095010757446,\n",
       "  1.9949644843737284,\n",
       "  1.7774877945582073,\n",
       "  1.6270771503448487,\n",
       "  1.6270374139149983,\n",
       "  1.5656809409459431,\n",
       "  1.57162051598231,\n",
       "  1.6783667008082073,\n",
       "  1.617337457338969,\n",
       "  1.4464350779851278,\n",
       "  1.4525826692581176,\n",
       "  1.5193050980567933,\n",
       "  1.522053631146749,\n",
       "  1.4185364683469137,\n",
       "  1.4243167042732239,\n",
       "  1.39568084081014,\n",
       "  1.363304030895233,\n",
       "  1.3865405082702638,\n",
       "  1.4009225726127625,\n",
       "  1.4180922945340475,\n",
       "  1.3560147205988566,\n",
       "  1.2944121440251668,\n",
       "  1.3145299514134725,\n",
       "  1.3101358532905578,\n",
       "  1.248644999663035,\n",
       "  1.2321911056836445,\n",
       "  1.271419676144918,\n",
       "  1.1820587933063507,\n",
       "  1.415858018398285,\n",
       "  1.2401572704315185,\n",
       "  1.2433702985445658,\n",
       "  1.1960076014200847,\n",
       "  1.4211961348851523,\n",
       "  1.1815643032391867,\n",
       "  1.2196959614753724,\n",
       "  1.1699199000994365,\n",
       "  1.2902218461036683,\n",
       "  1.0983460863431296,\n",
       "  1.1357225974400837,\n",
       "  1.1272162556648255,\n",
       "  1.1050981998443603,\n",
       "  1.2107107957204184,\n",
       "  1.1125417470932006,\n",
       "  1.1203450481096904],\n",
       " 'val_losses': [9.414766788482666,\n",
       "  4.771497964859009,\n",
       "  4.543305158615112,\n",
       "  4.523425817489624,\n",
       "  4.411806106567383,\n",
       "  4.129918694496155,\n",
       "  4.248782396316528,\n",
       "  4.1452189683914185,\n",
       "  4.371139287948608,\n",
       "  4.2445409297943115,\n",
       "  4.247758150100708,\n",
       "  4.2427321672439575,\n",
       "  3.9053685665130615,\n",
       "  3.9647570848464966,\n",
       "  4.206765413284302,\n",
       "  4.0055296421051025,\n",
       "  3.738456964492798,\n",
       "  3.864161491394043,\n",
       "  3.8042213916778564,\n",
       "  3.7483909130096436,\n",
       "  3.570444703102112,\n",
       "  3.624173641204834,\n",
       "  3.356778144836426,\n",
       "  3.368768334388733,\n",
       "  3.3618701696395874,\n",
       "  3.208799719810486,\n",
       "  3.183034300804138,\n",
       "  3.065619111061096,\n",
       "  3.0749263763427734,\n",
       "  3.2763105630874634,\n",
       "  2.8235484957695007,\n",
       "  3.0142343044281006,\n",
       "  2.863064169883728,\n",
       "  2.9550375938415527,\n",
       "  2.9008709192276,\n",
       "  3.053530693054199,\n",
       "  2.6746084690093994,\n",
       "  2.72660493850708,\n",
       "  3.1129775047302246,\n",
       "  2.633130192756653,\n",
       "  2.8202348947525024,\n",
       "  2.963721513748169,\n",
       "  2.851326107978821,\n",
       "  2.7047502994537354,\n",
       "  2.524585485458374,\n",
       "  2.7012192010879517,\n",
       "  2.458508014678955,\n",
       "  2.5134702920913696,\n",
       "  2.4972957372665405,\n",
       "  2.791144847869873,\n",
       "  2.6746705770492554,\n",
       "  2.313979923725128,\n",
       "  2.31086802482605,\n",
       "  2.604888677597046,\n",
       "  2.4409942030906677,\n",
       "  2.5828351974487305,\n",
       "  2.2431362867355347,\n",
       "  2.3486424684524536,\n",
       "  2.2528598308563232,\n",
       "  2.5660794973373413,\n",
       "  2.2910666465759277,\n",
       "  2.3367894887924194,\n",
       "  2.486027240753174,\n",
       "  2.162380337715149,\n",
       "  2.294910192489624,\n",
       "  2.1547319293022156,\n",
       "  2.3537654876708984,\n",
       "  2.053794801235199,\n",
       "  2.2453209161758423,\n",
       "  2.093329071998596,\n",
       "  2.145702600479126,\n",
       "  2.3778370022773743,\n",
       "  2.1022821068763733]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_extract = ['hidden_channels', 'gcn_layers', 'linear_sizes', 'aggregations']\n",
    "\n",
    "plot1 = []\n",
    "for run in file1_load:\n",
    "    lossvalue_mse = run[\"mean_mse\"]\n",
    "    lossvalue_l1 = run[\"mean_l1\"]\n",
    "    \n",
    "    extracted_dict = {key: run[key] for key in keys_to_extract if key in run}\n",
    "    extracted_dict[\"lossvalue_mse\"] = lossvalue_mse\n",
    "    extracted_dict[\"lossvalue_l1\"] = lossvalue_l1\n",
    "    df = pd.DataFrame([extracted_dict])\n",
    "    #plot1.append([lossvalue, df])\n",
    "    plot1.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[  hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           1           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.822363      1.054378  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           1           []  [global_mean_pool]       1.774046   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0       1.00009  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           4           []  [global_mean_pool]       2.427783   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0       1.16823  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           2   [512, 256]  [global_mean_pool]       1.853513   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.997915  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           2   [512, 256]  [global_max_pool]       1.677117   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.026187  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           3   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]        1.30449      0.891201  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           3   [512, 256]  [global_mean_pool]       1.736525   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.027164  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           3   [512, 256]  [global_max_pool]       1.320622   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.923801  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           4   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.317651      0.891474  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           4   [512, 256]  [global_mean_pool]       1.826213   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.004823  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           4   [512, 256]  [global_max_pool]       1.545086   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.942401  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           4           []  [global_max_pool]       1.903641   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.080142  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           1        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.982429      1.135471  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           1        [512]  [global_mean_pool]       1.981134   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.072147  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           1        [512]  [global_max_pool]       2.734133   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.282376  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           2        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.847012      1.053907  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           2        [512]  [global_mean_pool]       2.194327   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.098116  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           2        [512]  [global_max_pool]       1.639046   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0       0.97821  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           3        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.869264      1.071124  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           3        [512]  [global_mean_pool]       1.718177   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.025834  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           1           []  [global_max_pool]       3.061537   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.350474  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           3        [512]  [global_max_pool]       1.952973   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.107383  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           4        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.782694      1.063235  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           4        [512]  [global_mean_pool]       1.663829   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.983118  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           4        [512]  [global_max_pool]       1.667042   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.003995  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           1   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]        1.87908      1.070802  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           1   [512, 256]  [global_mean_pool]       2.007505   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.079502  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           1   [512, 256]  [global_max_pool]        3.70488   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.422107  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           2   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.851332      1.074543  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           2   [512, 256]  [global_mean_pool]       1.966939   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.052555  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           2   [512, 256]  [global_max_pool]        1.72989   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.014345  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           2           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.859373      1.069263  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           3   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.794477      1.029742  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           3   [512, 256]  [global_mean_pool]       1.998079   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0       1.04386  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           3   [512, 256]  [global_max_pool]       1.991922   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.093257  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           4   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.810129      1.021747  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           4   [512, 256]  [global_mean_pool]       1.864664   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.972548  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           4   [512, 256]  [global_max_pool]       1.742396   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.045283  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           1           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.647135      1.013511  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           1           []  [global_mean_pool]       1.789288   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.988432  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           1           []  [global_max_pool]       2.032514   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.137989  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           2           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.409926      0.945727  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           2           []  [global_mean_pool]       1.891909   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0       1.03702  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           2           []  [global_mean_pool]       2.009363   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.069059  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           2           []  [global_max_pool]       1.601146   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.988182  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           3           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.800985      1.043071  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           3           []  [global_mean_pool]       1.712613   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.020882  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           3           []  [global_max_pool]       1.559103   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.964162  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           4           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.344558       0.91735  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           4           []  [global_mean_pool]       1.542044   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.952549  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           4           []  [global_max_pool]       1.412543   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.918208  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           1        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.861713      1.077506  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           1        [512]  [global_mean_pool]       1.951656   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.048711  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           2           []  [global_max_pool]       1.694059   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.007994  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           1        [512]  [global_max_pool]       3.569377   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.390494  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           2        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.382416      0.919353  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           2        [512]  [global_mean_pool]       1.836079   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0       1.03455  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           2        [512]  [global_max_pool]       1.574251   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.988541  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           3        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.508131      0.984268  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           3        [512]  [global_mean_pool]       1.646032   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.985311  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           3        [512]  [global_max_pool]       1.785904   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.038566  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           4        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.506695      0.919771  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           4        [512]  [global_mean_pool]       1.801419   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.023469  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           4        [512]  [global_max_pool]       1.319729   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.892361  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           3           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.726943      1.032046  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           1   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.514382      0.976927  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           1   [512, 256]  [global_mean_pool]       1.822558   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.006681  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           1   [512, 256]  [global_max_pool]       2.340199   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.216415  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           2   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.651778      1.006659  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           2   [512, 256]  [global_mean_pool]       1.856957   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.077828  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           2   [512, 256]  [global_max_pool]       1.603891   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.967442  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           3   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.674085      1.020093  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           3   [512, 256]  [global_mean_pool]       1.703026   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.007167  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           3   [512, 256]  [global_max_pool]       1.471861   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.971736  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [256]           4   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.560182      0.975383  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0            [64]           3           []  [global_mean_pool]       2.019315   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0        1.0633  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [256]           4   [512, 256]  [global_mean_pool]       1.735936   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.021627  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [256]           4   [512, 256]  [global_max_pool]       1.847809   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.043497  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           1           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.607848      1.016571  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           1           []  [global_mean_pool]       1.844461   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0       1.00636  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           1           []  [global_max_pool]       2.182305   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.189816  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           2           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.640213      0.977738  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           2           []  [global_mean_pool]       1.895043   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.078867  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           2           []  [global_max_pool]       1.621399   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.006339  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           3           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]        1.45915      0.945975  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           3           []  [global_mean_pool]       1.531404   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.957719  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0            [64]           3           []  [global_max_pool]       1.934883   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.057842  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           3           []  [global_max_pool]       1.595873   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.980456  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           4           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.357898      0.901737  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           4           []  [global_mean_pool]        1.98454   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.053671  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           4           []  [global_max_pool]       1.939569   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.077258  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           1        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.604228      1.011597  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           1        [512]  [global_mean_pool]       1.880164   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.026946  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           1        [512]  [global_max_pool]       2.084315   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.180876  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           2        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.743656      1.022949  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           2        [512]  [global_mean_pool]       1.375359   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.920297  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           2        [512]  [global_max_pool]       1.589022   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.990457  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0            [64]           4           []   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]        1.84095      1.033493  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           3        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.389036      0.929248  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           3        [512]  [global_mean_pool]       1.872073   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.037799  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           3        [512]  [global_max_pool]        1.14134   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.830645  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           4        [512]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.462749      0.940038  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           4        [512]  [global_mean_pool]        2.14958   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.080329  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           4        [512]  [global_max_pool]       1.603379   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.970413  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           1   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.469752      0.964603  ,\n",
       "   hidden_channels  gcn_layers linear_sizes        aggregations  lossvalue_mse  \\\n",
       " 0           [512]           1   [512, 256]  [global_mean_pool]       1.881705   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0       1.01466  ,\n",
       "   hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       " 0           [512]           1   [512, 256]  [global_max_pool]       2.114384   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.197554  ,\n",
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       " 0           [512]           2   [512, 256]   \n",
       " \n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       " 0  [global_mean_pool, global_max_pool]       1.496811      0.934064  ]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_channels</th>\n",
       "      <th>gcn_layers</th>\n",
       "      <th>linear_sizes</th>\n",
       "      <th>aggregations</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.677117</td>\n",
       "      <td>1.026187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hidden_channels  gcn_layers linear_sizes       aggregations  lossvalue_mse  \\\n",
       "0           [512]           2   [512, 256]  [global_max_pool]       1.677117   \n",
       "\n",
       "   lossvalue_l1  \n",
       "0      1.026187  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot1[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullplot1 = pd.concat(plot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_channels</th>\n",
       "      <th>gcn_layers</th>\n",
       "      <th>linear_sizes</th>\n",
       "      <th>aggregations</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.822363</td>\n",
       "      <td>1.054378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.774046</td>\n",
       "      <td>1.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.427783</td>\n",
       "      <td>1.168230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.853513</td>\n",
       "      <td>0.997915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.677117</td>\n",
       "      <td>1.026187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.603379</td>\n",
       "      <td>0.970413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.469752</td>\n",
       "      <td>0.964603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.881705</td>\n",
       "      <td>1.014660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.114384</td>\n",
       "      <td>1.197554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.496811</td>\n",
       "      <td>0.934064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       "0             [64]           1           []   \n",
       "0             [64]           1           []   \n",
       "0             [64]           4           []   \n",
       "0            [512]           2   [512, 256]   \n",
       "0            [512]           2   [512, 256]   \n",
       "..             ...         ...          ...   \n",
       "0            [512]           4        [512]   \n",
       "0            [512]           1   [512, 256]   \n",
       "0            [512]           1   [512, 256]   \n",
       "0            [512]           1   [512, 256]   \n",
       "0            [512]           2   [512, 256]   \n",
       "\n",
       "                           aggregations  lossvalue_mse  lossvalue_l1  \n",
       "0   [global_mean_pool, global_max_pool]       1.822363      1.054378  \n",
       "0                    [global_mean_pool]       1.774046      1.000090  \n",
       "0                    [global_mean_pool]       2.427783      1.168230  \n",
       "0                    [global_mean_pool]       1.853513      0.997915  \n",
       "0                     [global_max_pool]       1.677117      1.026187  \n",
       "..                                  ...            ...           ...  \n",
       "0                     [global_max_pool]       1.603379      0.970413  \n",
       "0   [global_mean_pool, global_max_pool]       1.469752      0.964603  \n",
       "0                    [global_mean_pool]       1.881705      1.014660  \n",
       "0                     [global_max_pool]       2.114384      1.197554  \n",
       "0   [global_mean_pool, global_max_pool]       1.496811      0.934064  \n",
       "\n",
       "[108 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            []\n",
       "0            []\n",
       "0            []\n",
       "0    [512, 256]\n",
       "0    [512, 256]\n",
       "        ...    \n",
       "0         [512]\n",
       "0    [512, 256]\n",
       "0    [512, 256]\n",
       "0    [512, 256]\n",
       "0    [512, 256]\n",
       "Name: linear_sizes, Length: 108, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1['linear_sizes'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['global_mean_pool', 'global_max_pool']\n",
       "0                       ['global_mean_pool']\n",
       "0                       ['global_mean_pool']\n",
       "0                       ['global_mean_pool']\n",
       "0                        ['global_max_pool']\n",
       "                      ...                   \n",
       "0                        ['global_max_pool']\n",
       "0    ['global_mean_pool', 'global_max_pool']\n",
       "0                       ['global_mean_pool']\n",
       "0                        ['global_max_pool']\n",
       "0    ['global_mean_pool', 'global_max_pool']\n",
       "Name: aggregations, Length: 108, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1['aggregations'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_channels</th>\n",
       "      <th>gcn_layers</th>\n",
       "      <th>linear_sizes</th>\n",
       "      <th>aggregations</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.054378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.168230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>0.997915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.026187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>0.970413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>0.964603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.014660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.197554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>0.934064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hidden_channels  gcn_layers linear_sizes  \\\n",
       "0             [64]           1           []   \n",
       "0             [64]           1           []   \n",
       "0             [64]           4           []   \n",
       "0            [512]           2   [512, 256]   \n",
       "0            [512]           2   [512, 256]   \n",
       "..             ...         ...          ...   \n",
       "0            [512]           4        [512]   \n",
       "0            [512]           1   [512, 256]   \n",
       "0            [512]           1   [512, 256]   \n",
       "0            [512]           1   [512, 256]   \n",
       "0            [512]           2   [512, 256]   \n",
       "\n",
       "                           aggregations  lossvalue_l1  \n",
       "0   [global_mean_pool, global_max_pool]      1.054378  \n",
       "0                    [global_mean_pool]      1.000090  \n",
       "0                    [global_mean_pool]      1.168230  \n",
       "0                    [global_mean_pool]      0.997915  \n",
       "0                     [global_max_pool]      1.026187  \n",
       "..                                  ...           ...  \n",
       "0                     [global_max_pool]      0.970413  \n",
       "0   [global_mean_pool, global_max_pool]      0.964603  \n",
       "0                    [global_mean_pool]      1.014660  \n",
       "0                     [global_max_pool]      1.197554  \n",
       "0   [global_mean_pool, global_max_pool]      0.934064  \n",
       "\n",
       "[108 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1.drop(columns=\"lossvalue_mse\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.822363\n",
       "0    1.774046\n",
       "0    2.427783\n",
       "0    1.853513\n",
       "0    1.677117\n",
       "       ...   \n",
       "0    1.603379\n",
       "0    1.469752\n",
       "0    1.881705\n",
       "0    2.114384\n",
       "0    1.496811\n",
       "Name: lossvalue_mse, Length: 108, dtype: float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1[\"lossvalue_mse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullplot1['Combined Label'] = fullplot1.drop(columns=[\"lossvalue_mse\", \"lossvalue_l1\"], axis=1).astype(str).agg(' - '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_channels</th>\n",
       "      <th>gcn_layers</th>\n",
       "      <th>linear_sizes</th>\n",
       "      <th>aggregations</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "      <th>Combined Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.141340</td>\n",
       "      <td>0.830645</td>\n",
       "      <td>[512] - 3 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.304490</td>\n",
       "      <td>0.891201</td>\n",
       "      <td>[512] - 3 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.317651</td>\n",
       "      <td>0.891474</td>\n",
       "      <td>[512] - 4 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.319729</td>\n",
       "      <td>0.892361</td>\n",
       "      <td>[256] - 4 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.320622</td>\n",
       "      <td>0.923801</td>\n",
       "      <td>[512] - 3 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.344558</td>\n",
       "      <td>0.917350</td>\n",
       "      <td>[256] - 4 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.357898</td>\n",
       "      <td>0.901737</td>\n",
       "      <td>[512] - 4 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.375359</td>\n",
       "      <td>0.920297</td>\n",
       "      <td>[512] - 2 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.382416</td>\n",
       "      <td>0.919353</td>\n",
       "      <td>[256] - 2 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.389036</td>\n",
       "      <td>0.929248</td>\n",
       "      <td>[512] - 3 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.409926</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>[256] - 2 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.412543</td>\n",
       "      <td>0.918208</td>\n",
       "      <td>[256] - 4 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.459150</td>\n",
       "      <td>0.945975</td>\n",
       "      <td>[512] - 3 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.462749</td>\n",
       "      <td>0.940038</td>\n",
       "      <td>[512] - 4 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.469752</td>\n",
       "      <td>0.964603</td>\n",
       "      <td>[512] - 1 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.471861</td>\n",
       "      <td>0.971736</td>\n",
       "      <td>[256] - 3 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.496811</td>\n",
       "      <td>0.934064</td>\n",
       "      <td>[512] - 2 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.506695</td>\n",
       "      <td>0.919771</td>\n",
       "      <td>[256] - 4 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.508131</td>\n",
       "      <td>0.984268</td>\n",
       "      <td>[256] - 3 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.514382</td>\n",
       "      <td>0.976927</td>\n",
       "      <td>[256] - 1 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.531404</td>\n",
       "      <td>0.957719</td>\n",
       "      <td>[512] - 3 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.542044</td>\n",
       "      <td>0.952549</td>\n",
       "      <td>[256] - 4 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.545086</td>\n",
       "      <td>0.942401</td>\n",
       "      <td>[512] - 4 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.559103</td>\n",
       "      <td>0.964162</td>\n",
       "      <td>[256] - 3 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.560182</td>\n",
       "      <td>0.975383</td>\n",
       "      <td>[256] - 4 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.574251</td>\n",
       "      <td>0.988541</td>\n",
       "      <td>[256] - 2 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.589022</td>\n",
       "      <td>0.990457</td>\n",
       "      <td>[512] - 2 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.595873</td>\n",
       "      <td>0.980456</td>\n",
       "      <td>[512] - 3 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.601146</td>\n",
       "      <td>0.988182</td>\n",
       "      <td>[256] - 2 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.603379</td>\n",
       "      <td>0.970413</td>\n",
       "      <td>[512] - 4 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.603891</td>\n",
       "      <td>0.967442</td>\n",
       "      <td>[256] - 2 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.604228</td>\n",
       "      <td>1.011597</td>\n",
       "      <td>[512] - 1 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.607848</td>\n",
       "      <td>1.016571</td>\n",
       "      <td>[512] - 1 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.621399</td>\n",
       "      <td>1.006339</td>\n",
       "      <td>[512] - 2 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.639046</td>\n",
       "      <td>0.978210</td>\n",
       "      <td>[64] - 2 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.640213</td>\n",
       "      <td>0.977738</td>\n",
       "      <td>[512] - 2 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.646032</td>\n",
       "      <td>0.985311</td>\n",
       "      <td>[256] - 3 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.647135</td>\n",
       "      <td>1.013511</td>\n",
       "      <td>[256] - 1 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.651778</td>\n",
       "      <td>1.006659</td>\n",
       "      <td>[256] - 2 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.663829</td>\n",
       "      <td>0.983118</td>\n",
       "      <td>[64] - 4 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.667042</td>\n",
       "      <td>1.003995</td>\n",
       "      <td>[64] - 4 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.674085</td>\n",
       "      <td>1.020093</td>\n",
       "      <td>[256] - 3 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.677117</td>\n",
       "      <td>1.026187</td>\n",
       "      <td>[512] - 2 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.694059</td>\n",
       "      <td>1.007994</td>\n",
       "      <td>[64] - 2 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.703026</td>\n",
       "      <td>1.007167</td>\n",
       "      <td>[256] - 3 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.712613</td>\n",
       "      <td>1.020882</td>\n",
       "      <td>[256] - 3 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.718177</td>\n",
       "      <td>1.025834</td>\n",
       "      <td>[64] - 3 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.726943</td>\n",
       "      <td>1.032046</td>\n",
       "      <td>[64] - 3 - [] - ['global_mean_pool', 'global_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.729890</td>\n",
       "      <td>1.014345</td>\n",
       "      <td>[64] - 2 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.735936</td>\n",
       "      <td>1.021627</td>\n",
       "      <td>[256] - 4 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.736525</td>\n",
       "      <td>1.027164</td>\n",
       "      <td>[512] - 3 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.742396</td>\n",
       "      <td>1.045283</td>\n",
       "      <td>[64] - 4 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.743656</td>\n",
       "      <td>1.022949</td>\n",
       "      <td>[512] - 2 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.774046</td>\n",
       "      <td>1.000090</td>\n",
       "      <td>[64] - 1 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.782694</td>\n",
       "      <td>1.063235</td>\n",
       "      <td>[64] - 4 - [512] - ['global_mean_pool', 'globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.785904</td>\n",
       "      <td>1.038566</td>\n",
       "      <td>[256] - 3 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.789288</td>\n",
       "      <td>0.988432</td>\n",
       "      <td>[256] - 1 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.794477</td>\n",
       "      <td>1.029742</td>\n",
       "      <td>[64] - 3 - [512, 256] - ['global_mean_pool', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.800985</td>\n",
       "      <td>1.043071</td>\n",
       "      <td>[256] - 3 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.801419</td>\n",
       "      <td>1.023469</td>\n",
       "      <td>[256] - 4 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.810129</td>\n",
       "      <td>1.021747</td>\n",
       "      <td>[64] - 4 - [512, 256] - ['global_mean_pool', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.822363</td>\n",
       "      <td>1.054378</td>\n",
       "      <td>[64] - 1 - [] - ['global_mean_pool', 'global_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.822558</td>\n",
       "      <td>1.006681</td>\n",
       "      <td>[256] - 1 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.826213</td>\n",
       "      <td>1.004823</td>\n",
       "      <td>[512] - 4 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.836079</td>\n",
       "      <td>1.034550</td>\n",
       "      <td>[256] - 2 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.840950</td>\n",
       "      <td>1.033493</td>\n",
       "      <td>[64] - 4 - [] - ['global_mean_pool', 'global_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.844461</td>\n",
       "      <td>1.006360</td>\n",
       "      <td>[512] - 1 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.847012</td>\n",
       "      <td>1.053907</td>\n",
       "      <td>[64] - 2 - [512] - ['global_mean_pool', 'globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.847809</td>\n",
       "      <td>1.043497</td>\n",
       "      <td>[256] - 4 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.851332</td>\n",
       "      <td>1.074543</td>\n",
       "      <td>[64] - 2 - [512, 256] - ['global_mean_pool', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.853513</td>\n",
       "      <td>0.997915</td>\n",
       "      <td>[512] - 2 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.856957</td>\n",
       "      <td>1.077828</td>\n",
       "      <td>[256] - 2 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.859373</td>\n",
       "      <td>1.069263</td>\n",
       "      <td>[64] - 2 - [] - ['global_mean_pool', 'global_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.861713</td>\n",
       "      <td>1.077506</td>\n",
       "      <td>[256] - 1 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.864664</td>\n",
       "      <td>0.972548</td>\n",
       "      <td>[64] - 4 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.869264</td>\n",
       "      <td>1.071124</td>\n",
       "      <td>[64] - 3 - [512] - ['global_mean_pool', 'globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.872073</td>\n",
       "      <td>1.037799</td>\n",
       "      <td>[512] - 3 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.879080</td>\n",
       "      <td>1.070802</td>\n",
       "      <td>[64] - 1 - [512, 256] - ['global_mean_pool', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.880164</td>\n",
       "      <td>1.026946</td>\n",
       "      <td>[512] - 1 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.881705</td>\n",
       "      <td>1.014660</td>\n",
       "      <td>[512] - 1 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.891909</td>\n",
       "      <td>1.037020</td>\n",
       "      <td>[64] - 2 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.895043</td>\n",
       "      <td>1.078867</td>\n",
       "      <td>[512] - 2 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.903641</td>\n",
       "      <td>1.080142</td>\n",
       "      <td>[64] - 4 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.934883</td>\n",
       "      <td>1.057842</td>\n",
       "      <td>[64] - 3 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.939569</td>\n",
       "      <td>1.077258</td>\n",
       "      <td>[512] - 4 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.951656</td>\n",
       "      <td>1.048711</td>\n",
       "      <td>[256] - 1 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.952973</td>\n",
       "      <td>1.107383</td>\n",
       "      <td>[64] - 3 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.966939</td>\n",
       "      <td>1.052555</td>\n",
       "      <td>[64] - 2 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.981134</td>\n",
       "      <td>1.072147</td>\n",
       "      <td>[64] - 1 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.982429</td>\n",
       "      <td>1.135471</td>\n",
       "      <td>[64] - 1 - [512] - ['global_mean_pool', 'globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.984540</td>\n",
       "      <td>1.053671</td>\n",
       "      <td>[512] - 4 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.991922</td>\n",
       "      <td>1.093257</td>\n",
       "      <td>[64] - 3 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.998079</td>\n",
       "      <td>1.043860</td>\n",
       "      <td>[64] - 3 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.007505</td>\n",
       "      <td>1.079502</td>\n",
       "      <td>[64] - 1 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.009363</td>\n",
       "      <td>1.069059</td>\n",
       "      <td>[256] - 2 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.019315</td>\n",
       "      <td>1.063300</td>\n",
       "      <td>[64] - 3 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.032514</td>\n",
       "      <td>1.137989</td>\n",
       "      <td>[256] - 1 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.084315</td>\n",
       "      <td>1.180876</td>\n",
       "      <td>[512] - 1 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.114384</td>\n",
       "      <td>1.197554</td>\n",
       "      <td>[512] - 1 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.149580</td>\n",
       "      <td>1.080329</td>\n",
       "      <td>[512] - 4 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.182305</td>\n",
       "      <td>1.189816</td>\n",
       "      <td>[512] - 1 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.194327</td>\n",
       "      <td>1.098116</td>\n",
       "      <td>[64] - 2 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.340199</td>\n",
       "      <td>1.216415</td>\n",
       "      <td>[256] - 1 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.427783</td>\n",
       "      <td>1.168230</td>\n",
       "      <td>[64] - 4 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.734133</td>\n",
       "      <td>1.282376</td>\n",
       "      <td>[64] - 1 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>3.061537</td>\n",
       "      <td>1.350474</td>\n",
       "      <td>[64] - 1 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>3.569377</td>\n",
       "      <td>1.390494</td>\n",
       "      <td>[256] - 1 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>3.704880</td>\n",
       "      <td>1.422107</td>\n",
       "      <td>[64] - 1 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hidden_channels  gcn_layers linear_sizes  \\\n",
       "0           [512]           3        [512]   \n",
       "0           [512]           3   [512, 256]   \n",
       "0           [512]           4   [512, 256]   \n",
       "0           [256]           4        [512]   \n",
       "0           [512]           3   [512, 256]   \n",
       "0           [256]           4           []   \n",
       "0           [512]           4           []   \n",
       "0           [512]           2        [512]   \n",
       "0           [256]           2        [512]   \n",
       "0           [512]           3        [512]   \n",
       "0           [256]           2           []   \n",
       "0           [256]           4           []   \n",
       "0           [512]           3           []   \n",
       "0           [512]           4        [512]   \n",
       "0           [512]           1   [512, 256]   \n",
       "0           [256]           3   [512, 256]   \n",
       "0           [512]           2   [512, 256]   \n",
       "0           [256]           4        [512]   \n",
       "0           [256]           3        [512]   \n",
       "0           [256]           1   [512, 256]   \n",
       "0           [512]           3           []   \n",
       "0           [256]           4           []   \n",
       "0           [512]           4   [512, 256]   \n",
       "0           [256]           3           []   \n",
       "0           [256]           4   [512, 256]   \n",
       "0           [256]           2        [512]   \n",
       "0           [512]           2        [512]   \n",
       "0           [512]           3           []   \n",
       "0           [256]           2           []   \n",
       "0           [512]           4        [512]   \n",
       "0           [256]           2   [512, 256]   \n",
       "0           [512]           1        [512]   \n",
       "0           [512]           1           []   \n",
       "0           [512]           2           []   \n",
       "0            [64]           2        [512]   \n",
       "0           [512]           2           []   \n",
       "0           [256]           3        [512]   \n",
       "0           [256]           1           []   \n",
       "0           [256]           2   [512, 256]   \n",
       "0            [64]           4        [512]   \n",
       "0            [64]           4        [512]   \n",
       "0           [256]           3   [512, 256]   \n",
       "0           [512]           2   [512, 256]   \n",
       "0            [64]           2           []   \n",
       "0           [256]           3   [512, 256]   \n",
       "0           [256]           3           []   \n",
       "0            [64]           3        [512]   \n",
       "0            [64]           3           []   \n",
       "0            [64]           2   [512, 256]   \n",
       "0           [256]           4   [512, 256]   \n",
       "0           [512]           3   [512, 256]   \n",
       "0            [64]           4   [512, 256]   \n",
       "0           [512]           2        [512]   \n",
       "0            [64]           1           []   \n",
       "0            [64]           4        [512]   \n",
       "0           [256]           3        [512]   \n",
       "0           [256]           1           []   \n",
       "0            [64]           3   [512, 256]   \n",
       "0           [256]           3           []   \n",
       "0           [256]           4        [512]   \n",
       "0            [64]           4   [512, 256]   \n",
       "0            [64]           1           []   \n",
       "0           [256]           1   [512, 256]   \n",
       "0           [512]           4   [512, 256]   \n",
       "0           [256]           2        [512]   \n",
       "0            [64]           4           []   \n",
       "0           [512]           1           []   \n",
       "0            [64]           2        [512]   \n",
       "0           [256]           4   [512, 256]   \n",
       "0            [64]           2   [512, 256]   \n",
       "0           [512]           2   [512, 256]   \n",
       "0           [256]           2   [512, 256]   \n",
       "0            [64]           2           []   \n",
       "0           [256]           1        [512]   \n",
       "0            [64]           4   [512, 256]   \n",
       "0            [64]           3        [512]   \n",
       "0           [512]           3        [512]   \n",
       "0            [64]           1   [512, 256]   \n",
       "0           [512]           1        [512]   \n",
       "0           [512]           1   [512, 256]   \n",
       "0            [64]           2           []   \n",
       "0           [512]           2           []   \n",
       "0            [64]           4           []   \n",
       "0            [64]           3           []   \n",
       "0           [512]           4           []   \n",
       "0           [256]           1        [512]   \n",
       "0            [64]           3        [512]   \n",
       "0            [64]           2   [512, 256]   \n",
       "0            [64]           1        [512]   \n",
       "0            [64]           1        [512]   \n",
       "0           [512]           4           []   \n",
       "0            [64]           3   [512, 256]   \n",
       "0            [64]           3   [512, 256]   \n",
       "0            [64]           1   [512, 256]   \n",
       "0           [256]           2           []   \n",
       "0            [64]           3           []   \n",
       "0           [256]           1           []   \n",
       "0           [512]           1        [512]   \n",
       "0           [512]           1   [512, 256]   \n",
       "0           [512]           4        [512]   \n",
       "0           [512]           1           []   \n",
       "0            [64]           2        [512]   \n",
       "0           [256]           1   [512, 256]   \n",
       "0            [64]           4           []   \n",
       "0            [64]           1        [512]   \n",
       "0            [64]           1           []   \n",
       "0           [256]           1        [512]   \n",
       "0            [64]           1   [512, 256]   \n",
       "\n",
       "                          aggregations  lossvalue_mse  lossvalue_l1  \\\n",
       "0                    [global_max_pool]       1.141340      0.830645   \n",
       "0  [global_mean_pool, global_max_pool]       1.304490      0.891201   \n",
       "0  [global_mean_pool, global_max_pool]       1.317651      0.891474   \n",
       "0                    [global_max_pool]       1.319729      0.892361   \n",
       "0                    [global_max_pool]       1.320622      0.923801   \n",
       "0  [global_mean_pool, global_max_pool]       1.344558      0.917350   \n",
       "0  [global_mean_pool, global_max_pool]       1.357898      0.901737   \n",
       "0                   [global_mean_pool]       1.375359      0.920297   \n",
       "0  [global_mean_pool, global_max_pool]       1.382416      0.919353   \n",
       "0  [global_mean_pool, global_max_pool]       1.389036      0.929248   \n",
       "0  [global_mean_pool, global_max_pool]       1.409926      0.945727   \n",
       "0                    [global_max_pool]       1.412543      0.918208   \n",
       "0  [global_mean_pool, global_max_pool]       1.459150      0.945975   \n",
       "0  [global_mean_pool, global_max_pool]       1.462749      0.940038   \n",
       "0  [global_mean_pool, global_max_pool]       1.469752      0.964603   \n",
       "0                    [global_max_pool]       1.471861      0.971736   \n",
       "0  [global_mean_pool, global_max_pool]       1.496811      0.934064   \n",
       "0  [global_mean_pool, global_max_pool]       1.506695      0.919771   \n",
       "0  [global_mean_pool, global_max_pool]       1.508131      0.984268   \n",
       "0  [global_mean_pool, global_max_pool]       1.514382      0.976927   \n",
       "0                   [global_mean_pool]       1.531404      0.957719   \n",
       "0                   [global_mean_pool]       1.542044      0.952549   \n",
       "0                    [global_max_pool]       1.545086      0.942401   \n",
       "0                    [global_max_pool]       1.559103      0.964162   \n",
       "0  [global_mean_pool, global_max_pool]       1.560182      0.975383   \n",
       "0                    [global_max_pool]       1.574251      0.988541   \n",
       "0                    [global_max_pool]       1.589022      0.990457   \n",
       "0                    [global_max_pool]       1.595873      0.980456   \n",
       "0                    [global_max_pool]       1.601146      0.988182   \n",
       "0                    [global_max_pool]       1.603379      0.970413   \n",
       "0                    [global_max_pool]       1.603891      0.967442   \n",
       "0  [global_mean_pool, global_max_pool]       1.604228      1.011597   \n",
       "0  [global_mean_pool, global_max_pool]       1.607848      1.016571   \n",
       "0                    [global_max_pool]       1.621399      1.006339   \n",
       "0                    [global_max_pool]       1.639046      0.978210   \n",
       "0  [global_mean_pool, global_max_pool]       1.640213      0.977738   \n",
       "0                   [global_mean_pool]       1.646032      0.985311   \n",
       "0  [global_mean_pool, global_max_pool]       1.647135      1.013511   \n",
       "0  [global_mean_pool, global_max_pool]       1.651778      1.006659   \n",
       "0                   [global_mean_pool]       1.663829      0.983118   \n",
       "0                    [global_max_pool]       1.667042      1.003995   \n",
       "0  [global_mean_pool, global_max_pool]       1.674085      1.020093   \n",
       "0                    [global_max_pool]       1.677117      1.026187   \n",
       "0                    [global_max_pool]       1.694059      1.007994   \n",
       "0                   [global_mean_pool]       1.703026      1.007167   \n",
       "0                   [global_mean_pool]       1.712613      1.020882   \n",
       "0                   [global_mean_pool]       1.718177      1.025834   \n",
       "0  [global_mean_pool, global_max_pool]       1.726943      1.032046   \n",
       "0                    [global_max_pool]       1.729890      1.014345   \n",
       "0                   [global_mean_pool]       1.735936      1.021627   \n",
       "0                   [global_mean_pool]       1.736525      1.027164   \n",
       "0                    [global_max_pool]       1.742396      1.045283   \n",
       "0  [global_mean_pool, global_max_pool]       1.743656      1.022949   \n",
       "0                   [global_mean_pool]       1.774046      1.000090   \n",
       "0  [global_mean_pool, global_max_pool]       1.782694      1.063235   \n",
       "0                    [global_max_pool]       1.785904      1.038566   \n",
       "0                   [global_mean_pool]       1.789288      0.988432   \n",
       "0  [global_mean_pool, global_max_pool]       1.794477      1.029742   \n",
       "0  [global_mean_pool, global_max_pool]       1.800985      1.043071   \n",
       "0                   [global_mean_pool]       1.801419      1.023469   \n",
       "0  [global_mean_pool, global_max_pool]       1.810129      1.021747   \n",
       "0  [global_mean_pool, global_max_pool]       1.822363      1.054378   \n",
       "0                   [global_mean_pool]       1.822558      1.006681   \n",
       "0                   [global_mean_pool]       1.826213      1.004823   \n",
       "0                   [global_mean_pool]       1.836079      1.034550   \n",
       "0  [global_mean_pool, global_max_pool]       1.840950      1.033493   \n",
       "0                   [global_mean_pool]       1.844461      1.006360   \n",
       "0  [global_mean_pool, global_max_pool]       1.847012      1.053907   \n",
       "0                    [global_max_pool]       1.847809      1.043497   \n",
       "0  [global_mean_pool, global_max_pool]       1.851332      1.074543   \n",
       "0                   [global_mean_pool]       1.853513      0.997915   \n",
       "0                   [global_mean_pool]       1.856957      1.077828   \n",
       "0  [global_mean_pool, global_max_pool]       1.859373      1.069263   \n",
       "0  [global_mean_pool, global_max_pool]       1.861713      1.077506   \n",
       "0                   [global_mean_pool]       1.864664      0.972548   \n",
       "0  [global_mean_pool, global_max_pool]       1.869264      1.071124   \n",
       "0                   [global_mean_pool]       1.872073      1.037799   \n",
       "0  [global_mean_pool, global_max_pool]       1.879080      1.070802   \n",
       "0                   [global_mean_pool]       1.880164      1.026946   \n",
       "0                   [global_mean_pool]       1.881705      1.014660   \n",
       "0                   [global_mean_pool]       1.891909      1.037020   \n",
       "0                   [global_mean_pool]       1.895043      1.078867   \n",
       "0                    [global_max_pool]       1.903641      1.080142   \n",
       "0                    [global_max_pool]       1.934883      1.057842   \n",
       "0                    [global_max_pool]       1.939569      1.077258   \n",
       "0                   [global_mean_pool]       1.951656      1.048711   \n",
       "0                    [global_max_pool]       1.952973      1.107383   \n",
       "0                   [global_mean_pool]       1.966939      1.052555   \n",
       "0                   [global_mean_pool]       1.981134      1.072147   \n",
       "0  [global_mean_pool, global_max_pool]       1.982429      1.135471   \n",
       "0                   [global_mean_pool]       1.984540      1.053671   \n",
       "0                    [global_max_pool]       1.991922      1.093257   \n",
       "0                   [global_mean_pool]       1.998079      1.043860   \n",
       "0                   [global_mean_pool]       2.007505      1.079502   \n",
       "0                   [global_mean_pool]       2.009363      1.069059   \n",
       "0                   [global_mean_pool]       2.019315      1.063300   \n",
       "0                    [global_max_pool]       2.032514      1.137989   \n",
       "0                    [global_max_pool]       2.084315      1.180876   \n",
       "0                    [global_max_pool]       2.114384      1.197554   \n",
       "0                   [global_mean_pool]       2.149580      1.080329   \n",
       "0                    [global_max_pool]       2.182305      1.189816   \n",
       "0                   [global_mean_pool]       2.194327      1.098116   \n",
       "0                    [global_max_pool]       2.340199      1.216415   \n",
       "0                   [global_mean_pool]       2.427783      1.168230   \n",
       "0                    [global_max_pool]       2.734133      1.282376   \n",
       "0                    [global_max_pool]       3.061537      1.350474   \n",
       "0                    [global_max_pool]       3.569377      1.390494   \n",
       "0                    [global_max_pool]       3.704880      1.422107   \n",
       "\n",
       "                                      Combined Label  \n",
       "0            [512] - 3 - [512] - ['global_max_pool']  \n",
       "0  [512] - 3 - [512, 256] - ['global_mean_pool', ...  \n",
       "0  [512] - 4 - [512, 256] - ['global_mean_pool', ...  \n",
       "0            [256] - 4 - [512] - ['global_max_pool']  \n",
       "0       [512] - 3 - [512, 256] - ['global_max_pool']  \n",
       "0  [256] - 4 - [] - ['global_mean_pool', 'global_...  \n",
       "0  [512] - 4 - [] - ['global_mean_pool', 'global_...  \n",
       "0           [512] - 2 - [512] - ['global_mean_pool']  \n",
       "0  [256] - 2 - [512] - ['global_mean_pool', 'glob...  \n",
       "0  [512] - 3 - [512] - ['global_mean_pool', 'glob...  \n",
       "0  [256] - 2 - [] - ['global_mean_pool', 'global_...  \n",
       "0               [256] - 4 - [] - ['global_max_pool']  \n",
       "0  [512] - 3 - [] - ['global_mean_pool', 'global_...  \n",
       "0  [512] - 4 - [512] - ['global_mean_pool', 'glob...  \n",
       "0  [512] - 1 - [512, 256] - ['global_mean_pool', ...  \n",
       "0       [256] - 3 - [512, 256] - ['global_max_pool']  \n",
       "0  [512] - 2 - [512, 256] - ['global_mean_pool', ...  \n",
       "0  [256] - 4 - [512] - ['global_mean_pool', 'glob...  \n",
       "0  [256] - 3 - [512] - ['global_mean_pool', 'glob...  \n",
       "0  [256] - 1 - [512, 256] - ['global_mean_pool', ...  \n",
       "0              [512] - 3 - [] - ['global_mean_pool']  \n",
       "0              [256] - 4 - [] - ['global_mean_pool']  \n",
       "0       [512] - 4 - [512, 256] - ['global_max_pool']  \n",
       "0               [256] - 3 - [] - ['global_max_pool']  \n",
       "0  [256] - 4 - [512, 256] - ['global_mean_pool', ...  \n",
       "0            [256] - 2 - [512] - ['global_max_pool']  \n",
       "0            [512] - 2 - [512] - ['global_max_pool']  \n",
       "0               [512] - 3 - [] - ['global_max_pool']  \n",
       "0               [256] - 2 - [] - ['global_max_pool']  \n",
       "0            [512] - 4 - [512] - ['global_max_pool']  \n",
       "0       [256] - 2 - [512, 256] - ['global_max_pool']  \n",
       "0  [512] - 1 - [512] - ['global_mean_pool', 'glob...  \n",
       "0  [512] - 1 - [] - ['global_mean_pool', 'global_...  \n",
       "0               [512] - 2 - [] - ['global_max_pool']  \n",
       "0             [64] - 2 - [512] - ['global_max_pool']  \n",
       "0  [512] - 2 - [] - ['global_mean_pool', 'global_...  \n",
       "0           [256] - 3 - [512] - ['global_mean_pool']  \n",
       "0  [256] - 1 - [] - ['global_mean_pool', 'global_...  \n",
       "0  [256] - 2 - [512, 256] - ['global_mean_pool', ...  \n",
       "0            [64] - 4 - [512] - ['global_mean_pool']  \n",
       "0             [64] - 4 - [512] - ['global_max_pool']  \n",
       "0  [256] - 3 - [512, 256] - ['global_mean_pool', ...  \n",
       "0       [512] - 2 - [512, 256] - ['global_max_pool']  \n",
       "0                [64] - 2 - [] - ['global_max_pool']  \n",
       "0      [256] - 3 - [512, 256] - ['global_mean_pool']  \n",
       "0              [256] - 3 - [] - ['global_mean_pool']  \n",
       "0            [64] - 3 - [512] - ['global_mean_pool']  \n",
       "0  [64] - 3 - [] - ['global_mean_pool', 'global_m...  \n",
       "0        [64] - 2 - [512, 256] - ['global_max_pool']  \n",
       "0      [256] - 4 - [512, 256] - ['global_mean_pool']  \n",
       "0      [512] - 3 - [512, 256] - ['global_mean_pool']  \n",
       "0        [64] - 4 - [512, 256] - ['global_max_pool']  \n",
       "0  [512] - 2 - [512] - ['global_mean_pool', 'glob...  \n",
       "0               [64] - 1 - [] - ['global_mean_pool']  \n",
       "0  [64] - 4 - [512] - ['global_mean_pool', 'globa...  \n",
       "0            [256] - 3 - [512] - ['global_max_pool']  \n",
       "0              [256] - 1 - [] - ['global_mean_pool']  \n",
       "0  [64] - 3 - [512, 256] - ['global_mean_pool', '...  \n",
       "0  [256] - 3 - [] - ['global_mean_pool', 'global_...  \n",
       "0           [256] - 4 - [512] - ['global_mean_pool']  \n",
       "0  [64] - 4 - [512, 256] - ['global_mean_pool', '...  \n",
       "0  [64] - 1 - [] - ['global_mean_pool', 'global_m...  \n",
       "0      [256] - 1 - [512, 256] - ['global_mean_pool']  \n",
       "0      [512] - 4 - [512, 256] - ['global_mean_pool']  \n",
       "0           [256] - 2 - [512] - ['global_mean_pool']  \n",
       "0  [64] - 4 - [] - ['global_mean_pool', 'global_m...  \n",
       "0              [512] - 1 - [] - ['global_mean_pool']  \n",
       "0  [64] - 2 - [512] - ['global_mean_pool', 'globa...  \n",
       "0       [256] - 4 - [512, 256] - ['global_max_pool']  \n",
       "0  [64] - 2 - [512, 256] - ['global_mean_pool', '...  \n",
       "0      [512] - 2 - [512, 256] - ['global_mean_pool']  \n",
       "0      [256] - 2 - [512, 256] - ['global_mean_pool']  \n",
       "0  [64] - 2 - [] - ['global_mean_pool', 'global_m...  \n",
       "0  [256] - 1 - [512] - ['global_mean_pool', 'glob...  \n",
       "0       [64] - 4 - [512, 256] - ['global_mean_pool']  \n",
       "0  [64] - 3 - [512] - ['global_mean_pool', 'globa...  \n",
       "0           [512] - 3 - [512] - ['global_mean_pool']  \n",
       "0  [64] - 1 - [512, 256] - ['global_mean_pool', '...  \n",
       "0           [512] - 1 - [512] - ['global_mean_pool']  \n",
       "0      [512] - 1 - [512, 256] - ['global_mean_pool']  \n",
       "0               [64] - 2 - [] - ['global_mean_pool']  \n",
       "0              [512] - 2 - [] - ['global_mean_pool']  \n",
       "0                [64] - 4 - [] - ['global_max_pool']  \n",
       "0                [64] - 3 - [] - ['global_max_pool']  \n",
       "0               [512] - 4 - [] - ['global_max_pool']  \n",
       "0           [256] - 1 - [512] - ['global_mean_pool']  \n",
       "0             [64] - 3 - [512] - ['global_max_pool']  \n",
       "0       [64] - 2 - [512, 256] - ['global_mean_pool']  \n",
       "0            [64] - 1 - [512] - ['global_mean_pool']  \n",
       "0  [64] - 1 - [512] - ['global_mean_pool', 'globa...  \n",
       "0              [512] - 4 - [] - ['global_mean_pool']  \n",
       "0        [64] - 3 - [512, 256] - ['global_max_pool']  \n",
       "0       [64] - 3 - [512, 256] - ['global_mean_pool']  \n",
       "0       [64] - 1 - [512, 256] - ['global_mean_pool']  \n",
       "0              [256] - 2 - [] - ['global_mean_pool']  \n",
       "0               [64] - 3 - [] - ['global_mean_pool']  \n",
       "0               [256] - 1 - [] - ['global_max_pool']  \n",
       "0            [512] - 1 - [512] - ['global_max_pool']  \n",
       "0       [512] - 1 - [512, 256] - ['global_max_pool']  \n",
       "0           [512] - 4 - [512] - ['global_mean_pool']  \n",
       "0               [512] - 1 - [] - ['global_max_pool']  \n",
       "0            [64] - 2 - [512] - ['global_mean_pool']  \n",
       "0       [256] - 1 - [512, 256] - ['global_max_pool']  \n",
       "0               [64] - 4 - [] - ['global_mean_pool']  \n",
       "0             [64] - 1 - [512] - ['global_max_pool']  \n",
       "0                [64] - 1 - [] - ['global_max_pool']  \n",
       "0            [256] - 1 - [512] - ['global_max_pool']  \n",
       "0        [64] - 1 - [512, 256] - ['global_max_pool']  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1.sort_values(by=['lossvalue_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_channels</th>\n",
       "      <th>gcn_layers</th>\n",
       "      <th>linear_sizes</th>\n",
       "      <th>aggregations</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "      <th>Combined Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.141340</td>\n",
       "      <td>0.830645</td>\n",
       "      <td>[512] - 3 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.304490</td>\n",
       "      <td>0.891201</td>\n",
       "      <td>[512] - 3 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.317651</td>\n",
       "      <td>0.891474</td>\n",
       "      <td>[512] - 4 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.319729</td>\n",
       "      <td>0.892361</td>\n",
       "      <td>[256] - 4 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.357898</td>\n",
       "      <td>0.901737</td>\n",
       "      <td>[512] - 4 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.344558</td>\n",
       "      <td>0.917350</td>\n",
       "      <td>[256] - 4 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.412543</td>\n",
       "      <td>0.918208</td>\n",
       "      <td>[256] - 4 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.382416</td>\n",
       "      <td>0.919353</td>\n",
       "      <td>[256] - 2 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.506695</td>\n",
       "      <td>0.919771</td>\n",
       "      <td>[256] - 4 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.375359</td>\n",
       "      <td>0.920297</td>\n",
       "      <td>[512] - 2 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.320622</td>\n",
       "      <td>0.923801</td>\n",
       "      <td>[512] - 3 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.389036</td>\n",
       "      <td>0.929248</td>\n",
       "      <td>[512] - 3 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.496811</td>\n",
       "      <td>0.934064</td>\n",
       "      <td>[512] - 2 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.462749</td>\n",
       "      <td>0.940038</td>\n",
       "      <td>[512] - 4 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.545086</td>\n",
       "      <td>0.942401</td>\n",
       "      <td>[512] - 4 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.409926</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>[256] - 2 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.459150</td>\n",
       "      <td>0.945975</td>\n",
       "      <td>[512] - 3 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.542044</td>\n",
       "      <td>0.952549</td>\n",
       "      <td>[256] - 4 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.531404</td>\n",
       "      <td>0.957719</td>\n",
       "      <td>[512] - 3 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.559103</td>\n",
       "      <td>0.964162</td>\n",
       "      <td>[256] - 3 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.469752</td>\n",
       "      <td>0.964603</td>\n",
       "      <td>[512] - 1 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.603891</td>\n",
       "      <td>0.967442</td>\n",
       "      <td>[256] - 2 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.603379</td>\n",
       "      <td>0.970413</td>\n",
       "      <td>[512] - 4 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.471861</td>\n",
       "      <td>0.971736</td>\n",
       "      <td>[256] - 3 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.864664</td>\n",
       "      <td>0.972548</td>\n",
       "      <td>[64] - 4 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.560182</td>\n",
       "      <td>0.975383</td>\n",
       "      <td>[256] - 4 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.514382</td>\n",
       "      <td>0.976927</td>\n",
       "      <td>[256] - 1 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.640213</td>\n",
       "      <td>0.977738</td>\n",
       "      <td>[512] - 2 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.639046</td>\n",
       "      <td>0.978210</td>\n",
       "      <td>[64] - 2 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.595873</td>\n",
       "      <td>0.980456</td>\n",
       "      <td>[512] - 3 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.663829</td>\n",
       "      <td>0.983118</td>\n",
       "      <td>[64] - 4 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.508131</td>\n",
       "      <td>0.984268</td>\n",
       "      <td>[256] - 3 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.646032</td>\n",
       "      <td>0.985311</td>\n",
       "      <td>[256] - 3 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.601146</td>\n",
       "      <td>0.988182</td>\n",
       "      <td>[256] - 2 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.789288</td>\n",
       "      <td>0.988432</td>\n",
       "      <td>[256] - 1 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.574251</td>\n",
       "      <td>0.988541</td>\n",
       "      <td>[256] - 2 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.589022</td>\n",
       "      <td>0.990457</td>\n",
       "      <td>[512] - 2 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.853513</td>\n",
       "      <td>0.997915</td>\n",
       "      <td>[512] - 2 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.774046</td>\n",
       "      <td>1.000090</td>\n",
       "      <td>[64] - 1 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.667042</td>\n",
       "      <td>1.003995</td>\n",
       "      <td>[64] - 4 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.826213</td>\n",
       "      <td>1.004823</td>\n",
       "      <td>[512] - 4 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.621399</td>\n",
       "      <td>1.006339</td>\n",
       "      <td>[512] - 2 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.844461</td>\n",
       "      <td>1.006360</td>\n",
       "      <td>[512] - 1 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.651778</td>\n",
       "      <td>1.006659</td>\n",
       "      <td>[256] - 2 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.822558</td>\n",
       "      <td>1.006681</td>\n",
       "      <td>[256] - 1 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.703026</td>\n",
       "      <td>1.007167</td>\n",
       "      <td>[256] - 3 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.694059</td>\n",
       "      <td>1.007994</td>\n",
       "      <td>[64] - 2 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.604228</td>\n",
       "      <td>1.011597</td>\n",
       "      <td>[512] - 1 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.647135</td>\n",
       "      <td>1.013511</td>\n",
       "      <td>[256] - 1 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.729890</td>\n",
       "      <td>1.014345</td>\n",
       "      <td>[64] - 2 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.881705</td>\n",
       "      <td>1.014660</td>\n",
       "      <td>[512] - 1 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.607848</td>\n",
       "      <td>1.016571</td>\n",
       "      <td>[512] - 1 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.674085</td>\n",
       "      <td>1.020093</td>\n",
       "      <td>[256] - 3 - [512, 256] - ['global_mean_pool', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.712613</td>\n",
       "      <td>1.020882</td>\n",
       "      <td>[256] - 3 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.735936</td>\n",
       "      <td>1.021627</td>\n",
       "      <td>[256] - 4 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.810129</td>\n",
       "      <td>1.021747</td>\n",
       "      <td>[64] - 4 - [512, 256] - ['global_mean_pool', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.743656</td>\n",
       "      <td>1.022949</td>\n",
       "      <td>[512] - 2 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.801419</td>\n",
       "      <td>1.023469</td>\n",
       "      <td>[256] - 4 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.718177</td>\n",
       "      <td>1.025834</td>\n",
       "      <td>[64] - 3 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.677117</td>\n",
       "      <td>1.026187</td>\n",
       "      <td>[512] - 2 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.880164</td>\n",
       "      <td>1.026946</td>\n",
       "      <td>[512] - 1 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.736525</td>\n",
       "      <td>1.027164</td>\n",
       "      <td>[512] - 3 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.794477</td>\n",
       "      <td>1.029742</td>\n",
       "      <td>[64] - 3 - [512, 256] - ['global_mean_pool', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.726943</td>\n",
       "      <td>1.032046</td>\n",
       "      <td>[64] - 3 - [] - ['global_mean_pool', 'global_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.840950</td>\n",
       "      <td>1.033493</td>\n",
       "      <td>[64] - 4 - [] - ['global_mean_pool', 'global_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.836079</td>\n",
       "      <td>1.034550</td>\n",
       "      <td>[256] - 2 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.891909</td>\n",
       "      <td>1.037020</td>\n",
       "      <td>[64] - 2 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.872073</td>\n",
       "      <td>1.037799</td>\n",
       "      <td>[512] - 3 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.785904</td>\n",
       "      <td>1.038566</td>\n",
       "      <td>[256] - 3 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.800985</td>\n",
       "      <td>1.043071</td>\n",
       "      <td>[256] - 3 - [] - ['global_mean_pool', 'global_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.847809</td>\n",
       "      <td>1.043497</td>\n",
       "      <td>[256] - 4 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.998079</td>\n",
       "      <td>1.043860</td>\n",
       "      <td>[64] - 3 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.742396</td>\n",
       "      <td>1.045283</td>\n",
       "      <td>[64] - 4 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.951656</td>\n",
       "      <td>1.048711</td>\n",
       "      <td>[256] - 1 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.966939</td>\n",
       "      <td>1.052555</td>\n",
       "      <td>[64] - 2 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.984540</td>\n",
       "      <td>1.053671</td>\n",
       "      <td>[512] - 4 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.847012</td>\n",
       "      <td>1.053907</td>\n",
       "      <td>[64] - 2 - [512] - ['global_mean_pool', 'globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.822363</td>\n",
       "      <td>1.054378</td>\n",
       "      <td>[64] - 1 - [] - ['global_mean_pool', 'global_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.934883</td>\n",
       "      <td>1.057842</td>\n",
       "      <td>[64] - 3 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.782694</td>\n",
       "      <td>1.063235</td>\n",
       "      <td>[64] - 4 - [512] - ['global_mean_pool', 'globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.019315</td>\n",
       "      <td>1.063300</td>\n",
       "      <td>[64] - 3 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.009363</td>\n",
       "      <td>1.069059</td>\n",
       "      <td>[256] - 2 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.859373</td>\n",
       "      <td>1.069263</td>\n",
       "      <td>[64] - 2 - [] - ['global_mean_pool', 'global_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.879080</td>\n",
       "      <td>1.070802</td>\n",
       "      <td>[64] - 1 - [512, 256] - ['global_mean_pool', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.869264</td>\n",
       "      <td>1.071124</td>\n",
       "      <td>[64] - 3 - [512] - ['global_mean_pool', 'globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.981134</td>\n",
       "      <td>1.072147</td>\n",
       "      <td>[64] - 1 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.851332</td>\n",
       "      <td>1.074543</td>\n",
       "      <td>[64] - 2 - [512, 256] - ['global_mean_pool', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.939569</td>\n",
       "      <td>1.077258</td>\n",
       "      <td>[512] - 4 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.861713</td>\n",
       "      <td>1.077506</td>\n",
       "      <td>[256] - 1 - [512] - ['global_mean_pool', 'glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.856957</td>\n",
       "      <td>1.077828</td>\n",
       "      <td>[256] - 2 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>1.895043</td>\n",
       "      <td>1.078867</td>\n",
       "      <td>[512] - 2 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.007505</td>\n",
       "      <td>1.079502</td>\n",
       "      <td>[64] - 1 - [512, 256] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.903641</td>\n",
       "      <td>1.080142</td>\n",
       "      <td>[64] - 4 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>4</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.149580</td>\n",
       "      <td>1.080329</td>\n",
       "      <td>[512] - 4 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.991922</td>\n",
       "      <td>1.093257</td>\n",
       "      <td>[64] - 3 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.194327</td>\n",
       "      <td>1.098116</td>\n",
       "      <td>[64] - 2 - [512] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>3</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>1.952973</td>\n",
       "      <td>1.107383</td>\n",
       "      <td>[64] - 3 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_mean_pool, global_max_pool]</td>\n",
       "      <td>1.982429</td>\n",
       "      <td>1.135471</td>\n",
       "      <td>[64] - 1 - [512] - ['global_mean_pool', 'globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.032514</td>\n",
       "      <td>1.137989</td>\n",
       "      <td>[256] - 1 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_mean_pool]</td>\n",
       "      <td>2.427783</td>\n",
       "      <td>1.168230</td>\n",
       "      <td>[64] - 4 - [] - ['global_mean_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.084315</td>\n",
       "      <td>1.180876</td>\n",
       "      <td>[512] - 1 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.182305</td>\n",
       "      <td>1.189816</td>\n",
       "      <td>[512] - 1 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.114384</td>\n",
       "      <td>1.197554</td>\n",
       "      <td>[512] - 1 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.340199</td>\n",
       "      <td>1.216415</td>\n",
       "      <td>[256] - 1 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>2.734133</td>\n",
       "      <td>1.282376</td>\n",
       "      <td>[64] - 1 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>3.061537</td>\n",
       "      <td>1.350474</td>\n",
       "      <td>[64] - 1 - [] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[256]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>3.569377</td>\n",
       "      <td>1.390494</td>\n",
       "      <td>[256] - 1 - [512] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[global_max_pool]</td>\n",
       "      <td>3.704880</td>\n",
       "      <td>1.422107</td>\n",
       "      <td>[64] - 1 - [512, 256] - ['global_max_pool']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hidden_channels  gcn_layers linear_sizes  \\\n",
       "0           [512]           3        [512]   \n",
       "0           [512]           3   [512, 256]   \n",
       "0           [512]           4   [512, 256]   \n",
       "0           [256]           4        [512]   \n",
       "0           [512]           4           []   \n",
       "0           [256]           4           []   \n",
       "0           [256]           4           []   \n",
       "0           [256]           2        [512]   \n",
       "0           [256]           4        [512]   \n",
       "0           [512]           2        [512]   \n",
       "0           [512]           3   [512, 256]   \n",
       "0           [512]           3        [512]   \n",
       "0           [512]           2   [512, 256]   \n",
       "0           [512]           4        [512]   \n",
       "0           [512]           4   [512, 256]   \n",
       "0           [256]           2           []   \n",
       "0           [512]           3           []   \n",
       "0           [256]           4           []   \n",
       "0           [512]           3           []   \n",
       "0           [256]           3           []   \n",
       "0           [512]           1   [512, 256]   \n",
       "0           [256]           2   [512, 256]   \n",
       "0           [512]           4        [512]   \n",
       "0           [256]           3   [512, 256]   \n",
       "0            [64]           4   [512, 256]   \n",
       "0           [256]           4   [512, 256]   \n",
       "0           [256]           1   [512, 256]   \n",
       "0           [512]           2           []   \n",
       "0            [64]           2        [512]   \n",
       "0           [512]           3           []   \n",
       "0            [64]           4        [512]   \n",
       "0           [256]           3        [512]   \n",
       "0           [256]           3        [512]   \n",
       "0           [256]           2           []   \n",
       "0           [256]           1           []   \n",
       "0           [256]           2        [512]   \n",
       "0           [512]           2        [512]   \n",
       "0           [512]           2   [512, 256]   \n",
       "0            [64]           1           []   \n",
       "0            [64]           4        [512]   \n",
       "0           [512]           4   [512, 256]   \n",
       "0           [512]           2           []   \n",
       "0           [512]           1           []   \n",
       "0           [256]           2   [512, 256]   \n",
       "0           [256]           1   [512, 256]   \n",
       "0           [256]           3   [512, 256]   \n",
       "0            [64]           2           []   \n",
       "0           [512]           1        [512]   \n",
       "0           [256]           1           []   \n",
       "0            [64]           2   [512, 256]   \n",
       "0           [512]           1   [512, 256]   \n",
       "0           [512]           1           []   \n",
       "0           [256]           3   [512, 256]   \n",
       "0           [256]           3           []   \n",
       "0           [256]           4   [512, 256]   \n",
       "0            [64]           4   [512, 256]   \n",
       "0           [512]           2        [512]   \n",
       "0           [256]           4        [512]   \n",
       "0            [64]           3        [512]   \n",
       "0           [512]           2   [512, 256]   \n",
       "0           [512]           1        [512]   \n",
       "0           [512]           3   [512, 256]   \n",
       "0            [64]           3   [512, 256]   \n",
       "0            [64]           3           []   \n",
       "0            [64]           4           []   \n",
       "0           [256]           2        [512]   \n",
       "0            [64]           2           []   \n",
       "0           [512]           3        [512]   \n",
       "0           [256]           3        [512]   \n",
       "0           [256]           3           []   \n",
       "0           [256]           4   [512, 256]   \n",
       "0            [64]           3   [512, 256]   \n",
       "0            [64]           4   [512, 256]   \n",
       "0           [256]           1        [512]   \n",
       "0            [64]           2   [512, 256]   \n",
       "0           [512]           4           []   \n",
       "0            [64]           2        [512]   \n",
       "0            [64]           1           []   \n",
       "0            [64]           3           []   \n",
       "0            [64]           4        [512]   \n",
       "0            [64]           3           []   \n",
       "0           [256]           2           []   \n",
       "0            [64]           2           []   \n",
       "0            [64]           1   [512, 256]   \n",
       "0            [64]           3        [512]   \n",
       "0            [64]           1        [512]   \n",
       "0            [64]           2   [512, 256]   \n",
       "0           [512]           4           []   \n",
       "0           [256]           1        [512]   \n",
       "0           [256]           2   [512, 256]   \n",
       "0           [512]           2           []   \n",
       "0            [64]           1   [512, 256]   \n",
       "0            [64]           4           []   \n",
       "0           [512]           4        [512]   \n",
       "0            [64]           3   [512, 256]   \n",
       "0            [64]           2        [512]   \n",
       "0            [64]           3        [512]   \n",
       "0            [64]           1        [512]   \n",
       "0           [256]           1           []   \n",
       "0            [64]           4           []   \n",
       "0           [512]           1        [512]   \n",
       "0           [512]           1           []   \n",
       "0           [512]           1   [512, 256]   \n",
       "0           [256]           1   [512, 256]   \n",
       "0            [64]           1        [512]   \n",
       "0            [64]           1           []   \n",
       "0           [256]           1        [512]   \n",
       "0            [64]           1   [512, 256]   \n",
       "\n",
       "                          aggregations  lossvalue_mse  lossvalue_l1  \\\n",
       "0                    [global_max_pool]       1.141340      0.830645   \n",
       "0  [global_mean_pool, global_max_pool]       1.304490      0.891201   \n",
       "0  [global_mean_pool, global_max_pool]       1.317651      0.891474   \n",
       "0                    [global_max_pool]       1.319729      0.892361   \n",
       "0  [global_mean_pool, global_max_pool]       1.357898      0.901737   \n",
       "0  [global_mean_pool, global_max_pool]       1.344558      0.917350   \n",
       "0                    [global_max_pool]       1.412543      0.918208   \n",
       "0  [global_mean_pool, global_max_pool]       1.382416      0.919353   \n",
       "0  [global_mean_pool, global_max_pool]       1.506695      0.919771   \n",
       "0                   [global_mean_pool]       1.375359      0.920297   \n",
       "0                    [global_max_pool]       1.320622      0.923801   \n",
       "0  [global_mean_pool, global_max_pool]       1.389036      0.929248   \n",
       "0  [global_mean_pool, global_max_pool]       1.496811      0.934064   \n",
       "0  [global_mean_pool, global_max_pool]       1.462749      0.940038   \n",
       "0                    [global_max_pool]       1.545086      0.942401   \n",
       "0  [global_mean_pool, global_max_pool]       1.409926      0.945727   \n",
       "0  [global_mean_pool, global_max_pool]       1.459150      0.945975   \n",
       "0                   [global_mean_pool]       1.542044      0.952549   \n",
       "0                   [global_mean_pool]       1.531404      0.957719   \n",
       "0                    [global_max_pool]       1.559103      0.964162   \n",
       "0  [global_mean_pool, global_max_pool]       1.469752      0.964603   \n",
       "0                    [global_max_pool]       1.603891      0.967442   \n",
       "0                    [global_max_pool]       1.603379      0.970413   \n",
       "0                    [global_max_pool]       1.471861      0.971736   \n",
       "0                   [global_mean_pool]       1.864664      0.972548   \n",
       "0  [global_mean_pool, global_max_pool]       1.560182      0.975383   \n",
       "0  [global_mean_pool, global_max_pool]       1.514382      0.976927   \n",
       "0  [global_mean_pool, global_max_pool]       1.640213      0.977738   \n",
       "0                    [global_max_pool]       1.639046      0.978210   \n",
       "0                    [global_max_pool]       1.595873      0.980456   \n",
       "0                   [global_mean_pool]       1.663829      0.983118   \n",
       "0  [global_mean_pool, global_max_pool]       1.508131      0.984268   \n",
       "0                   [global_mean_pool]       1.646032      0.985311   \n",
       "0                    [global_max_pool]       1.601146      0.988182   \n",
       "0                   [global_mean_pool]       1.789288      0.988432   \n",
       "0                    [global_max_pool]       1.574251      0.988541   \n",
       "0                    [global_max_pool]       1.589022      0.990457   \n",
       "0                   [global_mean_pool]       1.853513      0.997915   \n",
       "0                   [global_mean_pool]       1.774046      1.000090   \n",
       "0                    [global_max_pool]       1.667042      1.003995   \n",
       "0                   [global_mean_pool]       1.826213      1.004823   \n",
       "0                    [global_max_pool]       1.621399      1.006339   \n",
       "0                   [global_mean_pool]       1.844461      1.006360   \n",
       "0  [global_mean_pool, global_max_pool]       1.651778      1.006659   \n",
       "0                   [global_mean_pool]       1.822558      1.006681   \n",
       "0                   [global_mean_pool]       1.703026      1.007167   \n",
       "0                    [global_max_pool]       1.694059      1.007994   \n",
       "0  [global_mean_pool, global_max_pool]       1.604228      1.011597   \n",
       "0  [global_mean_pool, global_max_pool]       1.647135      1.013511   \n",
       "0                    [global_max_pool]       1.729890      1.014345   \n",
       "0                   [global_mean_pool]       1.881705      1.014660   \n",
       "0  [global_mean_pool, global_max_pool]       1.607848      1.016571   \n",
       "0  [global_mean_pool, global_max_pool]       1.674085      1.020093   \n",
       "0                   [global_mean_pool]       1.712613      1.020882   \n",
       "0                   [global_mean_pool]       1.735936      1.021627   \n",
       "0  [global_mean_pool, global_max_pool]       1.810129      1.021747   \n",
       "0  [global_mean_pool, global_max_pool]       1.743656      1.022949   \n",
       "0                   [global_mean_pool]       1.801419      1.023469   \n",
       "0                   [global_mean_pool]       1.718177      1.025834   \n",
       "0                    [global_max_pool]       1.677117      1.026187   \n",
       "0                   [global_mean_pool]       1.880164      1.026946   \n",
       "0                   [global_mean_pool]       1.736525      1.027164   \n",
       "0  [global_mean_pool, global_max_pool]       1.794477      1.029742   \n",
       "0  [global_mean_pool, global_max_pool]       1.726943      1.032046   \n",
       "0  [global_mean_pool, global_max_pool]       1.840950      1.033493   \n",
       "0                   [global_mean_pool]       1.836079      1.034550   \n",
       "0                   [global_mean_pool]       1.891909      1.037020   \n",
       "0                   [global_mean_pool]       1.872073      1.037799   \n",
       "0                    [global_max_pool]       1.785904      1.038566   \n",
       "0  [global_mean_pool, global_max_pool]       1.800985      1.043071   \n",
       "0                    [global_max_pool]       1.847809      1.043497   \n",
       "0                   [global_mean_pool]       1.998079      1.043860   \n",
       "0                    [global_max_pool]       1.742396      1.045283   \n",
       "0                   [global_mean_pool]       1.951656      1.048711   \n",
       "0                   [global_mean_pool]       1.966939      1.052555   \n",
       "0                   [global_mean_pool]       1.984540      1.053671   \n",
       "0  [global_mean_pool, global_max_pool]       1.847012      1.053907   \n",
       "0  [global_mean_pool, global_max_pool]       1.822363      1.054378   \n",
       "0                    [global_max_pool]       1.934883      1.057842   \n",
       "0  [global_mean_pool, global_max_pool]       1.782694      1.063235   \n",
       "0                   [global_mean_pool]       2.019315      1.063300   \n",
       "0                   [global_mean_pool]       2.009363      1.069059   \n",
       "0  [global_mean_pool, global_max_pool]       1.859373      1.069263   \n",
       "0  [global_mean_pool, global_max_pool]       1.879080      1.070802   \n",
       "0  [global_mean_pool, global_max_pool]       1.869264      1.071124   \n",
       "0                   [global_mean_pool]       1.981134      1.072147   \n",
       "0  [global_mean_pool, global_max_pool]       1.851332      1.074543   \n",
       "0                    [global_max_pool]       1.939569      1.077258   \n",
       "0  [global_mean_pool, global_max_pool]       1.861713      1.077506   \n",
       "0                   [global_mean_pool]       1.856957      1.077828   \n",
       "0                   [global_mean_pool]       1.895043      1.078867   \n",
       "0                   [global_mean_pool]       2.007505      1.079502   \n",
       "0                    [global_max_pool]       1.903641      1.080142   \n",
       "0                   [global_mean_pool]       2.149580      1.080329   \n",
       "0                    [global_max_pool]       1.991922      1.093257   \n",
       "0                   [global_mean_pool]       2.194327      1.098116   \n",
       "0                    [global_max_pool]       1.952973      1.107383   \n",
       "0  [global_mean_pool, global_max_pool]       1.982429      1.135471   \n",
       "0                    [global_max_pool]       2.032514      1.137989   \n",
       "0                   [global_mean_pool]       2.427783      1.168230   \n",
       "0                    [global_max_pool]       2.084315      1.180876   \n",
       "0                    [global_max_pool]       2.182305      1.189816   \n",
       "0                    [global_max_pool]       2.114384      1.197554   \n",
       "0                    [global_max_pool]       2.340199      1.216415   \n",
       "0                    [global_max_pool]       2.734133      1.282376   \n",
       "0                    [global_max_pool]       3.061537      1.350474   \n",
       "0                    [global_max_pool]       3.569377      1.390494   \n",
       "0                    [global_max_pool]       3.704880      1.422107   \n",
       "\n",
       "                                      Combined Label  \n",
       "0            [512] - 3 - [512] - ['global_max_pool']  \n",
       "0  [512] - 3 - [512, 256] - ['global_mean_pool', ...  \n",
       "0  [512] - 4 - [512, 256] - ['global_mean_pool', ...  \n",
       "0            [256] - 4 - [512] - ['global_max_pool']  \n",
       "0  [512] - 4 - [] - ['global_mean_pool', 'global_...  \n",
       "0  [256] - 4 - [] - ['global_mean_pool', 'global_...  \n",
       "0               [256] - 4 - [] - ['global_max_pool']  \n",
       "0  [256] - 2 - [512] - ['global_mean_pool', 'glob...  \n",
       "0  [256] - 4 - [512] - ['global_mean_pool', 'glob...  \n",
       "0           [512] - 2 - [512] - ['global_mean_pool']  \n",
       "0       [512] - 3 - [512, 256] - ['global_max_pool']  \n",
       "0  [512] - 3 - [512] - ['global_mean_pool', 'glob...  \n",
       "0  [512] - 2 - [512, 256] - ['global_mean_pool', ...  \n",
       "0  [512] - 4 - [512] - ['global_mean_pool', 'glob...  \n",
       "0       [512] - 4 - [512, 256] - ['global_max_pool']  \n",
       "0  [256] - 2 - [] - ['global_mean_pool', 'global_...  \n",
       "0  [512] - 3 - [] - ['global_mean_pool', 'global_...  \n",
       "0              [256] - 4 - [] - ['global_mean_pool']  \n",
       "0              [512] - 3 - [] - ['global_mean_pool']  \n",
       "0               [256] - 3 - [] - ['global_max_pool']  \n",
       "0  [512] - 1 - [512, 256] - ['global_mean_pool', ...  \n",
       "0       [256] - 2 - [512, 256] - ['global_max_pool']  \n",
       "0            [512] - 4 - [512] - ['global_max_pool']  \n",
       "0       [256] - 3 - [512, 256] - ['global_max_pool']  \n",
       "0       [64] - 4 - [512, 256] - ['global_mean_pool']  \n",
       "0  [256] - 4 - [512, 256] - ['global_mean_pool', ...  \n",
       "0  [256] - 1 - [512, 256] - ['global_mean_pool', ...  \n",
       "0  [512] - 2 - [] - ['global_mean_pool', 'global_...  \n",
       "0             [64] - 2 - [512] - ['global_max_pool']  \n",
       "0               [512] - 3 - [] - ['global_max_pool']  \n",
       "0            [64] - 4 - [512] - ['global_mean_pool']  \n",
       "0  [256] - 3 - [512] - ['global_mean_pool', 'glob...  \n",
       "0           [256] - 3 - [512] - ['global_mean_pool']  \n",
       "0               [256] - 2 - [] - ['global_max_pool']  \n",
       "0              [256] - 1 - [] - ['global_mean_pool']  \n",
       "0            [256] - 2 - [512] - ['global_max_pool']  \n",
       "0            [512] - 2 - [512] - ['global_max_pool']  \n",
       "0      [512] - 2 - [512, 256] - ['global_mean_pool']  \n",
       "0               [64] - 1 - [] - ['global_mean_pool']  \n",
       "0             [64] - 4 - [512] - ['global_max_pool']  \n",
       "0      [512] - 4 - [512, 256] - ['global_mean_pool']  \n",
       "0               [512] - 2 - [] - ['global_max_pool']  \n",
       "0              [512] - 1 - [] - ['global_mean_pool']  \n",
       "0  [256] - 2 - [512, 256] - ['global_mean_pool', ...  \n",
       "0      [256] - 1 - [512, 256] - ['global_mean_pool']  \n",
       "0      [256] - 3 - [512, 256] - ['global_mean_pool']  \n",
       "0                [64] - 2 - [] - ['global_max_pool']  \n",
       "0  [512] - 1 - [512] - ['global_mean_pool', 'glob...  \n",
       "0  [256] - 1 - [] - ['global_mean_pool', 'global_...  \n",
       "0        [64] - 2 - [512, 256] - ['global_max_pool']  \n",
       "0      [512] - 1 - [512, 256] - ['global_mean_pool']  \n",
       "0  [512] - 1 - [] - ['global_mean_pool', 'global_...  \n",
       "0  [256] - 3 - [512, 256] - ['global_mean_pool', ...  \n",
       "0              [256] - 3 - [] - ['global_mean_pool']  \n",
       "0      [256] - 4 - [512, 256] - ['global_mean_pool']  \n",
       "0  [64] - 4 - [512, 256] - ['global_mean_pool', '...  \n",
       "0  [512] - 2 - [512] - ['global_mean_pool', 'glob...  \n",
       "0           [256] - 4 - [512] - ['global_mean_pool']  \n",
       "0            [64] - 3 - [512] - ['global_mean_pool']  \n",
       "0       [512] - 2 - [512, 256] - ['global_max_pool']  \n",
       "0           [512] - 1 - [512] - ['global_mean_pool']  \n",
       "0      [512] - 3 - [512, 256] - ['global_mean_pool']  \n",
       "0  [64] - 3 - [512, 256] - ['global_mean_pool', '...  \n",
       "0  [64] - 3 - [] - ['global_mean_pool', 'global_m...  \n",
       "0  [64] - 4 - [] - ['global_mean_pool', 'global_m...  \n",
       "0           [256] - 2 - [512] - ['global_mean_pool']  \n",
       "0               [64] - 2 - [] - ['global_mean_pool']  \n",
       "0           [512] - 3 - [512] - ['global_mean_pool']  \n",
       "0            [256] - 3 - [512] - ['global_max_pool']  \n",
       "0  [256] - 3 - [] - ['global_mean_pool', 'global_...  \n",
       "0       [256] - 4 - [512, 256] - ['global_max_pool']  \n",
       "0       [64] - 3 - [512, 256] - ['global_mean_pool']  \n",
       "0        [64] - 4 - [512, 256] - ['global_max_pool']  \n",
       "0           [256] - 1 - [512] - ['global_mean_pool']  \n",
       "0       [64] - 2 - [512, 256] - ['global_mean_pool']  \n",
       "0              [512] - 4 - [] - ['global_mean_pool']  \n",
       "0  [64] - 2 - [512] - ['global_mean_pool', 'globa...  \n",
       "0  [64] - 1 - [] - ['global_mean_pool', 'global_m...  \n",
       "0                [64] - 3 - [] - ['global_max_pool']  \n",
       "0  [64] - 4 - [512] - ['global_mean_pool', 'globa...  \n",
       "0               [64] - 3 - [] - ['global_mean_pool']  \n",
       "0              [256] - 2 - [] - ['global_mean_pool']  \n",
       "0  [64] - 2 - [] - ['global_mean_pool', 'global_m...  \n",
       "0  [64] - 1 - [512, 256] - ['global_mean_pool', '...  \n",
       "0  [64] - 3 - [512] - ['global_mean_pool', 'globa...  \n",
       "0            [64] - 1 - [512] - ['global_mean_pool']  \n",
       "0  [64] - 2 - [512, 256] - ['global_mean_pool', '...  \n",
       "0               [512] - 4 - [] - ['global_max_pool']  \n",
       "0  [256] - 1 - [512] - ['global_mean_pool', 'glob...  \n",
       "0      [256] - 2 - [512, 256] - ['global_mean_pool']  \n",
       "0              [512] - 2 - [] - ['global_mean_pool']  \n",
       "0       [64] - 1 - [512, 256] - ['global_mean_pool']  \n",
       "0                [64] - 4 - [] - ['global_max_pool']  \n",
       "0           [512] - 4 - [512] - ['global_mean_pool']  \n",
       "0        [64] - 3 - [512, 256] - ['global_max_pool']  \n",
       "0            [64] - 2 - [512] - ['global_mean_pool']  \n",
       "0             [64] - 3 - [512] - ['global_max_pool']  \n",
       "0  [64] - 1 - [512] - ['global_mean_pool', 'globa...  \n",
       "0               [256] - 1 - [] - ['global_max_pool']  \n",
       "0               [64] - 4 - [] - ['global_mean_pool']  \n",
       "0            [512] - 1 - [512] - ['global_max_pool']  \n",
       "0               [512] - 1 - [] - ['global_max_pool']  \n",
       "0       [512] - 1 - [512, 256] - ['global_max_pool']  \n",
       "0       [256] - 1 - [512, 256] - ['global_max_pool']  \n",
       "0             [64] - 1 - [512] - ['global_max_pool']  \n",
       "0                [64] - 1 - [] - ['global_max_pool']  \n",
       "0            [256] - 1 - [512] - ['global_max_pool']  \n",
       "0        [64] - 1 - [512, 256] - ['global_max_pool']  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1.sort_values(by=['lossvalue_l1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Combined Label'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fullplot1.set_index('Combined Label', inplace=True)\n",
    "\n",
    "fullplot1['lossvalue_mse'].plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newest_dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
