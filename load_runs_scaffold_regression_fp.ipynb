{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def list_files(directory):\n",
    "    files = []\n",
    "    for entry in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, entry)):\n",
    "            files.append(entry)\n",
    "    return files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"results_regression_scaffold_fp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_fp', 'model_fp_1', 'model_fp_10', 'model_fp_11', 'model_fp_12', 'model_fp_13', 'model_fp_14', 'model_fp_15', 'model_fp_16', 'model_fp_17', 'model_fp_18', 'model_fp_19', 'model_fp_2', 'model_fp_20', 'model_fp_21', 'model_fp_22', 'model_fp_23', 'model_fp_24', 'model_fp_25', 'model_fp_26', 'model_fp_27', 'model_fp_28', 'model_fp_29', 'model_fp_3', 'model_fp_30', 'model_fp_31', 'model_fp_32', 'model_fp_33', 'model_fp_34', 'model_fp_35', 'model_fp_36', 'model_fp_37', 'model_fp_38', 'model_fp_39', 'model_fp_4', 'model_fp_40', 'model_fp_41', 'model_fp_42', 'model_fp_43', 'model_fp_44', 'model_fp_45', 'model_fp_46', 'model_fp_47', 'model_fp_48', 'model_fp_49', 'model_fp_5', 'model_fp_50', 'model_fp_51', 'model_fp_52', 'model_fp_53', 'model_fp_54', 'model_fp_55', 'model_fp_56', 'model_fp_57', 'model_fp_58', 'model_fp_59', 'model_fp_6', 'model_fp_60', 'model_fp_61', 'model_fp_62', 'model_fp_63', 'model_fp_7', 'model_fp_8', 'model_fp_9']\n"
     ]
    }
   ],
   "source": [
    "files = list_files(path1)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_load = []\n",
    "import dill as pickle\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(path1, file)\n",
    "    with open(file_path, 'rb') as filel:\n",
    "        \n",
    "        loaded_data = pickle.load(filel)\n",
    "    file1_load.append(loaded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pred_df':     y_real    y_pred\n",
       "  0   -3.538 -3.177367\n",
       "  1   -3.638 -4.513988\n",
       "  2   -2.780 -3.829369\n",
       "  3   -3.168 -2.564039\n",
       "  4   -4.380 -4.098007\n",
       "  ..     ...       ...\n",
       "  44  -4.883 -2.450736\n",
       "  45  -2.350 -2.963665\n",
       "  46  -6.860 -6.479978\n",
       "  47  -1.990 -3.130623\n",
       "  48  -2.676 -3.093221\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 8.824910640716553,\n",
       "  'mean_mse': 1.260419487953186,\n",
       "  'mean_l1': 0.868361085653305,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.160 -4.492082\n",
       "  1   -3.610 -1.946076\n",
       "  2   -1.990 -1.777185\n",
       "  3   -2.932 -2.949547\n",
       "  4    1.100  0.548000\n",
       "  ..     ...       ...\n",
       "  44  -3.360 -2.897863\n",
       "  45  -3.094 -1.145451\n",
       "  46  -2.676 -3.644702\n",
       "  47  -3.401 -1.888981\n",
       "  48  -2.982 -2.911066\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 10.69330644607544,\n",
       "  'mean_mse': 2.508826971054077,\n",
       "  'mean_l1': 1.1914304494857788,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.402 -4.537632\n",
       "  1    0.300 -1.012976\n",
       "  2   -2.350 -2.966101\n",
       "  3   -6.780 -6.277754\n",
       "  4   -4.380 -2.978679\n",
       "  ..     ...       ...\n",
       "  44  -3.931 -4.845644\n",
       "  45  -3.220 -1.280503\n",
       "  46   0.522 -0.365739\n",
       "  47   0.790  0.024387\n",
       "  48  -3.401 -0.942814\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 7.03437614440918,\n",
       "  'mean_mse': 1.2795251309871674,\n",
       "  'mean_l1': 0.9040779173374176,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.932 -2.987489\n",
       "  1   -2.982 -2.625629\n",
       "  2   -5.000 -5.136026\n",
       "  3   -0.400 -2.165460\n",
       "  4   -3.401 -1.548207\n",
       "  ..     ...       ...\n",
       "  44  -7.280 -3.699891\n",
       "  45  -3.690 -5.561237\n",
       "  46  -4.370 -3.713748\n",
       "  47  -4.160 -4.571742\n",
       "  48  -6.020 -2.581654\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 9.497028589248657,\n",
       "  'mean_mse': 2.2658774852752686,\n",
       "  'mean_l1': 1.2077237367630005,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.743 -4.941751\n",
       "  1   -4.402 -4.841801\n",
       "  2   -3.590 -5.073348\n",
       "  3   -4.310 -4.540578\n",
       "  4   -1.740 -2.432336\n",
       "  ..     ...       ...\n",
       "  44  -3.460 -3.613410\n",
       "  45  -8.600 -7.366562\n",
       "  46  -3.171 -3.084636\n",
       "  47  -3.021 -4.655212\n",
       "  48  -2.070 -2.612377\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.746767997741699,\n",
       "  'mean_mse': 1.3417324423789978,\n",
       "  'mean_l1': 0.8410532772541046,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.800 -3.911466\n",
       "  1   -2.338 -3.215450\n",
       "  2   -3.620 -2.670262\n",
       "  3   -3.220 -1.915211\n",
       "  4   -6.780 -4.815713\n",
       "  ..     ...       ...\n",
       "  44  -3.168 -2.969024\n",
       "  45   0.300 -1.980963\n",
       "  46  -3.930 -2.300636\n",
       "  47  -1.716 -2.214195\n",
       "  48  -3.583 -2.436947\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 9.672325372695923,\n",
       "  'mean_mse': 2.266599416732788,\n",
       "  'mean_l1': 1.1727111339569092,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.658 -3.666290\n",
       "  1   -3.931 -6.825655\n",
       "  2   -3.800 -4.998842\n",
       "  3   -6.860 -6.817156\n",
       "  4   -1.740 -2.138830\n",
       "  ..     ...       ...\n",
       "  44  -2.160 -1.775264\n",
       "  45  -5.696 -5.291053\n",
       "  46  -4.445 -9.300735\n",
       "  47  -3.638 -3.641628\n",
       "  48   0.522 -0.365872\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.278393268585205,\n",
       "  'mean_mse': 1.2022470235824585,\n",
       "  'mean_l1': 0.803523063659668,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.696 -3.832783\n",
       "  1   -3.451 -4.439577\n",
       "  2   -4.328 -4.077935\n",
       "  3   -3.094 -1.412769\n",
       "  4   -2.281 -2.377481\n",
       "  ..     ...       ...\n",
       "  44  -4.402 -4.790846\n",
       "  45  -2.320 -2.792151\n",
       "  46   0.522 -1.466154\n",
       "  47  -4.047 -4.815562\n",
       "  48  -5.350 -4.228159\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 14.170846223831177,\n",
       "  'mean_mse': 2.2690359354019165,\n",
       "  'mean_l1': 1.1761115789413452,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.190 -4.601691\n",
       "  1   -2.943 -2.198968\n",
       "  2   -1.716 -2.006191\n",
       "  3   -2.982 -3.179783\n",
       "  4   -4.445 -9.203823\n",
       "  ..     ...       ...\n",
       "  44  -9.332 -9.974738\n",
       "  45  -3.401 -1.207457\n",
       "  46  -7.280 -4.279510\n",
       "  47  -3.290 -3.546555\n",
       "  48  -6.780 -7.178610\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.965412378311157,\n",
       "  'mean_mse': 1.4318480491638184,\n",
       "  'mean_l1': 0.9128122329711914,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.925 -3.607967\n",
       "  1   -3.060 -2.083629\n",
       "  2   -2.676 -3.682630\n",
       "  3   -3.460 -2.617416\n",
       "  4   -4.328 -3.390873\n",
       "  ..     ...       ...\n",
       "  44  -2.060 -0.985175\n",
       "  45  -3.050 -3.049834\n",
       "  46  -9.018 -4.042531\n",
       "  47  -3.658 -4.558910\n",
       "  48  -2.338 -4.523084\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.053310871124268,\n",
       "  'mean_mse': 3.330203413963318,\n",
       "  'mean_l1': 1.3816655278205872,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.040 -1.620456\n",
       "  1   -6.860 -6.432989\n",
       "  2    0.522 -0.589249\n",
       "  3   -5.400 -5.801319\n",
       "  4   -1.990 -3.087170\n",
       "  ..     ...       ...\n",
       "  44  -2.160 -2.315455\n",
       "  45  -3.931 -5.293112\n",
       "  46  -4.800 -3.648287\n",
       "  47  -2.676 -3.821277\n",
       "  48  -1.990 -2.388918\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 7.297763109207153,\n",
       "  'mean_mse': 1.2444226741790771,\n",
       "  'mean_l1': 0.8921327888965607,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.320 -2.584013\n",
       "  1   -5.350 -6.193023\n",
       "  2   -4.402 -3.999733\n",
       "  3   -4.450 -1.525633\n",
       "  4   -2.266 -2.839955\n",
       "  ..     ...       ...\n",
       "  44  -2.932 -2.213821\n",
       "  45   0.790 -0.893737\n",
       "  46  -1.960 -3.324816\n",
       "  47   0.522 -1.558444\n",
       "  48  -2.982 -2.637169\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.844631671905518,\n",
       "  'mean_mse': 2.7793633937835693,\n",
       "  'mean_l1': 1.2941816449165344,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -9.332 -9.121849\n",
       "  1   -4.445 -8.593684\n",
       "  2   -6.800 -9.157680\n",
       "  3   -5.220 -3.932360\n",
       "  4   -3.043 -3.088665\n",
       "  ..     ...       ...\n",
       "  44  -1.640 -2.105200\n",
       "  45  -1.740 -2.105200\n",
       "  46  -3.180 -2.876359\n",
       "  47  -0.742 -2.399412\n",
       "  48  -7.280 -5.445278\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 5.702757358551025,\n",
       "  'mean_mse': 1.401963472366333,\n",
       "  'mean_l1': 0.939970850944519,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.021 -3.367657\n",
       "  1   -0.600 -2.515665\n",
       "  2   -5.696 -4.260244\n",
       "  3   -1.716 -2.175004\n",
       "  4   -2.070 -2.649025\n",
       "  ..     ...       ...\n",
       "  44  -5.350 -4.316012\n",
       "  45  -2.943 -1.351591\n",
       "  46  -3.460 -2.704430\n",
       "  47  -2.120 -0.906032\n",
       "  48  -4.445 -9.292459\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.521209478378296,\n",
       "  'mean_mse': 1.3154900074005127,\n",
       "  'mean_l1': 0.9022164642810822,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.401 -1.124113\n",
       "  1   -9.332 -2.716834\n",
       "  2   -2.461 -1.112037\n",
       "  3   -2.700 -3.233859\n",
       "  4   -3.610 -2.324491\n",
       "  ..     ...       ...\n",
       "  44  -1.740 -1.115713\n",
       "  45  -7.280 -3.883686\n",
       "  46  -3.930 -1.240564\n",
       "  47  -6.800 -3.413984\n",
       "  48  -4.743 -3.509374\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 5.346834182739258,\n",
       "  'mean_mse': 2.968159556388855,\n",
       "  'mean_l1': 1.3280661702156067,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -8.040 -5.521972\n",
       "  1   -1.250 -1.460145\n",
       "  2   -3.043 -3.081899\n",
       "  3   -5.220 -4.092688\n",
       "  4   -3.638 -5.161612\n",
       "  ..     ...       ...\n",
       "  44  -4.328 -3.761436\n",
       "  45  -8.600 -7.491992\n",
       "  46  -3.880 -3.918874\n",
       "  47  -1.716 -2.586864\n",
       "  48  -4.634 -2.575458\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 3.9932122230529785,\n",
       "  'mean_mse': 1.235341727733612,\n",
       "  'mean_l1': 0.864359050989151,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -8.000 -5.339572\n",
       "  1   -1.899 -1.487169\n",
       "  2   -2.070 -2.060957\n",
       "  3   -0.400 -1.302765\n",
       "  4   -9.332 -2.482254\n",
       "  ..     ...       ...\n",
       "  44  -3.050 -3.721446\n",
       "  45  -3.610 -2.984121\n",
       "  46  -1.990 -1.511286\n",
       "  47  -3.060 -2.741305\n",
       "  48  -2.700 -3.047660\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.61155366897583,\n",
       "  'mean_mse': 3.21611487865448,\n",
       "  'mean_l1': 1.3816609382629395,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.700 -2.753587\n",
       "  1   -9.018 -7.703207\n",
       "  2   -1.990 -3.026320\n",
       "  3   -8.600 -7.216126\n",
       "  4   -3.220 -1.468019\n",
       "  ..     ...       ...\n",
       "  44  -3.583 -1.037622\n",
       "  45  -5.000 -3.742520\n",
       "  46  -5.270 -4.823545\n",
       "  47  -1.899 -1.776718\n",
       "  48  -7.800 -7.072898\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.531208038330078,\n",
       "  'mean_mse': 1.3165460228919983,\n",
       "  'mean_l1': 0.8913021087646484,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -7.800 -5.066391\n",
       "  1   -3.800 -4.098657\n",
       "  2   -6.680 -6.471828\n",
       "  3    1.100 -0.301191\n",
       "  4   -3.050 -3.080635\n",
       "  ..     ...       ...\n",
       "  44  -3.180 -2.932105\n",
       "  45  -3.690 -5.030282\n",
       "  46  -3.672 -2.030265\n",
       "  47  -3.220 -1.553605\n",
       "  48  -2.932 -1.739277\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.836679458618164,\n",
       "  'mean_mse': 3.0150983333587646,\n",
       "  'mean_l1': 1.3056879043579102,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real     y_pred\n",
       "  0   -2.100  -2.641701\n",
       "  1   -2.461  -2.020446\n",
       "  2   -3.043  -3.133437\n",
       "  3   -4.445  -9.085897\n",
       "  4   -3.620  -1.784068\n",
       "  ..     ...        ...\n",
       "  44  -9.332 -12.458233\n",
       "  45  -1.740  -1.787953\n",
       "  46  -4.450  -3.111633\n",
       "  47  -1.990  -2.596895\n",
       "  48  -3.931  -4.136377\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 5.625933647155762,\n",
       "  'mean_mse': 1.2883383631706238,\n",
       "  'mean_l1': 0.8344023823738098,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.850 -2.818008\n",
       "  1   -2.943 -1.494877\n",
       "  2   -3.460 -3.161139\n",
       "  3   -2.932 -2.299574\n",
       "  4   -6.237 -4.457922\n",
       "  ..     ...       ...\n",
       "  44  -2.120 -0.450571\n",
       "  45  -3.043 -2.289408\n",
       "  46  -2.920 -2.393924\n",
       "  47  -6.860 -9.052976\n",
       "  48  -3.800 -3.390234\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 9.977100849151611,\n",
       "  'mean_mse': 2.687559127807617,\n",
       "  'mean_l1': 1.2874169945716858,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real     y_pred\n",
       "  0   -0.400  -1.400123\n",
       "  1   -9.332 -10.026315\n",
       "  2   -4.743  -4.439075\n",
       "  3   -2.932  -1.727385\n",
       "  4   -2.943  -1.527054\n",
       "  ..     ...        ...\n",
       "  44  -2.120  -0.779484\n",
       "  45  -4.799  -3.900093\n",
       "  46  -1.040  -1.779694\n",
       "  47  -5.270  -3.375180\n",
       "  48  -3.590  -4.401420\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.36760139465332,\n",
       "  'mean_mse': 1.4360724687576294,\n",
       "  'mean_l1': 0.9199962019920349,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.676 -3.288837\n",
       "  1   -2.780 -4.094871\n",
       "  2   -3.930 -0.932465\n",
       "  3   -4.370 -3.538606\n",
       "  4   -4.634 -3.073108\n",
       "  ..     ...       ...\n",
       "  44   0.300 -1.608628\n",
       "  45  -3.043 -2.248196\n",
       "  46  -5.350 -3.776478\n",
       "  47  -1.990 -1.501378\n",
       "  48  -4.120 -3.024565\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 5.900323152542114,\n",
       "  'mean_mse': 2.663520097732544,\n",
       "  'mean_l1': 1.2844579815864563,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.360 -3.068374\n",
       "  1   -6.726 -5.737986\n",
       "  2   -2.349 -2.616812\n",
       "  3   -2.461 -1.216501\n",
       "  4   -6.800 -2.445741\n",
       "  ..     ...       ...\n",
       "  44  -3.460 -3.368721\n",
       "  45  -5.190 -3.781995\n",
       "  46  -4.402 -4.363638\n",
       "  47  -4.805 -2.846268\n",
       "  48  -1.716 -3.496886\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 14.088936567306519,\n",
       "  'mean_mse': 2.102535843849182,\n",
       "  'mean_l1': 1.1058465242385864,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.743 -4.798810\n",
       "  1   -3.290 -3.432935\n",
       "  2   -2.266 -1.136325\n",
       "  3   -3.880 -3.476504\n",
       "  4   -3.094 -2.765007\n",
       "  ..     ...       ...\n",
       "  44  -4.120 -4.858255\n",
       "  45  -3.931 -5.944041\n",
       "  46  -3.672 -2.774704\n",
       "  47  -4.160 -4.597228\n",
       "  48  -1.960 -2.328084\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.246304988861084,\n",
       "  'mean_mse': 1.2411150932312012,\n",
       "  'mean_l1': 0.8328036367893219,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.800 -1.412752\n",
       "  1   -2.120 -0.483557\n",
       "  2   -2.070 -3.263421\n",
       "  3   -4.445 -7.791658\n",
       "  4   -3.171 -2.757381\n",
       "  ..     ...       ...\n",
       "  44  -7.280 -4.377685\n",
       "  45  -6.780 -8.288338\n",
       "  46  -2.943 -1.788942\n",
       "  47  -4.632 -2.859222\n",
       "  48  -3.021 -3.849588\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.474838972091675,\n",
       "  'mean_mse': 3.2860984802246094,\n",
       "  'mean_l1': 1.3867407441139221,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 2,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.640 -1.908719\n",
       "  1   -2.920 -3.234834\n",
       "  2   -4.160 -4.099567\n",
       "  3   -1.990 -2.395549\n",
       "  4    0.300 -1.028610\n",
       "  ..     ...       ...\n",
       "  44  -3.930 -1.463579\n",
       "  45  -2.780 -3.662611\n",
       "  46  -4.805 -4.245345\n",
       "  47  -3.360 -3.692518\n",
       "  48  -2.461 -2.526643\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.562455415725708,\n",
       "  'mean_mse': 1.4168900847434998,\n",
       "  'mean_l1': 0.8985206484794617,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.676 -4.638147\n",
       "  1   -3.220 -1.513706\n",
       "  2   -4.047 -5.709466\n",
       "  3   -3.620 -4.150795\n",
       "  4   -4.743 -3.794914\n",
       "  ..     ...       ...\n",
       "  44  -4.445 -8.377129\n",
       "  45  -6.680 -7.389640\n",
       "  46  -5.350 -4.595780\n",
       "  47  -8.600 -4.440186\n",
       "  48  -7.280 -5.223577\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.797054767608643,\n",
       "  'mean_mse': 3.520938515663147,\n",
       "  'mean_l1': 1.37895268201828,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -6.800 -8.563553\n",
       "  1   -5.915 -5.682066\n",
       "  2   -4.380 -4.536295\n",
       "  3   -5.220 -3.726198\n",
       "  4   -3.451 -3.878020\n",
       "  ..     ...       ...\n",
       "  44  -4.799 -4.115639\n",
       "  45  -0.400 -1.240192\n",
       "  46  -3.538 -3.774561\n",
       "  47  -4.800 -3.798867\n",
       "  48  -3.460 -3.695523\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 5.816666126251221,\n",
       "  'mean_mse': 1.2615724205970764,\n",
       "  'mean_l1': 0.8976225256919861,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.590 -3.183518\n",
       "  1   -6.780 -7.576377\n",
       "  2   -4.173 -3.591889\n",
       "  3   -7.280 -4.650173\n",
       "  4   -2.060 -1.900684\n",
       "  ..     ...       ...\n",
       "  44   0.522 -1.455151\n",
       "  45  -3.290 -4.432858\n",
       "  46  -4.950 -1.667487\n",
       "  47  -0.400 -1.379283\n",
       "  48  -3.931 -3.820985\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 6.118316888809204,\n",
       "  'mean_mse': 2.9837342500686646,\n",
       "  'mean_l1': 1.2986893057823181,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.982 -2.437240\n",
       "  1   -2.070 -3.025030\n",
       "  2   -3.451 -4.342694\n",
       "  3   -4.632 -3.899774\n",
       "  4   -5.270 -4.412911\n",
       "  ..     ...       ...\n",
       "  44  -3.050 -2.609075\n",
       "  45  -3.180 -2.714586\n",
       "  46  -4.799 -3.951775\n",
       "  47  -4.800 -3.537934\n",
       "  48  -4.047 -4.304968\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.339007139205933,\n",
       "  'mean_mse': 1.3946863412857056,\n",
       "  'mean_l1': 0.893341451883316,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.270 -4.008219\n",
       "  1   -3.060 -1.510607\n",
       "  2   -4.328 -2.848480\n",
       "  3   -8.040 -4.809152\n",
       "  4   -3.620 -2.763531\n",
       "  ..     ...       ...\n",
       "  44  -2.780 -4.662137\n",
       "  45  -3.538 -2.697820\n",
       "  46  -2.943 -1.502413\n",
       "  47  -6.860 -6.984195\n",
       "  48  -3.171 -4.241421\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 5.575016260147095,\n",
       "  'mean_mse': 3.093811511993408,\n",
       "  'mean_l1': 1.3295686841011047,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.883 -2.834028\n",
       "  1   -3.931 -6.748542\n",
       "  2   -4.632 -3.761545\n",
       "  3   -6.726 -6.962881\n",
       "  4   -1.960 -2.221908\n",
       "  ..     ...       ...\n",
       "  44  -5.696 -4.432421\n",
       "  45  -1.850 -1.615945\n",
       "  46  -2.920 -3.630056\n",
       "  47  -3.021 -3.578181\n",
       "  48  -2.281 -2.415603\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 3.853367805480957,\n",
       "  'mean_mse': 1.30672949552536,\n",
       "  'mean_l1': 0.8729195296764374,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.990 -1.263133\n",
       "  1   -1.740 -1.505754\n",
       "  2   -2.060 -1.537136\n",
       "  3   -9.332 -1.830559\n",
       "  4   -9.018 -3.382406\n",
       "  ..     ...       ...\n",
       "  44  -4.310 -4.450697\n",
       "  45  -3.538 -4.019846\n",
       "  46   0.522 -0.935788\n",
       "  47  -3.220 -1.915990\n",
       "  48  -3.021 -3.172379\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 3.982146978378296,\n",
       "  'mean_mse': 3.3326414823532104,\n",
       "  'mean_l1': 1.3510385751724243,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.460 -3.112115\n",
       "  1   -4.120 -4.371861\n",
       "  2   -4.370 -3.742828\n",
       "  3   -5.350 -4.054357\n",
       "  4   -4.883 -2.588429\n",
       "  ..     ...       ...\n",
       "  44  -3.460 -2.920146\n",
       "  45  -2.982 -2.615854\n",
       "  46  -3.246 -4.840466\n",
       "  47  -3.360 -3.065413\n",
       "  48  -0.600 -2.200093\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.563686370849609,\n",
       "  'mean_mse': 1.2886634469032288,\n",
       "  'mean_l1': 0.8565435707569122,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.672 -2.712796\n",
       "  1   -2.461 -2.297080\n",
       "  2   -7.280 -4.427107\n",
       "  3   -2.070 -2.797875\n",
       "  4   -4.402 -2.937149\n",
       "  ..     ...       ...\n",
       "  44  -3.460 -3.308253\n",
       "  45  -3.120 -3.606189\n",
       "  46  -3.050 -1.896827\n",
       "  47  -4.883 -2.236296\n",
       "  48  -3.538 -3.191056\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.917760372161865,\n",
       "  'mean_mse': 1.2543936967849731,\n",
       "  'mean_l1': 0.8590366840362549,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.043 -2.632688\n",
       "  1   -0.742 -2.981218\n",
       "  2   -2.100 -2.703861\n",
       "  3   -4.310 -3.557357\n",
       "  4   -1.990 -2.206038\n",
       "  ..     ...       ...\n",
       "  44  -6.800 -1.917950\n",
       "  45  -9.018 -3.381735\n",
       "  46  -2.281 -2.478775\n",
       "  47  -0.400 -1.303465\n",
       "  48  -3.880 -2.323894\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 5.478577613830566,\n",
       "  'mean_mse': 3.4915305376052856,\n",
       "  'mean_l1': 1.415131688117981,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.451 -4.433054\n",
       "  1   -3.672 -2.817491\n",
       "  2   -4.883 -2.369626\n",
       "  3   -3.401 -0.973235\n",
       "  4    0.300 -1.185221\n",
       "  ..     ...       ...\n",
       "  44  -3.590 -3.746595\n",
       "  45  -3.021 -3.698141\n",
       "  46  -1.040 -1.970556\n",
       "  47  -5.190 -3.541119\n",
       "  48  -4.450 -3.240919\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 6.5517425537109375,\n",
       "  'mean_mse': 1.1953858733177185,\n",
       "  'mean_l1': 0.820043683052063,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.060 -2.570115\n",
       "  1   -5.000 -3.748694\n",
       "  2   -4.376 -4.746921\n",
       "  3   -4.173 -3.880553\n",
       "  4   -2.943 -2.222634\n",
       "  ..     ...       ...\n",
       "  44  -5.270 -3.082808\n",
       "  45  -1.960 -2.804257\n",
       "  46  -4.160 -3.164501\n",
       "  47  -3.672 -3.120190\n",
       "  48  -5.270 -4.050067\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 8.98731780052185,\n",
       "  'mean_mse': 2.787351131439209,\n",
       "  'mean_l1': 1.2657793164253235,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.982 -3.153384\n",
       "  1   -6.800 -8.051967\n",
       "  2   -4.380 -4.510991\n",
       "  3   -1.899 -1.908588\n",
       "  4   -4.925 -4.160434\n",
       "  ..     ...       ...\n",
       "  44  -8.040 -6.178821\n",
       "  45  -2.932 -2.349499\n",
       "  46  -4.120 -3.560381\n",
       "  47  -4.402 -3.774892\n",
       "  48  -2.700 -2.585171\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.716123104095459,\n",
       "  'mean_mse': 1.1780560612678528,\n",
       "  'mean_l1': 0.8311842381954193,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.060 -0.983884\n",
       "  1   -2.943 -2.279669\n",
       "  2   -1.040 -2.218151\n",
       "  3   -5.696 -4.073922\n",
       "  4   -5.270 -3.708035\n",
       "  ..     ...       ...\n",
       "  44  -3.460 -2.385732\n",
       "  45  -3.538 -2.869262\n",
       "  46  -3.060 -2.563839\n",
       "  47  -2.982 -3.017722\n",
       "  48  -3.021 -3.106838\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 5.551095962524414,\n",
       "  'mean_mse': 3.3164124488830566,\n",
       "  'mean_l1': 1.360421061515808,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.060 -0.889071\n",
       "  1   -3.094 -2.501825\n",
       "  2   -1.640 -1.686179\n",
       "  3   -3.021 -3.934759\n",
       "  4   -5.400 -4.759060\n",
       "  ..     ...       ...\n",
       "  44  -4.450 -2.674295\n",
       "  45  -3.246 -2.843008\n",
       "  46  -3.690 -4.109658\n",
       "  47  -1.716 -2.631259\n",
       "  48  -5.220 -3.996414\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.424541711807251,\n",
       "  'mean_mse': 1.2686252295970917,\n",
       "  'mean_l1': 0.8570969998836517,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -7.280 -5.290220\n",
       "  1   -3.220 -2.331299\n",
       "  2   -4.883 -2.993666\n",
       "  3   -4.328 -4.736863\n",
       "  4   -2.120 -1.236274\n",
       "  ..     ...       ...\n",
       "  44  -5.190 -2.548902\n",
       "  45  -7.800 -4.745606\n",
       "  46  -5.270 -3.865287\n",
       "  47  -4.370 -2.782226\n",
       "  48  -6.780 -8.023682\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.323369979858398,\n",
       "  'mean_mse': 3.3713899850845337,\n",
       "  'mean_l1': 1.368656039237976,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 3,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.400 -5.027822\n",
       "  1   -3.220 -2.003858\n",
       "  2   -4.376 -3.743642\n",
       "  3   -1.640 -1.504352\n",
       "  4   -2.780 -3.817333\n",
       "  ..     ...       ...\n",
       "  44  -5.270 -4.531815\n",
       "  45  -8.000 -7.394183\n",
       "  46  -3.460 -4.322510\n",
       "  47   1.100  0.655431\n",
       "  48  -1.990 -2.900615\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 5.675699949264526,\n",
       "  'mean_mse': 1.4028814435005188,\n",
       "  'mean_l1': 0.91203573346138,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.350 -3.468583\n",
       "  1   -3.460 -3.484182\n",
       "  2   -2.676 -4.497004\n",
       "  3   -2.320 -1.627857\n",
       "  4   -2.982 -2.612453\n",
       "  ..     ...       ...\n",
       "  44  -5.270 -5.224816\n",
       "  45  -4.743 -3.361066\n",
       "  46  -4.450 -1.704550\n",
       "  47  -5.000 -2.503428\n",
       "  48  -4.160 -2.568097\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 14.723313093185425,\n",
       "  'mean_mse': 3.3357430696487427,\n",
       "  'mean_l1': 1.3819507956504822,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -1.990 -1.489863\n",
       "  1   -3.690 -5.312229\n",
       "  2   -8.600 -6.343436\n",
       "  3   -6.780 -4.633800\n",
       "  4   -5.190 -3.757918\n",
       "  ..     ...       ...\n",
       "  44  -2.676 -3.664184\n",
       "  45  -1.250 -2.049209\n",
       "  46  -0.600 -3.260173\n",
       "  47  -4.160 -4.133130\n",
       "  48  -2.281 -2.633340\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 6.555711269378662,\n",
       "  'mean_mse': 2.0705403685569763,\n",
       "  'mean_l1': 1.1222276091575623,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.690 -4.855688\n",
       "  1   -2.266 -1.988808\n",
       "  2   -3.401 -1.546229\n",
       "  3   -4.310 -4.423486\n",
       "  4   -7.800 -6.821087\n",
       "  ..     ...       ...\n",
       "  44  -4.376 -3.407336\n",
       "  45  -5.270 -6.040029\n",
       "  46  -1.800 -4.471618\n",
       "  47  -4.370 -3.572083\n",
       "  48  -7.280 -4.522371\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 7.86655068397522,\n",
       "  'mean_mse': 1.530912160873413,\n",
       "  'mean_l1': 0.9307903051376343,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -7.280 -4.342679\n",
       "  1   -4.883 -4.510772\n",
       "  2   -2.100 -3.285104\n",
       "  3   -8.600 -5.771833\n",
       "  4   -2.676 -4.454759\n",
       "  ..     ...       ...\n",
       "  44  -6.680 -6.466676\n",
       "  45  -2.461 -0.793409\n",
       "  46  -1.716 -3.358607\n",
       "  47  -3.880 -2.840051\n",
       "  48  -2.920 -2.904366\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 8.129328966140747,\n",
       "  'mean_mse': 3.136576533317566,\n",
       "  'mean_l1': 1.3052020072937012,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.634 -3.250684\n",
       "  1   -3.050 -2.431957\n",
       "  2   -3.168 -2.316820\n",
       "  3   -3.401 -1.118134\n",
       "  4   -1.990 -2.727618\n",
       "  ..     ...       ...\n",
       "  44  -1.740 -1.674292\n",
       "  45  -4.376 -3.208429\n",
       "  46  -5.696 -4.501025\n",
       "  47  -3.120 -3.937020\n",
       "  48  -2.700 -2.314668\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.320711612701416,\n",
       "  'mean_mse': 1.3783428072929382,\n",
       "  'mean_l1': 0.9180383384227753,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.281 -1.819959\n",
       "  1   -6.800 -3.654150\n",
       "  2   -3.931 -5.557870\n",
       "  3   -2.120 -1.016507\n",
       "  4   -1.716 -2.986334\n",
       "  ..     ...       ...\n",
       "  44  -3.050 -2.940768\n",
       "  45  -6.237 -2.995627\n",
       "  46  -3.290 -5.592459\n",
       "  47  -6.860 -6.605570\n",
       "  48  -2.350 -3.305716\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 9.032859086990356,\n",
       "  'mean_mse': 3.1473453044891357,\n",
       "  'mean_l1': 1.3427836298942566,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.060 -1.263405\n",
       "  1   -3.880 -3.418984\n",
       "  2   -3.620 -3.070411\n",
       "  3   -3.451 -4.459217\n",
       "  4   -4.370 -3.330178\n",
       "  ..     ...       ...\n",
       "  44  -1.850 -1.943155\n",
       "  45  -1.899 -1.540088\n",
       "  46  -4.445 -9.535910\n",
       "  47  -5.270 -4.830724\n",
       "  48  -5.270 -6.163813\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 5.377845048904419,\n",
       "  'mean_mse': 1.4008880853652954,\n",
       "  'mean_l1': 0.8785311579704285,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -6.237 -2.731023\n",
       "  1   -4.925 -4.978593\n",
       "  2   -3.120 -2.664548\n",
       "  3   -2.700 -3.834940\n",
       "  4   -4.402 -2.967402\n",
       "  ..     ...       ...\n",
       "  44  -1.250 -0.980451\n",
       "  45  -3.590 -5.560530\n",
       "  46  -3.638 -3.267975\n",
       "  47   0.790 -0.446932\n",
       "  48  -4.799 -3.092177\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 4.538740158081055,\n",
       "  'mean_mse': 3.3919479846954346,\n",
       "  'mean_l1': 1.39096337556839,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.700 -2.626265\n",
       "  1    0.790  0.512793\n",
       "  2   -4.805 -4.121950\n",
       "  3   -2.281 -2.112057\n",
       "  4   -2.266 -1.194646\n",
       "  ..     ...       ...\n",
       "  44  -2.349 -1.744937\n",
       "  45  -3.050 -2.334957\n",
       "  46  -4.402 -3.345642\n",
       "  47  -3.460 -2.991694\n",
       "  48  -3.620 -2.350337\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 5.9140753746032715,\n",
       "  'mean_mse': 1.4348140358924866,\n",
       "  'mean_l1': 0.914264976978302,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -6.020 -4.184669\n",
       "  1   -4.634 -2.894659\n",
       "  2   -1.716 -2.830569\n",
       "  3   -2.120 -0.376805\n",
       "  4   -4.402 -2.684580\n",
       "  ..     ...       ...\n",
       "  44  -1.800 -2.558084\n",
       "  45  -3.360 -3.601179\n",
       "  46  -2.920 -2.185213\n",
       "  47  -2.932 -2.447602\n",
       "  48  -8.000 -6.209561\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 6.260335206985474,\n",
       "  'mean_mse': 3.708987593650818,\n",
       "  'mean_l1': 1.4405238032341003,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -2.349 -2.129426\n",
       "  1   -4.310 -4.404997\n",
       "  2   -6.680 -5.697258\n",
       "  3   -2.920 -4.115543\n",
       "  4   -2.700 -3.642478\n",
       "  ..     ...       ...\n",
       "  44  -2.281 -2.117776\n",
       "  45  -8.040 -6.180750\n",
       "  46  -2.932 -2.890579\n",
       "  47  -5.270 -4.030405\n",
       "  48  -2.120 -0.400831\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 10.545974731445312,\n",
       "  'mean_mse': 1.3458251953125,\n",
       "  'mean_l1': 0.8664187788963318,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.171 -4.852286\n",
       "  1   -5.400 -2.582011\n",
       "  2   -5.270 -4.376520\n",
       "  3   -5.190 -2.803237\n",
       "  4   -3.460 -2.934569\n",
       "  ..     ...       ...\n",
       "  44   1.100  0.411988\n",
       "  45  -3.583 -1.884717\n",
       "  46  -4.310 -4.826685\n",
       "  47   0.522 -0.989818\n",
       "  48  -2.943 -2.506054\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 13.096108198165894,\n",
       "  'mean_mse': 2.9904037714004517,\n",
       "  'mean_l1': 1.266721785068512,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048, 1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0    0.522 -0.397582\n",
       "  1   -4.925 -4.391644\n",
       "  2   -1.250 -1.265998\n",
       "  3   -4.743 -4.298471\n",
       "  4   -3.171 -2.657422\n",
       "  ..     ...       ...\n",
       "  44  -8.000 -7.135279\n",
       "  45  -4.445 -9.465459\n",
       "  46  -6.680 -5.563567\n",
       "  47  -1.990 -3.117344\n",
       "  48  -3.180 -2.671570\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 3.7801311016082764,\n",
       "  'mean_mse': 1.2235814929008484,\n",
       "  'mean_l1': 0.8304733335971832,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.460 -2.718651\n",
       "  1   -4.402 -2.961282\n",
       "  2   -6.680 -4.765222\n",
       "  3   -4.925 -3.917211\n",
       "  4   -3.460 -2.855791\n",
       "  ..     ...       ...\n",
       "  44  -1.716 -2.322283\n",
       "  45  -0.742 -2.021773\n",
       "  46  -2.349 -1.783457\n",
       "  47  -2.266 -1.325949\n",
       "  48  -3.880 -3.312630\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 8.098810195922852,\n",
       "  'mean_mse': 1.506370186805725,\n",
       "  'mean_l1': 0.9753918051719666,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -5.270 -2.883429\n",
       "  1   -2.932 -2.379459\n",
       "  2   -4.800 -3.023060\n",
       "  3   -3.290 -5.502899\n",
       "  4   -3.120 -2.349803\n",
       "  ..     ...       ...\n",
       "  44  -4.380 -3.862235\n",
       "  45  -1.800 -2.857163\n",
       "  46  -3.930 -1.444272\n",
       "  47  -4.799 -3.326181\n",
       "  48  -4.173 -4.283883\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 13.201232671737671,\n",
       "  'mean_mse': 3.0520761013031006,\n",
       "  'mean_l1': 1.3272595405578613,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024, 512],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.925 -4.662123\n",
       "  1   -8.040 -5.651703\n",
       "  2   -4.634 -3.098840\n",
       "  3   -3.290 -4.223636\n",
       "  4   -1.990 -2.160984\n",
       "  ..     ...       ...\n",
       "  44   1.100 -0.209766\n",
       "  45  -3.590 -4.760464\n",
       "  46  -0.600 -2.190494\n",
       "  47  -2.982 -3.525240\n",
       "  48   0.790 -0.130919\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 6.293023586273193,\n",
       "  'mean_mse': 1.3197973370552063,\n",
       "  'mean_l1': 0.8548278212547302,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -0.400 -1.090717\n",
       "  1   -3.043 -3.260050\n",
       "  2   -4.120 -2.774908\n",
       "  3   -2.676 -4.812764\n",
       "  4   -3.060 -2.609371\n",
       "  ..     ...       ...\n",
       "  44  -3.094 -1.728328\n",
       "  45   0.300 -1.087625\n",
       "  46   1.100 -0.075581\n",
       "  47  -6.680 -5.570860\n",
       "  48  -4.634 -2.740783\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 6.305643796920776,\n",
       "  'mean_mse': 3.509864568710327,\n",
       "  'mean_l1': 1.3919368982315063,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 4,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.451 -4.182050\n",
       "  1   -6.020 -2.793172\n",
       "  2   -1.960 -5.795697\n",
       "  3   -3.401 -1.810081\n",
       "  4   -5.270 -5.440484\n",
       "  ..     ...       ...\n",
       "  44  -4.160 -4.707475\n",
       "  45  -2.320 -2.878900\n",
       "  46  -6.237 -3.436713\n",
       "  47  -2.943 -2.184424\n",
       "  48  -4.376 -2.431652\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 11.028058767318726,\n",
       "  'mean_mse': 2.645894408226013,\n",
       "  'mean_l1': 1.2460222244262695,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 1024,\n",
       "  'linear_layers': [1024],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -3.060 -2.354903\n",
       "  1   -3.538 -2.999428\n",
       "  2   -2.461 -2.446661\n",
       "  3   -4.445 -8.864798\n",
       "  4   -3.120 -3.540743\n",
       "  ..     ...       ...\n",
       "  44  -0.742 -0.893926\n",
       "  45  -4.380 -4.184017\n",
       "  46  -3.360 -3.122902\n",
       "  47  -3.043 -3.242769\n",
       "  48  -3.690 -5.001575\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 6.768104553222656,\n",
       "  'mean_mse': 1.1310542821884155,\n",
       "  'mean_l1': 0.8003930747509003,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': True,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )},\n",
       " {'pred_df':     y_real    y_pred\n",
       "  0   -4.800 -4.129080\n",
       "  1   -4.743 -3.975988\n",
       "  2   -3.290 -5.648259\n",
       "  3   -2.120 -0.574024\n",
       "  4   -3.800 -3.034428\n",
       "  ..     ...       ...\n",
       "  44  -8.600 -6.313016\n",
       "  45  -1.990 -1.688614\n",
       "  46  -3.401 -1.339311\n",
       "  47  -3.050 -2.107304\n",
       "  48  -2.070 -1.611649\n",
       "  \n",
       "  [113 rows x 2 columns],\n",
       "  'el_time': 16.648772478103638,\n",
       "  'mean_mse': 2.3313441276550293,\n",
       "  'mean_l1': 1.1940023303031921,\n",
       "  'apply_scaffold_split': True,\n",
       "  'radius': 1,\n",
       "  'fpSize': 2048,\n",
       "  'linear_layers': [2048],\n",
       "  'create_count_fp': False,\n",
       "  'apply_random_aggregations': False,\n",
       "  'learning_rate': 0.001,\n",
       "  'model_type': 'GNN',\n",
       "  'model': FPN(\n",
       "    (nns): ModuleList(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = file1_load[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_df':     y_real    y_pred\n",
       " 0   -3.538 -3.177367\n",
       " 1   -3.638 -4.513988\n",
       " 2   -2.780 -3.829369\n",
       " 3   -3.168 -2.564039\n",
       " 4   -4.380 -4.098007\n",
       " ..     ...       ...\n",
       " 44  -4.883 -2.450736\n",
       " 45  -2.350 -2.963665\n",
       " 46  -6.860 -6.479978\n",
       " 47  -1.990 -3.130623\n",
       " 48  -2.676 -3.093221\n",
       " \n",
       " [113 rows x 2 columns],\n",
       " 'el_time': 8.824910640716553,\n",
       " 'mean_mse': 1.260419487953186,\n",
       " 'mean_l1': 0.868361085653305,\n",
       " 'apply_scaffold_split': True,\n",
       " 'radius': 1,\n",
       " 'fpSize': 1024,\n",
       " 'linear_layers': [2048],\n",
       " 'create_count_fp': True,\n",
       " 'apply_random_aggregations': False,\n",
       " 'learning_rate': 0.001,\n",
       " 'model_type': 'GNN',\n",
       " 'model': FPN(\n",
       "   (nns): ModuleList(\n",
       "     (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "   )\n",
       "   (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "   (relu): ReLU()\n",
       " )}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_real</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.538</td>\n",
       "      <td>-3.177367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.638</td>\n",
       "      <td>-4.513988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.780</td>\n",
       "      <td>-3.829369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.168</td>\n",
       "      <td>-2.564039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.380</td>\n",
       "      <td>-4.098007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-4.883</td>\n",
       "      <td>-2.450736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-2.350</td>\n",
       "      <td>-2.963665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-6.860</td>\n",
       "      <td>-6.479978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-1.990</td>\n",
       "      <td>-3.130623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-2.676</td>\n",
       "      <td>-3.093221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_real    y_pred\n",
       "0   -3.538 -3.177367\n",
       "1   -3.638 -4.513988\n",
       "2   -2.780 -3.829369\n",
       "3   -3.168 -2.564039\n",
       "4   -4.380 -4.098007\n",
       "..     ...       ...\n",
       "44  -4.883 -2.450736\n",
       "45  -2.350 -2.963665\n",
       "46  -6.860 -6.479978\n",
       "47  -1.990 -3.130623\n",
       "48  -2.676 -3.093221\n",
       "\n",
       "[113 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff[\"pred_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_df':     y_real    y_pred\n",
       " 0   -3.538 -3.177367\n",
       " 1   -3.638 -4.513988\n",
       " 2   -2.780 -3.829369\n",
       " 3   -3.168 -2.564039\n",
       " 4   -4.380 -4.098007\n",
       " ..     ...       ...\n",
       " 44  -4.883 -2.450736\n",
       " 45  -2.350 -2.963665\n",
       " 46  -6.860 -6.479978\n",
       " 47  -1.990 -3.130623\n",
       " 48  -2.676 -3.093221\n",
       " \n",
       " [113 rows x 2 columns],\n",
       " 'el_time': 8.824910640716553,\n",
       " 'mean_mse': 1.260419487953186,\n",
       " 'mean_l1': 0.868361085653305,\n",
       " 'apply_scaffold_split': True,\n",
       " 'radius': 1,\n",
       " 'fpSize': 1024,\n",
       " 'linear_layers': [2048],\n",
       " 'create_count_fp': True,\n",
       " 'apply_random_aggregations': False,\n",
       " 'learning_rate': 0.001,\n",
       " 'model_type': 'GNN',\n",
       " 'model': FPN(\n",
       "   (nns): ModuleList(\n",
       "     (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "   )\n",
       "   (out): Linear(in_features=2048, out_features=1, bias=True)\n",
       "   (relu): ReLU()\n",
       " )}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_extract = ['create_count_fp', 'radius', 'fpSize', 'linear_layers']\n",
    "\n",
    "plot1 = []\n",
    "for run in file1_load:\n",
    "    lossvalue_mse = run[\"mean_mse\"]\n",
    "    lossvalue_l1 = run[\"mean_l1\"]\n",
    "    \n",
    "    extracted_dict = {key: run[key] for key in keys_to_extract if key in run}\n",
    "    extracted_dict[\"lossvalue_mse\"] = lossvalue_mse\n",
    "    extracted_dict[\"lossvalue_l1\"] = lossvalue_l1\n",
    "    df = pd.DataFrame([extracted_dict])\n",
    "    #plot1.append([lossvalue, df])\n",
    "    plot1.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    1024        [2048]       1.260419      0.868361,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    1024        [2048]       2.508827       1.19143,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       1    2048  [2048, 1024, 512]       1.279525   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.904078  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       1    2048  [2048, 1024, 512]       2.265877   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.207724  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    2048   [1024, 512]       1.341732      0.841053,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    2048   [1024, 512]       2.266599      1.172711,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    2048        [1024]       1.202247      0.803523,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    2048        [1024]       2.269036      1.176112,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    1024        [2048]       1.431848      0.912812,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    1024        [2048]       3.330203      1.381666,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       2    1024  [2048, 1024, 512]       1.244423   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.892133  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       2    1024  [2048, 1024, 512]       2.779363   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.294182  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       1    1024  [2048, 1024, 512]       1.401963   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.939971  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    1024   [1024, 512]        1.31549      0.902216,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    1024   [1024, 512]        2.96816      1.328066,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    1024        [1024]       1.235342      0.864359,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    1024        [1024]       3.216115      1.381661,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    2048        [2048]       1.316546      0.891302,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    2048        [2048]       3.015098      1.305688,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       2    2048  [2048, 1024, 512]       1.288338   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.834402  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       2    2048  [2048, 1024, 512]       2.687559   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.287417  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    2048   [1024, 512]       1.436072      0.919996,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    2048   [1024, 512]        2.66352      1.284458,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       1    1024  [2048, 1024, 512]       2.102536   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.105847  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       2    2048        [1024]       1.241115      0.832804,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       2    2048        [1024]       3.286098      1.386741,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    1024        [2048]        1.41689      0.898521,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    1024        [2048]       3.520939      1.378953,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       3    1024  [2048, 1024, 512]       1.261572   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.897623  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       3    1024  [2048, 1024, 512]       2.983734   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.298689  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    1024   [1024, 512]       1.394686      0.893341,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    1024   [1024, 512]       3.093812      1.329569,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    1024        [1024]       1.306729       0.87292,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    1024        [1024]       3.332641      1.351039,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    1024   [1024, 512]       1.288663      0.856544,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    2048        [2048]       1.254394      0.859037,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    2048        [2048]       3.491531      1.415132,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       3    2048  [2048, 1024, 512]       1.195386   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.820044  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       3    2048  [2048, 1024, 512]       2.787351   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.265779  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    2048   [1024, 512]       1.178056      0.831184,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    2048   [1024, 512]       3.316412      1.360421,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       3    2048        [1024]       1.268625      0.857097,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       3    2048        [1024]        3.37139      1.368656,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    1024        [2048]       1.402881      0.912036,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    1024        [2048]       3.335743      1.381951,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    1024   [1024, 512]        2.07054      1.122228,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       4    1024  [2048, 1024, 512]       1.530912   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0       0.93079  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       4    1024  [2048, 1024, 512]       3.136577   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.305202  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    1024   [1024, 512]       1.378343      0.918038,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    1024   [1024, 512]       3.147345      1.342784,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    1024        [1024]       1.400888      0.878531,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    1024        [1024]       3.391948      1.390963,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    2048        [2048]       1.434814      0.914265,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    2048        [2048]       3.708988      1.440524,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0             True       4    2048  [2048, 1024, 512]       1.345825   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      0.866419  ,\n",
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       " 0            False       4    2048  [2048, 1024, 512]       2.990404   \n",
       " \n",
       "    lossvalue_l1  \n",
       " 0      1.266722  ,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    1024        [1024]       1.223581      0.830473,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    2048   [1024, 512]        1.50637      0.975392,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    2048   [1024, 512]       3.052076       1.32726,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       4    2048        [1024]       1.319797      0.854828,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       4    2048        [1024]       3.509865      1.391937,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    1024        [1024]       2.645894      1.246022,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0             True       1    2048        [2048]       1.131054      0.800393,\n",
       "    create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       " 0            False       1    2048        [2048]       2.331344      1.194002]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_count_fp</th>\n",
       "      <th>radius</th>\n",
       "      <th>fpSize</th>\n",
       "      <th>linear_layers</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.341732</td>\n",
       "      <td>0.841053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   create_count_fp  radius  fpSize linear_layers  lossvalue_mse  lossvalue_l1\n",
       "0             True       1    2048   [1024, 512]       1.341732      0.841053"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot1[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullplot1 = pd.concat(plot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_count_fp</th>\n",
       "      <th>radius</th>\n",
       "      <th>fpSize</th>\n",
       "      <th>linear_layers</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.260419</td>\n",
       "      <td>0.868361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>2.508827</td>\n",
       "      <td>1.191430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.279525</td>\n",
       "      <td>0.904078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.265877</td>\n",
       "      <td>1.207724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.341732</td>\n",
       "      <td>0.841053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.319797</td>\n",
       "      <td>0.854828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.509865</td>\n",
       "      <td>1.391937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>2.645894</td>\n",
       "      <td>1.246022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.131054</td>\n",
       "      <td>0.800393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>2.331344</td>\n",
       "      <td>1.194002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       "0              True       1    1024             [2048]       1.260419   \n",
       "0             False       1    1024             [2048]       2.508827   \n",
       "0              True       1    2048  [2048, 1024, 512]       1.279525   \n",
       "0             False       1    2048  [2048, 1024, 512]       2.265877   \n",
       "0              True       1    2048        [1024, 512]       1.341732   \n",
       "..              ...     ...     ...                ...            ...   \n",
       "0              True       4    2048             [1024]       1.319797   \n",
       "0             False       4    2048             [1024]       3.509865   \n",
       "0             False       1    1024             [1024]       2.645894   \n",
       "0              True       1    2048             [2048]       1.131054   \n",
       "0             False       1    2048             [2048]       2.331344   \n",
       "\n",
       "    lossvalue_l1  \n",
       "0       0.868361  \n",
       "0       1.191430  \n",
       "0       0.904078  \n",
       "0       1.207724  \n",
       "0       0.841053  \n",
       "..           ...  \n",
       "0       0.854828  \n",
       "0       1.391937  \n",
       "0       1.246022  \n",
       "0       0.800393  \n",
       "0       1.194002  \n",
       "\n",
       "[64 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_count_fp</th>\n",
       "      <th>radius</th>\n",
       "      <th>fpSize</th>\n",
       "      <th>linear_layers</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.868361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.191430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>0.904078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.207724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>0.841053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>0.854828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.391937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.246022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>0.800393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.194002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    create_count_fp  radius  fpSize      linear_layers  lossvalue_l1\n",
       "0              True       1    1024             [2048]      0.868361\n",
       "0             False       1    1024             [2048]      1.191430\n",
       "0              True       1    2048  [2048, 1024, 512]      0.904078\n",
       "0             False       1    2048  [2048, 1024, 512]      1.207724\n",
       "0              True       1    2048        [1024, 512]      0.841053\n",
       "..              ...     ...     ...                ...           ...\n",
       "0              True       4    2048             [1024]      0.854828\n",
       "0             False       4    2048             [1024]      1.391937\n",
       "0             False       1    1024             [1024]      1.246022\n",
       "0              True       1    2048             [2048]      0.800393\n",
       "0             False       1    2048             [2048]      1.194002\n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1.drop(columns=\"lossvalue_mse\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.260419\n",
       "0    2.508827\n",
       "0    1.279525\n",
       "0    2.265877\n",
       "0    1.341732\n",
       "       ...   \n",
       "0    1.319797\n",
       "0    3.509865\n",
       "0    2.645894\n",
       "0    1.131054\n",
       "0    2.331344\n",
       "Name: lossvalue_mse, Length: 64, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1[\"lossvalue_mse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullplot1['Combined Label'] = fullplot1.drop(columns=[\"lossvalue_mse\", \"lossvalue_l1\"], axis=1).astype(str).agg(' - '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_count_fp</th>\n",
       "      <th>radius</th>\n",
       "      <th>fpSize</th>\n",
       "      <th>linear_layers</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "      <th>Combined Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.131054</td>\n",
       "      <td>0.800393</td>\n",
       "      <td>True - 1 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.178056</td>\n",
       "      <td>0.831184</td>\n",
       "      <td>True - 3 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.195386</td>\n",
       "      <td>0.820044</td>\n",
       "      <td>True - 3 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.202247</td>\n",
       "      <td>0.803523</td>\n",
       "      <td>True - 1 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.223581</td>\n",
       "      <td>0.830473</td>\n",
       "      <td>True - 1 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.235342</td>\n",
       "      <td>0.864359</td>\n",
       "      <td>True - 2 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.241115</td>\n",
       "      <td>0.832804</td>\n",
       "      <td>True - 2 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.244423</td>\n",
       "      <td>0.892133</td>\n",
       "      <td>True - 2 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.254394</td>\n",
       "      <td>0.859037</td>\n",
       "      <td>True - 3 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.260419</td>\n",
       "      <td>0.868361</td>\n",
       "      <td>True - 1 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.261572</td>\n",
       "      <td>0.897623</td>\n",
       "      <td>True - 3 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.268625</td>\n",
       "      <td>0.857097</td>\n",
       "      <td>True - 3 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.279525</td>\n",
       "      <td>0.904078</td>\n",
       "      <td>True - 1 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.288338</td>\n",
       "      <td>0.834402</td>\n",
       "      <td>True - 2 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.288663</td>\n",
       "      <td>0.856544</td>\n",
       "      <td>True - 1 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.306729</td>\n",
       "      <td>0.872920</td>\n",
       "      <td>True - 3 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.315490</td>\n",
       "      <td>0.902216</td>\n",
       "      <td>True - 2 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.316546</td>\n",
       "      <td>0.891302</td>\n",
       "      <td>True - 2 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.319797</td>\n",
       "      <td>0.854828</td>\n",
       "      <td>True - 4 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.341732</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>True - 1 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.345825</td>\n",
       "      <td>0.866419</td>\n",
       "      <td>True - 4 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.378343</td>\n",
       "      <td>0.918038</td>\n",
       "      <td>True - 4 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.394686</td>\n",
       "      <td>0.893341</td>\n",
       "      <td>True - 3 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.400888</td>\n",
       "      <td>0.878531</td>\n",
       "      <td>True - 4 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.401963</td>\n",
       "      <td>0.939971</td>\n",
       "      <td>True - 1 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.402881</td>\n",
       "      <td>0.912036</td>\n",
       "      <td>True - 4 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.416890</td>\n",
       "      <td>0.898521</td>\n",
       "      <td>True - 3 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.431848</td>\n",
       "      <td>0.912812</td>\n",
       "      <td>True - 2 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.434814</td>\n",
       "      <td>0.914265</td>\n",
       "      <td>True - 4 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.436072</td>\n",
       "      <td>0.919996</td>\n",
       "      <td>True - 2 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.506370</td>\n",
       "      <td>0.975392</td>\n",
       "      <td>True - 4 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.530912</td>\n",
       "      <td>0.930790</td>\n",
       "      <td>True - 4 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>2.070540</td>\n",
       "      <td>1.122228</td>\n",
       "      <td>False - 1 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.102536</td>\n",
       "      <td>1.105847</td>\n",
       "      <td>False - 1 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.265877</td>\n",
       "      <td>1.207724</td>\n",
       "      <td>False - 1 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>2.266599</td>\n",
       "      <td>1.172711</td>\n",
       "      <td>False - 1 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>2.269036</td>\n",
       "      <td>1.176112</td>\n",
       "      <td>False - 1 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>2.331344</td>\n",
       "      <td>1.194002</td>\n",
       "      <td>False - 1 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>2.508827</td>\n",
       "      <td>1.191430</td>\n",
       "      <td>False - 1 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>2.645894</td>\n",
       "      <td>1.246022</td>\n",
       "      <td>False - 1 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>2.663520</td>\n",
       "      <td>1.284458</td>\n",
       "      <td>False - 2 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.687559</td>\n",
       "      <td>1.287417</td>\n",
       "      <td>False - 2 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.779363</td>\n",
       "      <td>1.294182</td>\n",
       "      <td>False - 2 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.787351</td>\n",
       "      <td>1.265779</td>\n",
       "      <td>False - 3 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>2.968160</td>\n",
       "      <td>1.328066</td>\n",
       "      <td>False - 2 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.983734</td>\n",
       "      <td>1.298689</td>\n",
       "      <td>False - 3 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.990404</td>\n",
       "      <td>1.266722</td>\n",
       "      <td>False - 4 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.015098</td>\n",
       "      <td>1.305688</td>\n",
       "      <td>False - 2 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>3.052076</td>\n",
       "      <td>1.327260</td>\n",
       "      <td>False - 4 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>3.093812</td>\n",
       "      <td>1.329569</td>\n",
       "      <td>False - 3 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>3.136577</td>\n",
       "      <td>1.305202</td>\n",
       "      <td>False - 4 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>3.147345</td>\n",
       "      <td>1.342784</td>\n",
       "      <td>False - 4 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.216115</td>\n",
       "      <td>1.381661</td>\n",
       "      <td>False - 2 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.286098</td>\n",
       "      <td>1.386741</td>\n",
       "      <td>False - 2 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>3.316412</td>\n",
       "      <td>1.360421</td>\n",
       "      <td>False - 3 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.330203</td>\n",
       "      <td>1.381666</td>\n",
       "      <td>False - 2 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.332641</td>\n",
       "      <td>1.351039</td>\n",
       "      <td>False - 3 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.335743</td>\n",
       "      <td>1.381951</td>\n",
       "      <td>False - 4 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.371390</td>\n",
       "      <td>1.368656</td>\n",
       "      <td>False - 3 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.391948</td>\n",
       "      <td>1.390963</td>\n",
       "      <td>False - 4 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.491531</td>\n",
       "      <td>1.415132</td>\n",
       "      <td>False - 3 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.509865</td>\n",
       "      <td>1.391937</td>\n",
       "      <td>False - 4 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.520939</td>\n",
       "      <td>1.378953</td>\n",
       "      <td>False - 3 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.708988</td>\n",
       "      <td>1.440524</td>\n",
       "      <td>False - 4 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       "0             True       1    2048             [2048]       1.131054   \n",
       "0             True       3    2048        [1024, 512]       1.178056   \n",
       "0             True       3    2048  [2048, 1024, 512]       1.195386   \n",
       "0             True       1    2048             [1024]       1.202247   \n",
       "0             True       1    1024             [1024]       1.223581   \n",
       "0             True       2    1024             [1024]       1.235342   \n",
       "0             True       2    2048             [1024]       1.241115   \n",
       "0             True       2    1024  [2048, 1024, 512]       1.244423   \n",
       "0             True       3    2048             [2048]       1.254394   \n",
       "0             True       1    1024             [2048]       1.260419   \n",
       "0             True       3    1024  [2048, 1024, 512]       1.261572   \n",
       "0             True       3    2048             [1024]       1.268625   \n",
       "0             True       1    2048  [2048, 1024, 512]       1.279525   \n",
       "0             True       2    2048  [2048, 1024, 512]       1.288338   \n",
       "0             True       1    1024        [1024, 512]       1.288663   \n",
       "0             True       3    1024             [1024]       1.306729   \n",
       "0             True       2    1024        [1024, 512]       1.315490   \n",
       "0             True       2    2048             [2048]       1.316546   \n",
       "0             True       4    2048             [1024]       1.319797   \n",
       "0             True       1    2048        [1024, 512]       1.341732   \n",
       "0             True       4    2048  [2048, 1024, 512]       1.345825   \n",
       "0             True       4    1024        [1024, 512]       1.378343   \n",
       "0             True       3    1024        [1024, 512]       1.394686   \n",
       "0             True       4    1024             [1024]       1.400888   \n",
       "0             True       1    1024  [2048, 1024, 512]       1.401963   \n",
       "0             True       4    1024             [2048]       1.402881   \n",
       "0             True       3    1024             [2048]       1.416890   \n",
       "0             True       2    1024             [2048]       1.431848   \n",
       "0             True       4    2048             [2048]       1.434814   \n",
       "0             True       2    2048        [1024, 512]       1.436072   \n",
       "0             True       4    2048        [1024, 512]       1.506370   \n",
       "0             True       4    1024  [2048, 1024, 512]       1.530912   \n",
       "0            False       1    1024        [1024, 512]       2.070540   \n",
       "0            False       1    1024  [2048, 1024, 512]       2.102536   \n",
       "0            False       1    2048  [2048, 1024, 512]       2.265877   \n",
       "0            False       1    2048        [1024, 512]       2.266599   \n",
       "0            False       1    2048             [1024]       2.269036   \n",
       "0            False       1    2048             [2048]       2.331344   \n",
       "0            False       1    1024             [2048]       2.508827   \n",
       "0            False       1    1024             [1024]       2.645894   \n",
       "0            False       2    2048        [1024, 512]       2.663520   \n",
       "0            False       2    2048  [2048, 1024, 512]       2.687559   \n",
       "0            False       2    1024  [2048, 1024, 512]       2.779363   \n",
       "0            False       3    2048  [2048, 1024, 512]       2.787351   \n",
       "0            False       2    1024        [1024, 512]       2.968160   \n",
       "0            False       3    1024  [2048, 1024, 512]       2.983734   \n",
       "0            False       4    2048  [2048, 1024, 512]       2.990404   \n",
       "0            False       2    2048             [2048]       3.015098   \n",
       "0            False       4    2048        [1024, 512]       3.052076   \n",
       "0            False       3    1024        [1024, 512]       3.093812   \n",
       "0            False       4    1024  [2048, 1024, 512]       3.136577   \n",
       "0            False       4    1024        [1024, 512]       3.147345   \n",
       "0            False       2    1024             [1024]       3.216115   \n",
       "0            False       2    2048             [1024]       3.286098   \n",
       "0            False       3    2048        [1024, 512]       3.316412   \n",
       "0            False       2    1024             [2048]       3.330203   \n",
       "0            False       3    1024             [1024]       3.332641   \n",
       "0            False       4    1024             [2048]       3.335743   \n",
       "0            False       3    2048             [1024]       3.371390   \n",
       "0            False       4    1024             [1024]       3.391948   \n",
       "0            False       3    2048             [2048]       3.491531   \n",
       "0            False       4    2048             [1024]       3.509865   \n",
       "0            False       3    1024             [2048]       3.520939   \n",
       "0            False       4    2048             [2048]       3.708988   \n",
       "\n",
       "   lossvalue_l1                        Combined Label  \n",
       "0      0.800393              True - 1 - 2048 - [2048]  \n",
       "0      0.831184         True - 3 - 2048 - [1024, 512]  \n",
       "0      0.820044   True - 3 - 2048 - [2048, 1024, 512]  \n",
       "0      0.803523              True - 1 - 2048 - [1024]  \n",
       "0      0.830473              True - 1 - 1024 - [1024]  \n",
       "0      0.864359              True - 2 - 1024 - [1024]  \n",
       "0      0.832804              True - 2 - 2048 - [1024]  \n",
       "0      0.892133   True - 2 - 1024 - [2048, 1024, 512]  \n",
       "0      0.859037              True - 3 - 2048 - [2048]  \n",
       "0      0.868361              True - 1 - 1024 - [2048]  \n",
       "0      0.897623   True - 3 - 1024 - [2048, 1024, 512]  \n",
       "0      0.857097              True - 3 - 2048 - [1024]  \n",
       "0      0.904078   True - 1 - 2048 - [2048, 1024, 512]  \n",
       "0      0.834402   True - 2 - 2048 - [2048, 1024, 512]  \n",
       "0      0.856544         True - 1 - 1024 - [1024, 512]  \n",
       "0      0.872920              True - 3 - 1024 - [1024]  \n",
       "0      0.902216         True - 2 - 1024 - [1024, 512]  \n",
       "0      0.891302              True - 2 - 2048 - [2048]  \n",
       "0      0.854828              True - 4 - 2048 - [1024]  \n",
       "0      0.841053         True - 1 - 2048 - [1024, 512]  \n",
       "0      0.866419   True - 4 - 2048 - [2048, 1024, 512]  \n",
       "0      0.918038         True - 4 - 1024 - [1024, 512]  \n",
       "0      0.893341         True - 3 - 1024 - [1024, 512]  \n",
       "0      0.878531              True - 4 - 1024 - [1024]  \n",
       "0      0.939971   True - 1 - 1024 - [2048, 1024, 512]  \n",
       "0      0.912036              True - 4 - 1024 - [2048]  \n",
       "0      0.898521              True - 3 - 1024 - [2048]  \n",
       "0      0.912812              True - 2 - 1024 - [2048]  \n",
       "0      0.914265              True - 4 - 2048 - [2048]  \n",
       "0      0.919996         True - 2 - 2048 - [1024, 512]  \n",
       "0      0.975392         True - 4 - 2048 - [1024, 512]  \n",
       "0      0.930790   True - 4 - 1024 - [2048, 1024, 512]  \n",
       "0      1.122228        False - 1 - 1024 - [1024, 512]  \n",
       "0      1.105847  False - 1 - 1024 - [2048, 1024, 512]  \n",
       "0      1.207724  False - 1 - 2048 - [2048, 1024, 512]  \n",
       "0      1.172711        False - 1 - 2048 - [1024, 512]  \n",
       "0      1.176112             False - 1 - 2048 - [1024]  \n",
       "0      1.194002             False - 1 - 2048 - [2048]  \n",
       "0      1.191430             False - 1 - 1024 - [2048]  \n",
       "0      1.246022             False - 1 - 1024 - [1024]  \n",
       "0      1.284458        False - 2 - 2048 - [1024, 512]  \n",
       "0      1.287417  False - 2 - 2048 - [2048, 1024, 512]  \n",
       "0      1.294182  False - 2 - 1024 - [2048, 1024, 512]  \n",
       "0      1.265779  False - 3 - 2048 - [2048, 1024, 512]  \n",
       "0      1.328066        False - 2 - 1024 - [1024, 512]  \n",
       "0      1.298689  False - 3 - 1024 - [2048, 1024, 512]  \n",
       "0      1.266722  False - 4 - 2048 - [2048, 1024, 512]  \n",
       "0      1.305688             False - 2 - 2048 - [2048]  \n",
       "0      1.327260        False - 4 - 2048 - [1024, 512]  \n",
       "0      1.329569        False - 3 - 1024 - [1024, 512]  \n",
       "0      1.305202  False - 4 - 1024 - [2048, 1024, 512]  \n",
       "0      1.342784        False - 4 - 1024 - [1024, 512]  \n",
       "0      1.381661             False - 2 - 1024 - [1024]  \n",
       "0      1.386741             False - 2 - 2048 - [1024]  \n",
       "0      1.360421        False - 3 - 2048 - [1024, 512]  \n",
       "0      1.381666             False - 2 - 1024 - [2048]  \n",
       "0      1.351039             False - 3 - 1024 - [1024]  \n",
       "0      1.381951             False - 4 - 1024 - [2048]  \n",
       "0      1.368656             False - 3 - 2048 - [1024]  \n",
       "0      1.390963             False - 4 - 1024 - [1024]  \n",
       "0      1.415132             False - 3 - 2048 - [2048]  \n",
       "0      1.391937             False - 4 - 2048 - [1024]  \n",
       "0      1.378953             False - 3 - 1024 - [2048]  \n",
       "0      1.440524             False - 4 - 2048 - [2048]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1.sort_values(by=['lossvalue_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_count_fp</th>\n",
       "      <th>radius</th>\n",
       "      <th>fpSize</th>\n",
       "      <th>linear_layers</th>\n",
       "      <th>lossvalue_mse</th>\n",
       "      <th>lossvalue_l1</th>\n",
       "      <th>Combined Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.131054</td>\n",
       "      <td>0.800393</td>\n",
       "      <td>True - 1 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.202247</td>\n",
       "      <td>0.803523</td>\n",
       "      <td>True - 1 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.195386</td>\n",
       "      <td>0.820044</td>\n",
       "      <td>True - 3 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.223581</td>\n",
       "      <td>0.830473</td>\n",
       "      <td>True - 1 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.178056</td>\n",
       "      <td>0.831184</td>\n",
       "      <td>True - 3 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.241115</td>\n",
       "      <td>0.832804</td>\n",
       "      <td>True - 2 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.288338</td>\n",
       "      <td>0.834402</td>\n",
       "      <td>True - 2 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.341732</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>True - 1 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.319797</td>\n",
       "      <td>0.854828</td>\n",
       "      <td>True - 4 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.288663</td>\n",
       "      <td>0.856544</td>\n",
       "      <td>True - 1 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.268625</td>\n",
       "      <td>0.857097</td>\n",
       "      <td>True - 3 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.254394</td>\n",
       "      <td>0.859037</td>\n",
       "      <td>True - 3 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.235342</td>\n",
       "      <td>0.864359</td>\n",
       "      <td>True - 2 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.345825</td>\n",
       "      <td>0.866419</td>\n",
       "      <td>True - 4 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.260419</td>\n",
       "      <td>0.868361</td>\n",
       "      <td>True - 1 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.306729</td>\n",
       "      <td>0.872920</td>\n",
       "      <td>True - 3 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1.400888</td>\n",
       "      <td>0.878531</td>\n",
       "      <td>True - 4 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.316546</td>\n",
       "      <td>0.891302</td>\n",
       "      <td>True - 2 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.244423</td>\n",
       "      <td>0.892133</td>\n",
       "      <td>True - 2 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.394686</td>\n",
       "      <td>0.893341</td>\n",
       "      <td>True - 3 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.261572</td>\n",
       "      <td>0.897623</td>\n",
       "      <td>True - 3 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.416890</td>\n",
       "      <td>0.898521</td>\n",
       "      <td>True - 3 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.315490</td>\n",
       "      <td>0.902216</td>\n",
       "      <td>True - 2 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.279525</td>\n",
       "      <td>0.904078</td>\n",
       "      <td>True - 1 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.402881</td>\n",
       "      <td>0.912036</td>\n",
       "      <td>True - 4 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.431848</td>\n",
       "      <td>0.912812</td>\n",
       "      <td>True - 2 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>1.434814</td>\n",
       "      <td>0.914265</td>\n",
       "      <td>True - 4 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.378343</td>\n",
       "      <td>0.918038</td>\n",
       "      <td>True - 4 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.436072</td>\n",
       "      <td>0.919996</td>\n",
       "      <td>True - 2 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.530912</td>\n",
       "      <td>0.930790</td>\n",
       "      <td>True - 4 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>1.401963</td>\n",
       "      <td>0.939971</td>\n",
       "      <td>True - 1 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>1.506370</td>\n",
       "      <td>0.975392</td>\n",
       "      <td>True - 4 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.102536</td>\n",
       "      <td>1.105847</td>\n",
       "      <td>False - 1 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>2.070540</td>\n",
       "      <td>1.122228</td>\n",
       "      <td>False - 1 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>2.266599</td>\n",
       "      <td>1.172711</td>\n",
       "      <td>False - 1 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>2.269036</td>\n",
       "      <td>1.176112</td>\n",
       "      <td>False - 1 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>2.508827</td>\n",
       "      <td>1.191430</td>\n",
       "      <td>False - 1 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>2.331344</td>\n",
       "      <td>1.194002</td>\n",
       "      <td>False - 1 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.265877</td>\n",
       "      <td>1.207724</td>\n",
       "      <td>False - 1 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>2.645894</td>\n",
       "      <td>1.246022</td>\n",
       "      <td>False - 1 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.787351</td>\n",
       "      <td>1.265779</td>\n",
       "      <td>False - 3 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.990404</td>\n",
       "      <td>1.266722</td>\n",
       "      <td>False - 4 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>2.663520</td>\n",
       "      <td>1.284458</td>\n",
       "      <td>False - 2 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.687559</td>\n",
       "      <td>1.287417</td>\n",
       "      <td>False - 2 - 2048 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.779363</td>\n",
       "      <td>1.294182</td>\n",
       "      <td>False - 2 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>2.983734</td>\n",
       "      <td>1.298689</td>\n",
       "      <td>False - 3 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048, 1024, 512]</td>\n",
       "      <td>3.136577</td>\n",
       "      <td>1.305202</td>\n",
       "      <td>False - 4 - 1024 - [2048, 1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.015098</td>\n",
       "      <td>1.305688</td>\n",
       "      <td>False - 2 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>3.052076</td>\n",
       "      <td>1.327260</td>\n",
       "      <td>False - 4 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>2.968160</td>\n",
       "      <td>1.328066</td>\n",
       "      <td>False - 2 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>3.093812</td>\n",
       "      <td>1.329569</td>\n",
       "      <td>False - 3 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>3.147345</td>\n",
       "      <td>1.342784</td>\n",
       "      <td>False - 4 - 1024 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.332641</td>\n",
       "      <td>1.351039</td>\n",
       "      <td>False - 3 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>3.316412</td>\n",
       "      <td>1.360421</td>\n",
       "      <td>False - 3 - 2048 - [1024, 512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.371390</td>\n",
       "      <td>1.368656</td>\n",
       "      <td>False - 3 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.520939</td>\n",
       "      <td>1.378953</td>\n",
       "      <td>False - 3 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.216115</td>\n",
       "      <td>1.381661</td>\n",
       "      <td>False - 2 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.330203</td>\n",
       "      <td>1.381666</td>\n",
       "      <td>False - 2 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.335743</td>\n",
       "      <td>1.381951</td>\n",
       "      <td>False - 4 - 1024 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.286098</td>\n",
       "      <td>1.386741</td>\n",
       "      <td>False - 2 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.391948</td>\n",
       "      <td>1.390963</td>\n",
       "      <td>False - 4 - 1024 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>3.509865</td>\n",
       "      <td>1.391937</td>\n",
       "      <td>False - 4 - 2048 - [1024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.491531</td>\n",
       "      <td>1.415132</td>\n",
       "      <td>False - 3 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>3.708988</td>\n",
       "      <td>1.440524</td>\n",
       "      <td>False - 4 - 2048 - [2048]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   create_count_fp  radius  fpSize      linear_layers  lossvalue_mse  \\\n",
       "0             True       1    2048             [2048]       1.131054   \n",
       "0             True       1    2048             [1024]       1.202247   \n",
       "0             True       3    2048  [2048, 1024, 512]       1.195386   \n",
       "0             True       1    1024             [1024]       1.223581   \n",
       "0             True       3    2048        [1024, 512]       1.178056   \n",
       "0             True       2    2048             [1024]       1.241115   \n",
       "0             True       2    2048  [2048, 1024, 512]       1.288338   \n",
       "0             True       1    2048        [1024, 512]       1.341732   \n",
       "0             True       4    2048             [1024]       1.319797   \n",
       "0             True       1    1024        [1024, 512]       1.288663   \n",
       "0             True       3    2048             [1024]       1.268625   \n",
       "0             True       3    2048             [2048]       1.254394   \n",
       "0             True       2    1024             [1024]       1.235342   \n",
       "0             True       4    2048  [2048, 1024, 512]       1.345825   \n",
       "0             True       1    1024             [2048]       1.260419   \n",
       "0             True       3    1024             [1024]       1.306729   \n",
       "0             True       4    1024             [1024]       1.400888   \n",
       "0             True       2    2048             [2048]       1.316546   \n",
       "0             True       2    1024  [2048, 1024, 512]       1.244423   \n",
       "0             True       3    1024        [1024, 512]       1.394686   \n",
       "0             True       3    1024  [2048, 1024, 512]       1.261572   \n",
       "0             True       3    1024             [2048]       1.416890   \n",
       "0             True       2    1024        [1024, 512]       1.315490   \n",
       "0             True       1    2048  [2048, 1024, 512]       1.279525   \n",
       "0             True       4    1024             [2048]       1.402881   \n",
       "0             True       2    1024             [2048]       1.431848   \n",
       "0             True       4    2048             [2048]       1.434814   \n",
       "0             True       4    1024        [1024, 512]       1.378343   \n",
       "0             True       2    2048        [1024, 512]       1.436072   \n",
       "0             True       4    1024  [2048, 1024, 512]       1.530912   \n",
       "0             True       1    1024  [2048, 1024, 512]       1.401963   \n",
       "0             True       4    2048        [1024, 512]       1.506370   \n",
       "0            False       1    1024  [2048, 1024, 512]       2.102536   \n",
       "0            False       1    1024        [1024, 512]       2.070540   \n",
       "0            False       1    2048        [1024, 512]       2.266599   \n",
       "0            False       1    2048             [1024]       2.269036   \n",
       "0            False       1    1024             [2048]       2.508827   \n",
       "0            False       1    2048             [2048]       2.331344   \n",
       "0            False       1    2048  [2048, 1024, 512]       2.265877   \n",
       "0            False       1    1024             [1024]       2.645894   \n",
       "0            False       3    2048  [2048, 1024, 512]       2.787351   \n",
       "0            False       4    2048  [2048, 1024, 512]       2.990404   \n",
       "0            False       2    2048        [1024, 512]       2.663520   \n",
       "0            False       2    2048  [2048, 1024, 512]       2.687559   \n",
       "0            False       2    1024  [2048, 1024, 512]       2.779363   \n",
       "0            False       3    1024  [2048, 1024, 512]       2.983734   \n",
       "0            False       4    1024  [2048, 1024, 512]       3.136577   \n",
       "0            False       2    2048             [2048]       3.015098   \n",
       "0            False       4    2048        [1024, 512]       3.052076   \n",
       "0            False       2    1024        [1024, 512]       2.968160   \n",
       "0            False       3    1024        [1024, 512]       3.093812   \n",
       "0            False       4    1024        [1024, 512]       3.147345   \n",
       "0            False       3    1024             [1024]       3.332641   \n",
       "0            False       3    2048        [1024, 512]       3.316412   \n",
       "0            False       3    2048             [1024]       3.371390   \n",
       "0            False       3    1024             [2048]       3.520939   \n",
       "0            False       2    1024             [1024]       3.216115   \n",
       "0            False       2    1024             [2048]       3.330203   \n",
       "0            False       4    1024             [2048]       3.335743   \n",
       "0            False       2    2048             [1024]       3.286098   \n",
       "0            False       4    1024             [1024]       3.391948   \n",
       "0            False       4    2048             [1024]       3.509865   \n",
       "0            False       3    2048             [2048]       3.491531   \n",
       "0            False       4    2048             [2048]       3.708988   \n",
       "\n",
       "   lossvalue_l1                        Combined Label  \n",
       "0      0.800393              True - 1 - 2048 - [2048]  \n",
       "0      0.803523              True - 1 - 2048 - [1024]  \n",
       "0      0.820044   True - 3 - 2048 - [2048, 1024, 512]  \n",
       "0      0.830473              True - 1 - 1024 - [1024]  \n",
       "0      0.831184         True - 3 - 2048 - [1024, 512]  \n",
       "0      0.832804              True - 2 - 2048 - [1024]  \n",
       "0      0.834402   True - 2 - 2048 - [2048, 1024, 512]  \n",
       "0      0.841053         True - 1 - 2048 - [1024, 512]  \n",
       "0      0.854828              True - 4 - 2048 - [1024]  \n",
       "0      0.856544         True - 1 - 1024 - [1024, 512]  \n",
       "0      0.857097              True - 3 - 2048 - [1024]  \n",
       "0      0.859037              True - 3 - 2048 - [2048]  \n",
       "0      0.864359              True - 2 - 1024 - [1024]  \n",
       "0      0.866419   True - 4 - 2048 - [2048, 1024, 512]  \n",
       "0      0.868361              True - 1 - 1024 - [2048]  \n",
       "0      0.872920              True - 3 - 1024 - [1024]  \n",
       "0      0.878531              True - 4 - 1024 - [1024]  \n",
       "0      0.891302              True - 2 - 2048 - [2048]  \n",
       "0      0.892133   True - 2 - 1024 - [2048, 1024, 512]  \n",
       "0      0.893341         True - 3 - 1024 - [1024, 512]  \n",
       "0      0.897623   True - 3 - 1024 - [2048, 1024, 512]  \n",
       "0      0.898521              True - 3 - 1024 - [2048]  \n",
       "0      0.902216         True - 2 - 1024 - [1024, 512]  \n",
       "0      0.904078   True - 1 - 2048 - [2048, 1024, 512]  \n",
       "0      0.912036              True - 4 - 1024 - [2048]  \n",
       "0      0.912812              True - 2 - 1024 - [2048]  \n",
       "0      0.914265              True - 4 - 2048 - [2048]  \n",
       "0      0.918038         True - 4 - 1024 - [1024, 512]  \n",
       "0      0.919996         True - 2 - 2048 - [1024, 512]  \n",
       "0      0.930790   True - 4 - 1024 - [2048, 1024, 512]  \n",
       "0      0.939971   True - 1 - 1024 - [2048, 1024, 512]  \n",
       "0      0.975392         True - 4 - 2048 - [1024, 512]  \n",
       "0      1.105847  False - 1 - 1024 - [2048, 1024, 512]  \n",
       "0      1.122228        False - 1 - 1024 - [1024, 512]  \n",
       "0      1.172711        False - 1 - 2048 - [1024, 512]  \n",
       "0      1.176112             False - 1 - 2048 - [1024]  \n",
       "0      1.191430             False - 1 - 1024 - [2048]  \n",
       "0      1.194002             False - 1 - 2048 - [2048]  \n",
       "0      1.207724  False - 1 - 2048 - [2048, 1024, 512]  \n",
       "0      1.246022             False - 1 - 1024 - [1024]  \n",
       "0      1.265779  False - 3 - 2048 - [2048, 1024, 512]  \n",
       "0      1.266722  False - 4 - 2048 - [2048, 1024, 512]  \n",
       "0      1.284458        False - 2 - 2048 - [1024, 512]  \n",
       "0      1.287417  False - 2 - 2048 - [2048, 1024, 512]  \n",
       "0      1.294182  False - 2 - 1024 - [2048, 1024, 512]  \n",
       "0      1.298689  False - 3 - 1024 - [2048, 1024, 512]  \n",
       "0      1.305202  False - 4 - 1024 - [2048, 1024, 512]  \n",
       "0      1.305688             False - 2 - 2048 - [2048]  \n",
       "0      1.327260        False - 4 - 2048 - [1024, 512]  \n",
       "0      1.328066        False - 2 - 1024 - [1024, 512]  \n",
       "0      1.329569        False - 3 - 1024 - [1024, 512]  \n",
       "0      1.342784        False - 4 - 1024 - [1024, 512]  \n",
       "0      1.351039             False - 3 - 1024 - [1024]  \n",
       "0      1.360421        False - 3 - 2048 - [1024, 512]  \n",
       "0      1.368656             False - 3 - 2048 - [1024]  \n",
       "0      1.378953             False - 3 - 1024 - [2048]  \n",
       "0      1.381661             False - 2 - 1024 - [1024]  \n",
       "0      1.381666             False - 2 - 1024 - [2048]  \n",
       "0      1.381951             False - 4 - 1024 - [2048]  \n",
       "0      1.386741             False - 2 - 2048 - [1024]  \n",
       "0      1.390963             False - 4 - 1024 - [1024]  \n",
       "0      1.391937             False - 4 - 2048 - [1024]  \n",
       "0      1.415132             False - 3 - 2048 - [2048]  \n",
       "0      1.440524             False - 4 - 2048 - [2048]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullplot1.sort_values(by=['lossvalue_l1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Combined Label'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fullplot1.set_index('Combined Label', inplace=True)\n",
    "\n",
    "fullplot1['lossvalue_mse'].plot(kind='bar')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newest_dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
